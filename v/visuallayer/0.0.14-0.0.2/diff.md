# Comparing `tmp/visuallayer-0.0.14-py3.9-none-any.whl.zip` & `tmp/visuallayer-0.0.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,23 +1,21 @@
-Zip file size: 21546 bytes, number of entries: 21
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-12 11:08 visuallayer/__init__.py
--rw-r--r--  2.0 unx     4940 b- defN 23-Jun-12 11:08 visuallayer/sentry.py
--rw-r--r--  2.0 unx       19 b- defN 23-Jun-12 11:08 visuallayer/datasets/__init__.py
--rw-r--r--  2.0 unx     3747 b- defN 23-Jun-12 11:08 visuallayer/datasets/clean_torchvision_food101.py
--rw-r--r--  2.0 unx     2731 b- defN 23-Jun-12 11:08 visuallayer/datasets/clean_torchvision_imagenet.py
--rw-r--r--  2.0 unx     4483 b- defN 23-Jun-12 11:08 visuallayer/datasets/clean_torchvision_oxford_iiit_pet.py
--rw-r--r--  2.0 unx     2692 b- defN 23-Jun-12 11:08 visuallayer/datasets/dataset.py
--rw-r--r--  2.0 unx     2349 b- defN 23-Jun-12 11:08 visuallayer/datasets/image_folder.py
--rw-r--r--  2.0 unx     2765 b- defN 23-Jun-12 11:08 visuallayer/datasets/vl_cocodetection.py
--rw-r--r--  2.0 unx     3397 b- defN 23-Jun-12 11:08 visuallayer/datasets/vl_kitti.py
--rw-r--r--  2.0 unx     1139 b- defN 23-Jun-12 11:08 visuallayer/datasets/vl_parse_exclude_csv.py
--rw-r--r--  2.0 unx      154 b- defN 23-Jun-12 11:08 visuallayer/datasets/zoo/__init__.py
--rw-r--r--  2.0 unx      936 b- defN 23-Jun-12 11:08 visuallayer/datasets/zoo/utils.py
--rw-r--r--  2.0 unx     2823 b- defN 23-Jun-12 11:08 visuallayer/datasets/zoo/vl_food101.py
--rw-r--r--  2.0 unx     2694 b- defN 23-Jun-12 11:08 visuallayer/datasets/zoo/vl_imagenet.py
--rw-r--r--  2.0 unx     2990 b- defN 23-Jun-12 11:08 visuallayer/datasets/zoo/vl_oxford_iiit.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Jun-12 11:08 visuallayer-0.0.14.dist-info/LICENSE
--rw-r--r--  2.0 unx      864 b- defN 23-Jun-12 11:08 visuallayer-0.0.14.dist-info/METADATA
--rw-r--r--  2.0 unx      108 b- defN 23-Jun-12 11:08 visuallayer-0.0.14.dist-info/WHEEL
--rw-r--r--  2.0 unx       12 b- defN 23-Jun-12 11:08 visuallayer-0.0.14.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1921 b- defN 23-Jun-12 11:08 visuallayer-0.0.14.dist-info/RECORD
-21 files, 52213 bytes uncompressed, 18354 bytes compressed:  64.8%
+Zip file size: 19191 bytes, number of entries: 19
+-rw-rw-r--  2.0 unx       91 b- defN 23-Jun-05 11:41 visuallayer/__init__.py
+-rw-rw-r--  2.0 unx     4940 b- defN 23-Jun-05 04:57 visuallayer/sentry.py
+-rw-rw-r--  2.0 unx       19 b- defN 23-Jun-05 11:52 visuallayer/datasets/__init__.py
+-rw-rw-r--  2.0 unx     4483 b- defN 23-Jun-05 07:53 visuallayer/datasets/clean_torchvision_oxford_iiit_pet.py
+-rw-rw-r--  2.0 unx      942 b- defN 23-Jun-06 09:31 visuallayer/datasets/dataset.py
+-rw-rw-r--  2.0 unx     2349 b- defN 23-Jun-05 05:02 visuallayer/datasets/image_folder.py
+-rw-rw-r--  2.0 unx     2765 b- defN 23-Jun-05 04:57 visuallayer/datasets/vl_cocodetection.py
+-rw-rw-r--  2.0 unx     3733 b- defN 23-Jun-05 04:57 visuallayer/datasets/vl_food101.py
+-rw-rw-r--  2.0 unx     1887 b- defN 23-May-31 05:01 visuallayer/datasets/vl_imagenet.py
+-rw-rw-r--  2.0 unx     3397 b- defN 23-Jun-05 04:57 visuallayer/datasets/vl_kitti.py
+-rw-rw-r--  2.0 unx     1139 b- defN 23-May-30 04:29 visuallayer/datasets/vl_parse_exclude_csv.py
+-rw-rw-r--  2.0 unx       82 b- defN 23-Jun-06 02:56 visuallayer/datasets/zoo/__init__.py
+-rw-rw-r--  2.0 unx      646 b- defN 23-Jun-07 03:50 visuallayer/datasets/zoo/utils.py
+-rw-rw-r--  2.0 unx     5413 b- defN 23-Jun-07 04:21 visuallayer/datasets/zoo/vl_oxford_iiit.py
+-rw-rw-r--  2.0 unx    11357 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/LICENSE
+-rw-rw-r--  2.0 unx      821 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       12 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1692 b- defN 23-Jun-07 05:33 visuallayer-0.0.2.dist-info/RECORD
+19 files, 45860 bytes uncompressed, 16375 bytes compressed:  64.3%
```

## zipnote {}

```diff
@@ -3,62 +3,56 @@
 
 Filename: visuallayer/sentry.py
 Comment: 
 
 Filename: visuallayer/datasets/__init__.py
 Comment: 
 
-Filename: visuallayer/datasets/clean_torchvision_food101.py
-Comment: 
-
-Filename: visuallayer/datasets/clean_torchvision_imagenet.py
-Comment: 
-
 Filename: visuallayer/datasets/clean_torchvision_oxford_iiit_pet.py
 Comment: 
 
 Filename: visuallayer/datasets/dataset.py
 Comment: 
 
 Filename: visuallayer/datasets/image_folder.py
 Comment: 
 
 Filename: visuallayer/datasets/vl_cocodetection.py
 Comment: 
 
-Filename: visuallayer/datasets/vl_kitti.py
+Filename: visuallayer/datasets/vl_food101.py
 Comment: 
 
-Filename: visuallayer/datasets/vl_parse_exclude_csv.py
+Filename: visuallayer/datasets/vl_imagenet.py
 Comment: 
 
-Filename: visuallayer/datasets/zoo/__init__.py
+Filename: visuallayer/datasets/vl_kitti.py
 Comment: 
 
-Filename: visuallayer/datasets/zoo/utils.py
+Filename: visuallayer/datasets/vl_parse_exclude_csv.py
 Comment: 
 
-Filename: visuallayer/datasets/zoo/vl_food101.py
+Filename: visuallayer/datasets/zoo/__init__.py
 Comment: 
 
-Filename: visuallayer/datasets/zoo/vl_imagenet.py
+Filename: visuallayer/datasets/zoo/utils.py
 Comment: 
 
 Filename: visuallayer/datasets/zoo/vl_oxford_iiit.py
 Comment: 
 
-Filename: visuallayer-0.0.14.dist-info/LICENSE
+Filename: visuallayer-0.0.2.dist-info/LICENSE
 Comment: 
 
-Filename: visuallayer-0.0.14.dist-info/METADATA
+Filename: visuallayer-0.0.2.dist-info/METADATA
 Comment: 
 
-Filename: visuallayer-0.0.14.dist-info/WHEEL
+Filename: visuallayer-0.0.2.dist-info/WHEEL
 Comment: 
 
-Filename: visuallayer-0.0.14.dist-info/top_level.txt
+Filename: visuallayer-0.0.2.dist-info/top_level.txt
 Comment: 
 
-Filename: visuallayer-0.0.14.dist-info/RECORD
+Filename: visuallayer-0.0.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## visuallayer/__init__.py

```diff
@@ -1,4 +1,4 @@
-__version__ = '0.0.14'
+__version__ = '0.0.1'
 from .datasets import *
 from .sentry import init_sentry
 init_sentry()
```

## visuallayer/datasets/dataset.py

```diff
@@ -1,79 +1,61 @@
-import pandas as pd
-from typing import Union, List, Tuple
+from abc import ABC, abstractmethod
 
+class Dataset(ABC):
 
-class Dataset:
     @property
-    def num_images_with_issues(self) -> int:
-        df = pd.read_csv(self.filelist_csv_url)
-        return len(df["filename"].unique())
-
-    @property
-    def info(self) -> None:
-        # Get all attributes and methods of the class
-        dataset_metadata: List[Tuple[str, Union[str, int]]] = [
-            ("Name", self.name),
-            ("Description", self.description),
-            ("License", self.license),
-            ("Homepage URL", self.homepage_url),
-            ("Number of Images", self.num_images),
-            ("Number of Images with Issues", self.num_images_with_issues),
-        ]
-
-        print("Metadata:")
-        for metadata in dataset_metadata:
-            print(f"--> {metadata[0]} - {metadata[1]}")
-
-    @property
-    def report(self) -> pd.DataFrame:
-        df = pd.read_csv(self.issue_count_csv_url)
-        df = df.loc[df["split"] == "all"].drop("split", axis=1).reset_index(drop=True)
-        
-        # Calculate the total sum per column
-        total_count = df['count'].sum()
-        total_pct = df['pct'].sum()
-
-        # Create a DataFrame for the new row and concatenate it with the old DataFrame
-        new_row = pd.DataFrame({'reason': ['Total'], 'count': [total_count], 'pct': [total_pct]})
-        df = pd.concat([df, new_row], ignore_index=True)
-
-        return df
-    
-    def explore(self) -> pd.DataFrame:
-        import base64
-        from itables import init_notebook_mode
-        init_notebook_mode(all_interactive=True)
-
-        def to_img_tag(path):
-            if isinstance(path, str):
-                with open(path, 'rb') as f:
-                    image_data = f.read()
-                    base64_image = base64.b64encode(image_data).decode('utf-8')
-                return '<img src="data:image/png;base64,' + base64_image + '" width="150" >'
-            else:
-                return path  # Return the original value if it's not a string
-
-
-        df = pd.read_csv(self.filelist_csv_url)
-        df["filename_preview"] = df["filename"]
-        df["prototype_preview"] = df["prototype"]
-        df = df.loc[
-            :,
-            [
-                "filename",
-                "filename_preview",
-                "reason",
-                "value",
-                "prototype",
-                "prototype_preview",
-            ],
-        ]
-        df["filename_preview"] = df["filename"].apply(to_img_tag)
-        df["prototype_preview"] = df["prototype"].apply(to_img_tag)
-
-        return df
-
-    def export_issues(self, filename: str) -> None:
-        df = pd.read_csv(self.issue_count_csv_url)
-        df.to_csv(filename, index=False)
+    @abstractmethod
+    def filelist_csv_url(self):
+        pass
+
+    @property
+    @abstractmethod
+    def issue_count_csv_url(self):
+        pass
+
+    @property
+    @abstractmethod
+    def name(self):
+        pass
+
+    @property
+    @abstractmethod
+    def homepage_url(self):
+        pass
+
+    @property
+    @abstractmethod
+    def license(self):
+        pass
+
+    @property
+    @abstractmethod
+    def description(self):
+        pass
+
+    @property
+    @abstractmethod
+    def num_images(self):
+        pass
+
+    @property
+    @abstractmethod
+    def num_images_with_issues(self):
+        pass
+
+    @property
+    @abstractmethod
+    def info(self):
+        pass
+
+    @abstractmethod
+    def report(self):
+        pass
+
+    @abstractmethod
+    def export(self, output_format):
+        pass
+
+    @abstractmethod
+    def export_issues(self, filename):
+        pass
```

## visuallayer/datasets/zoo/__init__.py

```diff
@@ -1,4 +1,2 @@
 from .vl_oxford_iiit import VLOxfordIIITPet
-from .vl_food101 import VLFood101
-from .vl_imagenet import VLImageNet1k
 from .utils import load, list_datasets
```

## visuallayer/datasets/zoo/utils.py

```diff
@@ -1,31 +1,23 @@
 from .vl_oxford_iiit import VLOxfordIIITPet, VLOriginalOxfordIIITPet
-from .vl_food101 import VLFood101, VLOriginalFood101
-from .vl_imagenet import VLImageNet1k, VLOriginalImageNet1k
 
-dataset = {
-    "vl-oxford-iiit-pets": VLOxfordIIITPet,
-    "oxford-iiit-pets": VLOriginalOxfordIIITPet,
-    "vl-food101": VLFood101,
-    "food101": VLOriginalFood101,
-    "vl-imagenet-1k": VLImageNet1k,
-    "imagenet-1k": VLOriginalImageNet1k
-}
-
-
-def load(dataset_name: str):
-    loaded_dataset = dataset.get(dataset_name, CombinationError)
-    return loaded_dataset()
+
+def load(dataset_name, variant="vl"):
+    if dataset_name == "vl-oxford-iiit-pets":
+        if variant == "original":
+            return VLOriginalOxfordIIITPet()
+        else:
+            return VLOxfordIIITPet()
+    else:
+        raise ValueError(f"Could not find dataset. Did you mean {get_dataset_names()}?")
+
 
 def list_datasets():
-    names = _get_dataset_names()
+    names = get_dataset_names()
     print("Listing all datasets in zoo.")
-    return list(sorted(names))
-
-def _get_dataset_names():
-    dataset_names = [key for key in dataset.keys()]
-    return set(dataset_names)
+    return names
 
 
-class CombinationError:
-    def __init__(self):
-        raise NotImplementedError("This dataset and variation combination is not implemented.")
+def get_dataset_names():
+    datasets = [VLOxfordIIITPet()]
+    datasets_names = [dataset.name for dataset in datasets]
+    return datasets_names
```

## visuallayer/datasets/zoo/vl_oxford_iiit.py

```diff
@@ -1,68 +1,143 @@
 from ..clean_torchvision_oxford_iiit_pet import CleanTorchvisionOxfordIIITPet
 from ..dataset import Dataset
 from dataclasses import dataclass
 import pandas as pd
 from torchvision.datasets import OxfordIIITPet
 from typing import Union, List, Tuple
+from itables import init_notebook_mode
+
+init_notebook_mode(all_interactive=True)
+
 
 @dataclass(frozen=True)
 class VLOxfordIIITPet(Dataset):
+    filelist_csv_url: str = "https://sharedvisuallayer.s3.us-east-2.amazonaws.com/visual-layer-sdk/oxford-iiit-pet_images_issue_file_list.csv"
+    issue_count_csv_url: str = "https://sharedvisuallayer.s3.us-east-2.amazonaws.com/visual-layer-sdk/oxford-iiit-pet_images_issue_count.csv"
     name: str = "vl-oxford-iiit-pets"
     homepage_url: str = "https://www.robots.ox.ac.uk/~vgg/data/pets/"
-    license: str = "Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)"
+    license: str = (
+        "Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)"
+    )
     description: str = "A modified version of the original Oxford IIIT Pets Dataset removing dataset issues."
     num_images: int = 7349
-    filelist_csv_url: str = "https://sharedvisuallayer.s3.us-east-2.amazonaws.com/visual-layer-sdk/oxford-iiit-pet_images_issue_file_list.csv"
-    issue_count_csv_url: str = "https://sharedvisuallayer.s3.us-east-2.amazonaws.com/visual-layer-sdk/oxford-iiit-pet_images_issue_count.csv"
-    exclude_csv: str = None
 
-    # Hack: Download the dataset in the current dir
-    def __post_init__(self):
-        OxfordIIITPet(root="./", download=True)
+    @property
+    def num_images_with_issues(self) -> int:
+        df = pd.read_csv(self.filelist_csv_url)
+        return len(df["filename"].unique())
+
+    @property
+    def info(self) -> None:
+        # Get all attributes and methods of the class
+        dataset_metadata: List[Tuple[str, Union[str, int]]] = [
+            ("Name", self.name),
+            ("Description", self.description),
+            ("License", self.license),
+            ("Homepage URL", self.homepage_url),
+            ("Number of Images", self.num_images),
+            ("Number of Images with Issues", self.num_images_with_issues),
+        ]
+
+        print("Metadata:")
+        for metadata in dataset_metadata:
+            print(f"--> {metadata[0]} - {metadata[1]}")
+
+    @property
+    def report(self) -> None:
+        df = pd.read_csv(self.issue_count_csv_url)
+        all_issues_df: pd.DataFrame = (
+            df.loc[df["split"] == "all"].drop("split", axis=1).reset_index(drop=True)
+        )
+
+        print(f"Visual Layer Profiler issues in this dataset:\n")
+
+        # print issues to user
+        for _, row in all_issues_df.iterrows():
+            reason: str = row["reason"]
+            count: int = row["count"]
+            pct: float = row["pct"]
+
+            output: str = f"--> {count:,} {reason.upper()}(S) ({pct:.2f}%)"
+            print(output)
+
+        print(
+            "\nThese images are removed in the `vl` variant of the dataset. To load the original version of the dataset, use variant=`original`. Explore the full data and the issues head to http://visual-layer.com/datasets/dataset/1234-5678-abcd"
+        )
 
     def export(
         self,
         output_format: str,
-        variation: str = "vl",
+        variant: str = "vl",
         root: str = "./",
         split: str = "train",
     ):
         if output_format == "pytorch":
-            if variation == "vl":
+            if variant == "vl":
                 print(
-                    f"Exporting {variation.upper()} dataset into {output_format} dataset."
+                    f"Exporting {variant.upper()} dataset into {output_format} dataset."
                 )
-                return CleanTorchvisionOxfordIIITPet(root=root, split=split, exclude_csv=self.exclude_csv)
-            elif variation == "original":
+                return CleanTorchvisionOxfordIIITPet(root=root, split=split)
+            elif variant == "original":
                 print(
-                    f"Exporting {variation.upper()} dataset into {output_format} dataset."
+                    f"Exporting {variant.upper()} dataset into {output_format} dataset."
                 )
                 return OxfordIIITPet(root=root, split=split, download=True)
         
         elif output_format == "csv":
-            if variation == "vl":
+            if variant == "vl":
                 print(
-                    f"Exporting {variation.upper()} dataset into {output_format} dataset."
+                    f"Exporting {variant.upper()} dataset into {output_format} dataset."
                 )
-                dataset = CleanTorchvisionOxfordIIITPet(root=root, split=split, exclude_csv=self.exclude_csv)
+                dataset = CleanTorchvisionOxfordIIITPet(root=root, split=split)
                 samples = {"Image": dataset._images, "Label": dataset._labels}
                 df = pd.DataFrame(samples)
                 return df
-            elif variation == "original":
+            elif variant == "original":
                 print(
-                    f"Exporting {variation.upper()} dataset into {output_format} dataset."
+                    f"Exporting {variant.upper()} dataset into {output_format} dataset."
                 )
                 dataset = OxfordIIITPet(root=root, split=split, download=True)
                 samples = {"Image": dataset._images, "Label": dataset._labels}
                 df = pd.DataFrame(samples)
                 return df
 
         else:
             raise ValueError(
-                f"Unknown output format: {output_format} or variation {variation}."
+                f"Unknown output format: {output_format} or variant {variant}."
             )
 
+    def export_issues(self, filename: str) -> None:
+        df = pd.read_csv(self.issue_count_csv_url)
+        df.to_csv(filename, index=False)
+
+    def explore(self):
+        def to_img_tag(path):
+            if isinstance(path, str):
+                return '<img src="' + path + '" width="150" >'
+            else:
+                return path  # Return the original value if it's not a string
+
+        df = pd.read_csv(self.filelist_csv_url)
+        df["filename_preview"] = df["filename"]
+        df["prototype_preview"] = df["prototype"]
+        df = df.loc[
+            :,
+            [
+                "filename",
+                "filename_preview",
+                "reason",
+                "value",
+                "prototype",
+                "prototype_preview",
+            ],
+        ]
+        df["filename_preview"] = df["filename"].apply(to_img_tag)
+        df["prototype_preview"] = df["prototype"].apply(to_img_tag)
+
+        return df
+
+
 @dataclass(frozen=True)
 class VLOriginalOxfordIIITPet(VLOxfordIIITPet):
     name: str = "oxford-iiit-pets"
     description: str = "The original pets dataset by Oxford IIIT."
```

## Comparing `visuallayer/datasets/clean_torchvision_food101.py` & `visuallayer/datasets/vl_food101.py`

 * *Files 6% similar despite different names*

```diff
@@ -24,15 +24,15 @@
         transforms.CenterCrop(224),
         transforms.ToTensor(),
         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
     ]
 )
 
 
-class CleanTorchvisionFood101(Food101):
+class VLFood101(Food101):
     @v1_sentry_handler
     def __init__(
         self,
         root: str,
         split: str = "train",
         transform: Optional[Callable] = None,
         target_transform: Optional[Callable] = None,
```

## Comparing `visuallayer/datasets/clean_torchvision_imagenet.py` & `visuallayer/datasets/vl_imagenet.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,41 +1,21 @@
 # Code adapted from https://github.com/pytorch/vision/blob/main/torchvision/datasets/
 
 from torchvision.datasets import ImageNet
-from typing import Optional, Any, Tuple, Callable
+from typing import Optional, Any, Tuple
 import pandas as pd
-import torchvision.transforms as transforms
 
-train_transform = transforms.Compose(
-    [
-        transforms.RandomResizedCrop(224),
-        transforms.RandomHorizontalFlip(),
-        transforms.ToTensor(),
-        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
-    ]
-)
-
-valid_transform = transforms.Compose(
-    [
-        transforms.Resize(256),
-        transforms.CenterCrop(224),
-        transforms.ToTensor(),
-        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
-    ]
-)
-
-class CleanTorchvisionImageNet(ImageNet):
+class VLImageNet(ImageNet):
     def __init__(self, root: str, 
                  split: str = "train", 
                  exclude_csv: Optional[str] = None, 
-                 transform: Optional[Callable] = None,
                  **kwargs: Any) -> None:
         
 
-        super().__init__(root=root, split=split, transform=transform, **kwargs)
+        super().__init__(root=root, split=split, **kwargs)
         
         self.exclude_df, self.exclude_set = parse_exclude_csv(exclude_csv)
 
         # Filter file lists based on VL CSV files
         # Extract filenames from samples
         filenames = {sample[0].split("/")[-1] for sample in self.samples}
 
@@ -44,22 +24,14 @@
 
         # Create the filtered_list by filtering tuples_list based on the filtered_filenames
         filtered_samples = [(filename, label) for filename, label in self.samples if filename.split("/")[-1] in filtered_filenames]
         filtered_targets = [s[1] for s in filtered_samples]
 
         self.samples = filtered_samples
         self.targets = filtered_targets
-
-        # Default tranform
-        if transform is None:
-            if split == "train":
-                self.transform = train_transform
-
-            else:
-                self.transform = valid_transform
         
 
 def parse_exclude_csv(exclude_csv_arg: str) -> Tuple[pd.DataFrame, set]:
     
     if exclude_csv_arg:
         print(f"Using provided CSV file: {exclude_csv_arg}")
         exclude_df = pd.read_csv(exclude_csv_arg, header=0)
```

## Comparing `visuallayer-0.0.14.dist-info/LICENSE` & `visuallayer-0.0.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `visuallayer-0.0.14.dist-info/METADATA` & `visuallayer-0.0.2.dist-info/METADATA`

 * *Files 10% similar despite different names*

```diff
@@ -1,28 +1,25 @@
 Metadata-Version: 2.1
 Name: visuallayer
-Version: 0.0.14
+Version: 0.0.2
 Summary: Open, Clean Datasets for Computer Vision.
 Home-page: https://github.com/visual-layer/vl-datasets
 Author: Visual Layer
 Author-email: info@visual-layer.com
 License: Apache-2.0
 Keywords: machine learning,computer vision,data-centric
-Platform: UNKNOWN
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Operating System :: OS Independent
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: torch
 Requires-Dist: torchvision
 Requires-Dist: pandas
 Requires-Dist: sentry-sdk
 Requires-Dist: scipy
-Requires-Dist: itables
 
 Coming soon.
-
```

