# Comparing `tmp/google-cloud-alloydb-0.1.1.tar.gz` & `tmp/google-cloud-alloydb-0.2.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "google-cloud-alloydb-0.1.1.tar", last modified: Mon Mar 27 14:58:19 2023, max compression
+gzip compressed data, was "google-cloud-alloydb-0.2.0.tar", last modified: Tue Jun 13 15:01:16 2023, max compression
```

## Comparing `google-cloud-alloydb-0.1.1.tar` & `google-cloud-alloydb-0.2.0.tar`

### file list

```diff
@@ -1,102 +1,102 @@
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.310109 google-cloud-alloydb-0.1.1/
--rw-rw-r--   0 root         (0)     1003    11358 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/LICENSE
--rw-rw-r--   0 root         (0)     1003      860 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/MANIFEST.in
--rw-r--r--   0 root         (0)     1003     4362 2023-03-27 14:58:19.310109 google-cloud-alloydb-0.1.1/PKG-INFO
--rw-rw-r--   0 root         (0)     1003     3454 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/README.rst
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.290107 google-cloud-alloydb-0.1.1/google/
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.290107 google-cloud-alloydb-0.1.1/google/cloud/
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.294108 google-cloud-alloydb-0.1.1/google/cloud/alloydb/
--rw-rw-r--   0 root         (0)     1003     3265 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb/__init__.py
--rw-rw-r--   0 root         (0)     1003      653 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb/gapic_version.py
--rw-rw-r--   0 root         (0)     1003       81 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb/py.typed
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.294108 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/
--rw-rw-r--   0 root         (0)     1003     3111 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/__init__.py
--rw-rw-r--   0 root         (0)     1003     8061 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/gapic_metadata.json
--rw-rw-r--   0 root         (0)     1003      653 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/gapic_version.py
--rw-rw-r--   0 root         (0)     1003       81 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/py.typed
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.294108 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/
--rw-rw-r--   0 root         (0)     1003      600 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.294108 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/
--rw-rw-r--   0 root         (0)     1003      761 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/__init__.py
--rw-rw-r--   0 root         (0)     1003   122487 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/async_client.py
--rw-rw-r--   0 root         (0)     1003   134825 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/client.py
--rw-rw-r--   0 root         (0)     1003    20819 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/pagers.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.294108 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/
--rw-rw-r--   0 root         (0)     1003     1372 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/__init__.py
--rw-rw-r--   0 root         (0)     1003    18392 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/base.py
--rw-rw-r--   0 root         (0)     1003    39452 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/grpc.py
--rw-rw-r--   0 root         (0)     1003    40218 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/grpc_asyncio.py
--rw-rw-r--   0 root         (0)     1003   131980 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/rest.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.298108 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/types/
--rw-rw-r--   0 root         (0)     1003     2847 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/types/__init__.py
--rw-rw-r--   0 root         (0)     1003    55204 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/types/resources.py
--rw-rw-r--   0 root         (0)     1003    47733 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/types/service.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.298108 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/
--rw-rw-r--   0 root         (0)     1003     3750 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/__init__.py
--rw-rw-r--   0 root         (0)     1003    10129 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/gapic_metadata.json
--rw-rw-r--   0 root         (0)     1003      653 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/gapic_version.py
--rw-rw-r--   0 root         (0)     1003       81 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/py.typed
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.298108 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/
--rw-rw-r--   0 root         (0)     1003      600 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.298108 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/
--rw-rw-r--   0 root         (0)     1003      761 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/__init__.py
--rw-rw-r--   0 root         (0)     1003   149244 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/async_client.py
--rw-rw-r--   0 root         (0)     1003   162427 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/client.py
--rw-rw-r--   0 root         (0)     1003    20984 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/pagers.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.298108 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/
--rw-rw-r--   0 root         (0)     1003     1372 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/__init__.py
--rw-rw-r--   0 root         (0)     1003    21441 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/base.py
--rw-rw-r--   0 root         (0)     1003    45988 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/grpc.py
--rw-rw-r--   0 root         (0)     1003    46906 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/grpc_asyncio.py
--rw-rw-r--   0 root         (0)     1003   159201 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/rest.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.302109 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/types/
--rw-rw-r--   0 root         (0)     1003     3481 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/types/__init__.py
--rw-rw-r--   0 root         (0)     1003    60780 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/types/resources.py
--rw-rw-r--   0 root         (0)     1003    59767 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/types/service.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.302109 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/
--rw-rw-r--   0 root         (0)     1003     3749 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/__init__.py
--rw-rw-r--   0 root         (0)     1003    10127 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/gapic_metadata.json
--rw-rw-r--   0 root         (0)     1003      653 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/gapic_version.py
--rw-rw-r--   0 root         (0)     1003       81 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/py.typed
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.302109 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/
--rw-rw-r--   0 root         (0)     1003      600 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.302109 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/
--rw-rw-r--   0 root         (0)     1003      761 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/__init__.py
--rw-rw-r--   0 root         (0)     1003   149100 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/async_client.py
--rw-rw-r--   0 root         (0)     1003   162283 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/client.py
--rw-rw-r--   0 root         (0)     1003    20951 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/pagers.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.302109 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/
--rw-rw-r--   0 root         (0)     1003     1372 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/__init__.py
--rw-rw-r--   0 root         (0)     1003    21439 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/base.py
--rw-rw-r--   0 root         (0)     1003    45962 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/grpc.py
--rw-rw-r--   0 root         (0)     1003    46880 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/grpc_asyncio.py
--rw-rw-r--   0 root         (0)     1003   158997 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/rest.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.306109 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/types/
--rw-rw-r--   0 root         (0)     1003     3481 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/types/__init__.py
--rw-rw-r--   0 root         (0)     1003    60739 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/types/resources.py
--rw-rw-r--   0 root         (0)     1003    59742 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/types/service.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.306109 google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/
--rw-r--r--   0 root         (0)     1003     4362 2023-03-27 14:58:19.000000 google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/PKG-INFO
--rw-r--r--   0 root         (0)     1003     3705 2023-03-27 14:58:19.000000 google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/SOURCES.txt
--rw-r--r--   0 root         (0)     1003        1 2023-03-27 14:58:19.000000 google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/dependency_links.txt
--rw-r--r--   0 root         (0)     1003       20 2023-03-27 14:58:19.000000 google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/namespace_packages.txt
--rw-r--r--   0 root         (0)     1003        1 2023-03-27 14:58:19.000000 google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/not-zip-safe
--rw-r--r--   0 root         (0)     1003      352 2023-03-27 14:58:19.000000 google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/requires.txt
--rw-r--r--   0 root         (0)     1003        7 2023-03-27 14:58:19.000000 google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/top_level.txt
--rw-r--r--   0 root         (0)     1003       38 2023-03-27 14:58:19.310109 google-cloud-alloydb-0.1.1/setup.cfg
--rw-rw-r--   0 root         (0)     1003     2973 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/setup.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.306109 google-cloud-alloydb-0.1.1/tests/
--rw-rw-r--   0 root         (0)     1003      600 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/tests/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.306109 google-cloud-alloydb-0.1.1/tests/unit/
--rw-rw-r--   0 root         (0)     1003      600 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/tests/unit/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.306109 google-cloud-alloydb-0.1.1/tests/unit/gapic/
--rw-rw-r--   0 root         (0)     1003      600 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/tests/unit/gapic/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.306109 google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1/
--rw-rw-r--   0 root         (0)     1003      600 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1/__init__.py
--rw-rw-r--   0 root         (0)     1003   523844 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1/test_alloy_db_admin.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.306109 google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1alpha/
--rw-rw-r--   0 root         (0)     1003      600 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1alpha/__init__.py
--rw-rw-r--   0 root         (0)     1003   630944 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1alpha/test_alloy_db_admin.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-03-27 14:58:19.310109 google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1beta/
--rw-rw-r--   0 root         (0)     1003      600 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1beta/__init__.py
--rw-rw-r--   0 root         (0)     1003   630915 2023-03-27 14:55:35.000000 google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1beta/test_alloy_db_admin.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.429958 google-cloud-alloydb-0.2.0/
+-rw-rw-r--   0 root         (0)     1003    11358 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/LICENSE
+-rw-rw-r--   0 root         (0)     1003      860 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/MANIFEST.in
+-rw-r--r--   0 root         (0)     1003     4362 2023-06-13 15:01:16.429958 google-cloud-alloydb-0.2.0/PKG-INFO
+-rw-rw-r--   0 root         (0)     1003     3454 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/README.rst
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.409957 google-cloud-alloydb-0.2.0/google/
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.409957 google-cloud-alloydb-0.2.0/google/cloud/
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.413957 google-cloud-alloydb-0.2.0/google/cloud/alloydb/
+-rw-rw-r--   0 root         (0)     1003     4025 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb/__init__.py
+-rw-rw-r--   0 root         (0)     1003      652 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb/gapic_version.py
+-rw-rw-r--   0 root         (0)     1003       81 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb/py.typed
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.413957 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/
+-rw-rw-r--   0 root         (0)     1003     3871 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/__init__.py
+-rw-rw-r--   0 root         (0)     1003    11355 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/gapic_metadata.json
+-rw-rw-r--   0 root         (0)     1003      652 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/gapic_version.py
+-rw-rw-r--   0 root         (0)     1003       81 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/py.typed
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.413957 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/
+-rw-rw-r--   0 root         (0)     1003      600 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.413957 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/
+-rw-rw-r--   0 root         (0)     1003      761 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/__init__.py
+-rw-rw-r--   0 root         (0)     1003   165381 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/async_client.py
+-rw-rw-r--   0 root         (0)     1003   179610 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/client.py
+-rw-rw-r--   0 root         (0)     1003    25613 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/pagers.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.413957 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/
+-rw-rw-r--   0 root         (0)     1003     1372 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/__init__.py
+-rw-rw-r--   0 root         (0)     1003    22170 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/base.py
+-rw-rw-r--   0 root         (0)     1003    49405 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/grpc.py
+-rw-rw-r--   0 root         (0)     1003    50442 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/grpc_asyncio.py
+-rw-rw-r--   0 root         (0)     1003   176665 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/rest.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.417957 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/types/
+-rw-rw-r--   0 root         (0)     1003     3607 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/types/__init__.py
+-rw-rw-r--   0 root         (0)     1003    62689 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/types/resources.py
+-rw-rw-r--   0 root         (0)     1003    65977 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/types/service.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.417957 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/
+-rw-rw-r--   0 root         (0)     1003     4138 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/__init__.py
+-rw-rw-r--   0 root         (0)     1003    12199 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/gapic_metadata.json
+-rw-rw-r--   0 root         (0)     1003      652 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/gapic_version.py
+-rw-rw-r--   0 root         (0)     1003       81 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/py.typed
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.417957 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/
+-rw-rw-r--   0 root         (0)     1003      600 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.417957 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/
+-rw-rw-r--   0 root         (0)     1003      761 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/__init__.py
+-rw-rw-r--   0 root         (0)     1003   176250 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/async_client.py
+-rw-rw-r--   0 root         (0)     1003   190294 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/client.py
+-rw-rw-r--   0 root         (0)     1003    25818 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/pagers.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.421958 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/
+-rw-rw-r--   0 root         (0)     1003     1372 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/__init__.py
+-rw-rw-r--   0 root         (0)     1003    24539 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/base.py
+-rw-rw-r--   0 root         (0)     1003    52275 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/grpc.py
+-rw-rw-r--   0 root         (0)     1003    53370 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/grpc_asyncio.py
+-rw-rw-r--   0 root         (0)     1003   187741 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/rest.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.421958 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/types/
+-rw-rw-r--   0 root         (0)     1003     3869 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/types/__init__.py
+-rw-rw-r--   0 root         (0)     1003    67262 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/types/resources.py
+-rw-rw-r--   0 root         (0)     1003    71128 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/types/service.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.421958 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/
+-rw-rw-r--   0 root         (0)     1003     4137 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/__init__.py
+-rw-rw-r--   0 root         (0)     1003    12197 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/gapic_metadata.json
+-rw-rw-r--   0 root         (0)     1003      652 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/gapic_version.py
+-rw-rw-r--   0 root         (0)     1003       81 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/py.typed
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.421958 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/
+-rw-rw-r--   0 root         (0)     1003      600 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.421958 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/
+-rw-rw-r--   0 root         (0)     1003      761 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/__init__.py
+-rw-rw-r--   0 root         (0)     1003   176074 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/async_client.py
+-rw-rw-r--   0 root         (0)     1003   190118 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/client.py
+-rw-rw-r--   0 root         (0)     1003    25777 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/pagers.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.425958 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/
+-rw-rw-r--   0 root         (0)     1003     1372 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/__init__.py
+-rw-rw-r--   0 root         (0)     1003    24537 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/base.py
+-rw-rw-r--   0 root         (0)     1003    52243 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/grpc.py
+-rw-rw-r--   0 root         (0)     1003    53338 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/grpc_asyncio.py
+-rw-rw-r--   0 root         (0)     1003   187531 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/rest.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.425958 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/types/
+-rw-rw-r--   0 root         (0)     1003     3869 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/types/__init__.py
+-rw-rw-r--   0 root         (0)     1003    67217 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/types/resources.py
+-rw-rw-r--   0 root         (0)     1003    71098 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/types/service.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.425958 google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/
+-rw-r--r--   0 root         (0)     1003     4362 2023-06-13 15:01:16.000000 google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0)     1003     3705 2023-06-13 15:01:16.000000 google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0)     1003        1 2023-06-13 15:01:16.000000 google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0)     1003       20 2023-06-13 15:01:16.000000 google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/namespace_packages.txt
+-rw-r--r--   0 root         (0)     1003        1 2023-06-13 15:01:16.000000 google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/not-zip-safe
+-rw-r--r--   0 root         (0)     1003      352 2023-06-13 15:01:16.000000 google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/requires.txt
+-rw-r--r--   0 root         (0)     1003        7 2023-06-13 15:01:16.000000 google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/top_level.txt
+-rw-r--r--   0 root         (0)     1003       38 2023-06-13 15:01:16.429958 google-cloud-alloydb-0.2.0/setup.cfg
+-rw-rw-r--   0 root         (0)     1003     2973 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/setup.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.425958 google-cloud-alloydb-0.2.0/tests/
+-rw-rw-r--   0 root         (0)     1003      600 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/tests/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.425958 google-cloud-alloydb-0.2.0/tests/unit/
+-rw-rw-r--   0 root         (0)     1003      600 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/tests/unit/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.425958 google-cloud-alloydb-0.2.0/tests/unit/gapic/
+-rw-rw-r--   0 root         (0)     1003      600 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/tests/unit/gapic/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.425958 google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1/
+-rw-rw-r--   0 root         (0)     1003      600 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1/__init__.py
+-rw-rw-r--   0 root         (0)     1003   711930 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1/test_alloy_db_admin.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.429958 google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1alpha/
+-rw-rw-r--   0 root         (0)     1003      600 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1alpha/__init__.py
+-rw-rw-r--   0 root         (0)     1003   753611 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1alpha/test_alloy_db_admin.py
+drwxr-sr-x   0 root         (0)     1003        0 2023-06-13 15:01:16.429958 google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1beta/
+-rw-rw-r--   0 root         (0)     1003      600 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1beta/__init__.py
+-rw-rw-r--   0 root         (0)     1003   753576 2023-06-13 14:58:22.000000 google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1beta/test_alloy_db_admin.py
```

### Comparing `google-cloud-alloydb-0.1.1/LICENSE` & `google-cloud-alloydb-0.2.0/LICENSE`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/MANIFEST.in` & `google-cloud-alloydb-0.2.0/MANIFEST.in`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/PKG-INFO` & `google-cloud-alloydb-0.2.0/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: google-cloud-alloydb
-Version: 0.1.1
+Version: 0.2.0
 Summary: Google Cloud Alloydb API client library
 Home-page: https://github.com/googleapis/google-cloud-python
 Author: Google LLC
 Author-email: googleapis-packages@google.com
 License: Apache 2.0
 Platform: Posix; MacOS X; Windows
 Classifier: Development Status :: 4 - Beta
```

### Comparing `google-cloud-alloydb-0.1.1/README.rst` & `google-cloud-alloydb-0.2.0/README.rst`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -23,95 +23,125 @@
 )
 from google.cloud.alloydb_v1.services.alloy_db_admin.client import AlloyDBAdminClient
 from google.cloud.alloydb_v1.types.resources import (
     AutomatedBackupPolicy,
     Backup,
     BackupSource,
     Cluster,
+    ClusterView,
+    ContinuousBackupConfig,
+    ContinuousBackupInfo,
+    ContinuousBackupSource,
     DatabaseVersion,
     EncryptionConfig,
     EncryptionInfo,
     Instance,
     InstanceView,
     MigrationSource,
     SslConfig,
     SupportedDatabaseFlag,
+    User,
     UserPassword,
 )
 from google.cloud.alloydb_v1.types.service import (
     BatchCreateInstancesMetadata,
     BatchCreateInstancesRequest,
     BatchCreateInstancesResponse,
     BatchCreateInstanceStatus,
     CreateBackupRequest,
     CreateClusterRequest,
     CreateInstanceRequest,
     CreateInstanceRequests,
+    CreateSecondaryClusterRequest,
+    CreateSecondaryInstanceRequest,
+    CreateUserRequest,
     DeleteBackupRequest,
     DeleteClusterRequest,
     DeleteInstanceRequest,
+    DeleteUserRequest,
     FailoverInstanceRequest,
     GetBackupRequest,
     GetClusterRequest,
     GetInstanceRequest,
+    GetUserRequest,
+    InjectFaultRequest,
     ListBackupsRequest,
     ListBackupsResponse,
     ListClustersRequest,
     ListClustersResponse,
     ListInstancesRequest,
     ListInstancesResponse,
     ListSupportedDatabaseFlagsRequest,
     ListSupportedDatabaseFlagsResponse,
+    ListUsersRequest,
+    ListUsersResponse,
     OperationMetadata,
+    PromoteClusterRequest,
     RestartInstanceRequest,
     RestoreClusterRequest,
     UpdateBackupRequest,
     UpdateClusterRequest,
     UpdateInstanceRequest,
+    UpdateUserRequest,
 )
 
 __all__ = (
     "AlloyDBAdminClient",
     "AlloyDBAdminAsyncClient",
     "AutomatedBackupPolicy",
     "Backup",
     "BackupSource",
     "Cluster",
+    "ContinuousBackupConfig",
+    "ContinuousBackupInfo",
+    "ContinuousBackupSource",
     "EncryptionConfig",
     "EncryptionInfo",
     "Instance",
     "MigrationSource",
     "SslConfig",
     "SupportedDatabaseFlag",
+    "User",
     "UserPassword",
+    "ClusterView",
     "DatabaseVersion",
     "InstanceView",
     "BatchCreateInstancesMetadata",
     "BatchCreateInstancesRequest",
     "BatchCreateInstancesResponse",
     "BatchCreateInstanceStatus",
     "CreateBackupRequest",
     "CreateClusterRequest",
     "CreateInstanceRequest",
     "CreateInstanceRequests",
+    "CreateSecondaryClusterRequest",
+    "CreateSecondaryInstanceRequest",
+    "CreateUserRequest",
     "DeleteBackupRequest",
     "DeleteClusterRequest",
     "DeleteInstanceRequest",
+    "DeleteUserRequest",
     "FailoverInstanceRequest",
     "GetBackupRequest",
     "GetClusterRequest",
     "GetInstanceRequest",
+    "GetUserRequest",
+    "InjectFaultRequest",
     "ListBackupsRequest",
     "ListBackupsResponse",
     "ListClustersRequest",
     "ListClustersResponse",
     "ListInstancesRequest",
     "ListInstancesResponse",
     "ListSupportedDatabaseFlagsRequest",
     "ListSupportedDatabaseFlagsResponse",
+    "ListUsersRequest",
+    "ListUsersResponse",
     "OperationMetadata",
+    "PromoteClusterRequest",
     "RestartInstanceRequest",
     "RestoreClusterRequest",
     "UpdateBackupRequest",
     "UpdateClusterRequest",
     "UpdateInstanceRequest",
+    "UpdateUserRequest",
 )
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb/gapic_version.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/__init__.py`

 * *Files 13% similar despite different names*

```diff
@@ -9,9 +9,7 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-
-__version__ = "0.1.1"  # {x-release-please-version}
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/types/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -9,106 +9,128 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from google.cloud.alloydb_v1 import gapic_version as package_version
-
-__version__ = package_version.__version__
-
-
-from .services.alloy_db_admin import AlloyDBAdminAsyncClient, AlloyDBAdminClient
-from .types.resources import (
+from .resources import (
     AutomatedBackupPolicy,
     Backup,
     BackupSource,
     Cluster,
+    ClusterView,
+    ContinuousBackupConfig,
+    ContinuousBackupInfo,
+    ContinuousBackupSource,
     DatabaseVersion,
     EncryptionConfig,
     EncryptionInfo,
     Instance,
     InstanceView,
     MigrationSource,
     SslConfig,
     SupportedDatabaseFlag,
+    User,
     UserPassword,
 )
-from .types.service import (
+from .service import (
     BatchCreateInstancesMetadata,
     BatchCreateInstancesRequest,
     BatchCreateInstancesResponse,
     BatchCreateInstanceStatus,
     CreateBackupRequest,
     CreateClusterRequest,
     CreateInstanceRequest,
     CreateInstanceRequests,
+    CreateSecondaryClusterRequest,
+    CreateSecondaryInstanceRequest,
+    CreateUserRequest,
     DeleteBackupRequest,
     DeleteClusterRequest,
     DeleteInstanceRequest,
+    DeleteUserRequest,
     FailoverInstanceRequest,
     GetBackupRequest,
     GetClusterRequest,
     GetInstanceRequest,
+    GetUserRequest,
+    InjectFaultRequest,
     ListBackupsRequest,
     ListBackupsResponse,
     ListClustersRequest,
     ListClustersResponse,
     ListInstancesRequest,
     ListInstancesResponse,
     ListSupportedDatabaseFlagsRequest,
     ListSupportedDatabaseFlagsResponse,
+    ListUsersRequest,
+    ListUsersResponse,
     OperationMetadata,
+    PromoteClusterRequest,
     RestartInstanceRequest,
     RestoreClusterRequest,
     UpdateBackupRequest,
     UpdateClusterRequest,
     UpdateInstanceRequest,
+    UpdateUserRequest,
 )
 
 __all__ = (
-    "AlloyDBAdminAsyncClient",
-    "AlloyDBAdminClient",
     "AutomatedBackupPolicy",
     "Backup",
     "BackupSource",
-    "BatchCreateInstanceStatus",
+    "Cluster",
+    "ContinuousBackupConfig",
+    "ContinuousBackupInfo",
+    "ContinuousBackupSource",
+    "EncryptionConfig",
+    "EncryptionInfo",
+    "Instance",
+    "MigrationSource",
+    "SslConfig",
+    "SupportedDatabaseFlag",
+    "User",
+    "UserPassword",
+    "ClusterView",
+    "DatabaseVersion",
+    "InstanceView",
     "BatchCreateInstancesMetadata",
     "BatchCreateInstancesRequest",
     "BatchCreateInstancesResponse",
-    "Cluster",
+    "BatchCreateInstanceStatus",
     "CreateBackupRequest",
     "CreateClusterRequest",
     "CreateInstanceRequest",
     "CreateInstanceRequests",
-    "DatabaseVersion",
+    "CreateSecondaryClusterRequest",
+    "CreateSecondaryInstanceRequest",
+    "CreateUserRequest",
     "DeleteBackupRequest",
     "DeleteClusterRequest",
     "DeleteInstanceRequest",
-    "EncryptionConfig",
-    "EncryptionInfo",
+    "DeleteUserRequest",
     "FailoverInstanceRequest",
     "GetBackupRequest",
     "GetClusterRequest",
     "GetInstanceRequest",
-    "Instance",
-    "InstanceView",
+    "GetUserRequest",
+    "InjectFaultRequest",
     "ListBackupsRequest",
     "ListBackupsResponse",
     "ListClustersRequest",
     "ListClustersResponse",
     "ListInstancesRequest",
     "ListInstancesResponse",
     "ListSupportedDatabaseFlagsRequest",
     "ListSupportedDatabaseFlagsResponse",
-    "MigrationSource",
+    "ListUsersRequest",
+    "ListUsersResponse",
     "OperationMetadata",
+    "PromoteClusterRequest",
     "RestartInstanceRequest",
     "RestoreClusterRequest",
-    "SslConfig",
-    "SupportedDatabaseFlag",
     "UpdateBackupRequest",
     "UpdateClusterRequest",
     "UpdateInstanceRequest",
-    "UserPassword",
+    "UpdateUserRequest",
 )
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/gapic_metadata.json` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/gapic_metadata.json`

 * *Files 27% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9991918103448275%*

 * *Differences: {"'services'": "{'AlloyDBAdmin': {'clients': {'grpc': {'rpcs': {'CreateSecondaryCluster': "*

 * *               "OrderedDict([('methods', ['create_secondary_cluster'])]), "*

 * *               "'CreateSecondaryInstance': OrderedDict([('methods', "*

 * *               "['create_secondary_instance'])]), 'CreateUser': OrderedDict([('methods', "*

 * *               "['create_user'])]), 'DeleteUser': OrderedDict([('methods', ['delete_user'])]), "*

 * *               "'GetUser': OrderedDict([('methods', ['get_user'])]), 'InjectFault': "*

 * * [â€¦]*

```diff
@@ -26,14 +26,29 @@
                             ]
                         },
                         "CreateInstance": {
                             "methods": [
                                 "create_instance"
                             ]
                         },
+                        "CreateSecondaryCluster": {
+                            "methods": [
+                                "create_secondary_cluster"
+                            ]
+                        },
+                        "CreateSecondaryInstance": {
+                            "methods": [
+                                "create_secondary_instance"
+                            ]
+                        },
+                        "CreateUser": {
+                            "methods": [
+                                "create_user"
+                            ]
+                        },
                         "DeleteBackup": {
                             "methods": [
                                 "delete_backup"
                             ]
                         },
                         "DeleteCluster": {
                             "methods": [
@@ -41,14 +56,19 @@
                             ]
                         },
                         "DeleteInstance": {
                             "methods": [
                                 "delete_instance"
                             ]
                         },
+                        "DeleteUser": {
+                            "methods": [
+                                "delete_user"
+                            ]
+                        },
                         "FailoverInstance": {
                             "methods": [
                                 "failover_instance"
                             ]
                         },
                         "GetBackup": {
                             "methods": [
@@ -61,14 +81,24 @@
                             ]
                         },
                         "GetInstance": {
                             "methods": [
                                 "get_instance"
                             ]
                         },
+                        "GetUser": {
+                            "methods": [
+                                "get_user"
+                            ]
+                        },
+                        "InjectFault": {
+                            "methods": [
+                                "inject_fault"
+                            ]
+                        },
                         "ListBackups": {
                             "methods": [
                                 "list_backups"
                             ]
                         },
                         "ListClusters": {
                             "methods": [
@@ -81,14 +111,24 @@
                             ]
                         },
                         "ListSupportedDatabaseFlags": {
                             "methods": [
                                 "list_supported_database_flags"
                             ]
                         },
+                        "ListUsers": {
+                            "methods": [
+                                "list_users"
+                            ]
+                        },
+                        "PromoteCluster": {
+                            "methods": [
+                                "promote_cluster"
+                            ]
+                        },
                         "RestartInstance": {
                             "methods": [
                                 "restart_instance"
                             ]
                         },
                         "RestoreCluster": {
                             "methods": [
@@ -105,14 +145,19 @@
                                 "update_cluster"
                             ]
                         },
                         "UpdateInstance": {
                             "methods": [
                                 "update_instance"
                             ]
+                        },
+                        "UpdateUser": {
+                            "methods": [
+                                "update_user"
+                            ]
                         }
                     }
                 },
                 "grpc-async": {
                     "libraryClient": "AlloyDBAdminAsyncClient",
                     "rpcs": {
                         "BatchCreateInstances": {
@@ -131,14 +176,29 @@
                             ]
                         },
                         "CreateInstance": {
                             "methods": [
                                 "create_instance"
                             ]
                         },
+                        "CreateSecondaryCluster": {
+                            "methods": [
+                                "create_secondary_cluster"
+                            ]
+                        },
+                        "CreateSecondaryInstance": {
+                            "methods": [
+                                "create_secondary_instance"
+                            ]
+                        },
+                        "CreateUser": {
+                            "methods": [
+                                "create_user"
+                            ]
+                        },
                         "DeleteBackup": {
                             "methods": [
                                 "delete_backup"
                             ]
                         },
                         "DeleteCluster": {
                             "methods": [
@@ -146,14 +206,19 @@
                             ]
                         },
                         "DeleteInstance": {
                             "methods": [
                                 "delete_instance"
                             ]
                         },
+                        "DeleteUser": {
+                            "methods": [
+                                "delete_user"
+                            ]
+                        },
                         "FailoverInstance": {
                             "methods": [
                                 "failover_instance"
                             ]
                         },
                         "GetBackup": {
                             "methods": [
@@ -166,14 +231,24 @@
                             ]
                         },
                         "GetInstance": {
                             "methods": [
                                 "get_instance"
                             ]
                         },
+                        "GetUser": {
+                            "methods": [
+                                "get_user"
+                            ]
+                        },
+                        "InjectFault": {
+                            "methods": [
+                                "inject_fault"
+                            ]
+                        },
                         "ListBackups": {
                             "methods": [
                                 "list_backups"
                             ]
                         },
                         "ListClusters": {
                             "methods": [
@@ -186,14 +261,24 @@
                             ]
                         },
                         "ListSupportedDatabaseFlags": {
                             "methods": [
                                 "list_supported_database_flags"
                             ]
                         },
+                        "ListUsers": {
+                            "methods": [
+                                "list_users"
+                            ]
+                        },
+                        "PromoteCluster": {
+                            "methods": [
+                                "promote_cluster"
+                            ]
+                        },
                         "RestartInstance": {
                             "methods": [
                                 "restart_instance"
                             ]
                         },
                         "RestoreCluster": {
                             "methods": [
@@ -210,14 +295,19 @@
                                 "update_cluster"
                             ]
                         },
                         "UpdateInstance": {
                             "methods": [
                                 "update_instance"
                             ]
+                        },
+                        "UpdateUser": {
+                            "methods": [
+                                "update_user"
+                            ]
                         }
                     }
                 },
                 "rest": {
                     "libraryClient": "AlloyDBAdminClient",
                     "rpcs": {
                         "BatchCreateInstances": {
@@ -236,14 +326,29 @@
                             ]
                         },
                         "CreateInstance": {
                             "methods": [
                                 "create_instance"
                             ]
                         },
+                        "CreateSecondaryCluster": {
+                            "methods": [
+                                "create_secondary_cluster"
+                            ]
+                        },
+                        "CreateSecondaryInstance": {
+                            "methods": [
+                                "create_secondary_instance"
+                            ]
+                        },
+                        "CreateUser": {
+                            "methods": [
+                                "create_user"
+                            ]
+                        },
                         "DeleteBackup": {
                             "methods": [
                                 "delete_backup"
                             ]
                         },
                         "DeleteCluster": {
                             "methods": [
@@ -251,14 +356,19 @@
                             ]
                         },
                         "DeleteInstance": {
                             "methods": [
                                 "delete_instance"
                             ]
                         },
+                        "DeleteUser": {
+                            "methods": [
+                                "delete_user"
+                            ]
+                        },
                         "FailoverInstance": {
                             "methods": [
                                 "failover_instance"
                             ]
                         },
                         "GetBackup": {
                             "methods": [
@@ -271,14 +381,24 @@
                             ]
                         },
                         "GetInstance": {
                             "methods": [
                                 "get_instance"
                             ]
                         },
+                        "GetUser": {
+                            "methods": [
+                                "get_user"
+                            ]
+                        },
+                        "InjectFault": {
+                            "methods": [
+                                "inject_fault"
+                            ]
+                        },
                         "ListBackups": {
                             "methods": [
                                 "list_backups"
                             ]
                         },
                         "ListClusters": {
                             "methods": [
@@ -291,14 +411,24 @@
                             ]
                         },
                         "ListSupportedDatabaseFlags": {
                             "methods": [
                                 "list_supported_database_flags"
                             ]
                         },
+                        "ListUsers": {
+                            "methods": [
+                                "list_users"
+                            ]
+                        },
+                        "PromoteCluster": {
+                            "methods": [
+                                "promote_cluster"
+                            ]
+                        },
                         "RestartInstance": {
                             "methods": [
                                 "restart_instance"
                             ]
                         },
                         "RestoreCluster": {
                             "methods": [
@@ -315,14 +445,19 @@
                                 "update_cluster"
                             ]
                         },
                         "UpdateInstance": {
                             "methods": [
                                 "update_instance"
                             ]
+                        },
+                        "UpdateUser": {
+                            "methods": [
+                                "update_user"
+                            ]
                         }
                     }
                 }
             }
         }
     }
 }
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/gapic_version.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,17 +1,15 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2022 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-
-__version__ = "0.1.1"  # {x-release-please-version}
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/async_client.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/async_client.py`

 * *Files 12% similar despite different names*

```diff
@@ -82,14 +82,16 @@
     parse_network_path = staticmethod(AlloyDBAdminClient.parse_network_path)
     supported_database_flag_path = staticmethod(
         AlloyDBAdminClient.supported_database_flag_path
     )
     parse_supported_database_flag_path = staticmethod(
         AlloyDBAdminClient.parse_supported_database_flag_path
     )
+    user_path = staticmethod(AlloyDBAdminClient.user_path)
+    parse_user_path = staticmethod(AlloyDBAdminClient.parse_user_path)
     common_billing_account_path = staticmethod(
         AlloyDBAdminClient.common_billing_account_path
     )
     parse_common_billing_account_path = staticmethod(
         AlloyDBAdminClient.parse_common_billing_account_path
     )
     common_folder_path = staticmethod(AlloyDBAdminClient.common_folder_path)
@@ -530,16 +532,16 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Optional[Union[google.cloud.alloydb_v1.types.CreateClusterRequest, dict]]):
                 The request object. Message for creating a Cluster
             parent (:class:`str`):
-                Required. The name of the parent
-                resource. For the required format, see
+                Required. The location of the new
+                cluster. For the required format, see
                 the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (:class:`google.cloud.alloydb_v1.types.Cluster`):
                 Required. The resource being created
@@ -878,14 +880,135 @@
             empty_pb2.Empty,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    async def promote_cluster(
+        self,
+        request: Optional[Union[service.PromoteClusterRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation_async.AsyncOperation:
+        r"""Promotes a SECONDARY cluster. This turns down
+        replication from the PRIMARY cluster and promotes a
+        secondary cluster into its own standalone cluster.
+        Imperative only.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            async def sample_promote_cluster():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.PromoteClusterRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                operation = client.promote_cluster(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = (await operation).result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1.types.PromoteClusterRequest, dict]]):
+                The request object. Message for promoting a Cluster
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the Cluster.name field
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation_async.AsyncOperation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1.types.Cluster` A cluster is a collection of regional AlloyDB resources. It can include a
+                   primary instance and one or more read pool instances.
+                   All cluster resources share a storage layer, which
+                   scales as needed.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.PromoteClusterRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.promote_cluster,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation_async.from_gapic(
+            response,
+            self._client._transport.operations_client,
+            resources.Cluster,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     async def restore_cluster(
         self,
         request: Optional[Union[service.RestoreClusterRequest, dict]] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
@@ -988,14 +1111,160 @@
             resources.Cluster,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    async def create_secondary_cluster(
+        self,
+        request: Optional[Union[service.CreateSecondaryClusterRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        cluster: Optional[resources.Cluster] = None,
+        cluster_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation_async.AsyncOperation:
+        r"""Creates a cluster of type SECONDARY in the given
+        location using the primary cluster as the source.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            async def sample_create_secondary_cluster():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                cluster = alloydb_v1.Cluster()
+                cluster.backup_source.backup_name = "backup_name_value"
+                cluster.network = "network_value"
+
+                request = alloydb_v1.CreateSecondaryClusterRequest(
+                    parent="parent_value",
+                    cluster_id="cluster_id_value",
+                    cluster=cluster,
+                )
+
+                # Make the request
+                operation = client.create_secondary_cluster(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = (await operation).result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1.types.CreateSecondaryClusterRequest, dict]]):
+                The request object.
+            parent (:class:`str`):
+                Required. The location of the new
+                cluster. For the required format, see
+                the comment on the Cluster.name field.
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            cluster (:class:`google.cloud.alloydb_v1.types.Cluster`):
+                Required. Configuration of the
+                requesting object (the secondary
+                cluster).
+
+                This corresponds to the ``cluster`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            cluster_id (:class:`str`):
+                Required. ID of the requesting object
+                (the secondary cluster).
+
+                This corresponds to the ``cluster_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation_async.AsyncOperation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1.types.Cluster` A cluster is a collection of regional AlloyDB resources. It can include a
+                   primary instance and one or more read pool instances.
+                   All cluster resources share a storage layer, which
+                   scales as needed.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, cluster, cluster_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.CreateSecondaryClusterRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+        if cluster is not None:
+            request.cluster = cluster
+        if cluster_id is not None:
+            request.cluster_id = cluster_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.create_secondary_cluster,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation_async.from_gapic(
+            response,
+            self._client._transport.operations_client,
+            resources.Cluster,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     async def list_instances(
         self,
         request: Optional[Union[service.ListInstancesRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -1371,14 +1640,155 @@
             resources.Instance,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    async def create_secondary_instance(
+        self,
+        request: Optional[Union[service.CreateSecondaryInstanceRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        instance: Optional[resources.Instance] = None,
+        instance_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation_async.AsyncOperation:
+        r"""Creates a new SECONDARY Instance in a given project
+        and location.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            async def sample_create_secondary_instance():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                instance = alloydb_v1.Instance()
+                instance.instance_type = "SECONDARY"
+
+                request = alloydb_v1.CreateSecondaryInstanceRequest(
+                    parent="parent_value",
+                    instance_id="instance_id_value",
+                    instance=instance,
+                )
+
+                # Make the request
+                operation = client.create_secondary_instance(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = (await operation).result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1.types.CreateSecondaryInstanceRequest, dict]]):
+                The request object. Message for creating a Secondary
+                Instance
+            parent (:class:`str`):
+                Required. The name of the parent
+                resource. For the required format, see
+                the comment on the Instance.name field.
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            instance (:class:`google.cloud.alloydb_v1.types.Instance`):
+                Required. The resource being created
+                This corresponds to the ``instance`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            instance_id (:class:`str`):
+                Required. ID of the requesting
+                object.
+
+                This corresponds to the ``instance_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation_async.AsyncOperation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1.types.Instance` An Instance is a computing unit that an end customer can connect to.
+                   It's the main unit of computing resources in AlloyDB.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, instance, instance_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.CreateSecondaryInstanceRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+        if instance is not None:
+            request.instance = instance
+        if instance_id is not None:
+            request.instance_id = instance_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.create_secondary_instance,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation_async.from_gapic(
+            response,
+            self._client._transport.operations_client,
+            resources.Instance,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     async def batch_create_instances(
         self,
         request: Optional[Union[service.BatchCreateInstancesRequest, dict]] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
@@ -1859,14 +2269,143 @@
             resources.Instance,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    async def inject_fault(
+        self,
+        request: Optional[Union[service.InjectFaultRequest, dict]] = None,
+        *,
+        fault_type: Optional[service.InjectFaultRequest.FaultType] = None,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation_async.AsyncOperation:
+        r"""Injects fault in an instance.
+        Imperative only.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            async def sample_inject_fault():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.InjectFaultRequest(
+                    fault_type="STOP_VM",
+                    name="name_value",
+                )
+
+                # Make the request
+                operation = client.inject_fault(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = (await operation).result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1.types.InjectFaultRequest, dict]]):
+                The request object. Message for triggering fault
+                injection on an instance
+            fault_type (:class:`google.cloud.alloydb_v1.types.InjectFaultRequest.FaultType`):
+                Required. The type of fault to be
+                injected in an instance.
+
+                This corresponds to the ``fault_type`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the Instance.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation_async.AsyncOperation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1.types.Instance` An Instance is a computing unit that an end customer can connect to.
+                   It's the main unit of computing resources in AlloyDB.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([fault_type, name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.InjectFaultRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if fault_type is not None:
+            request.fault_type = fault_type
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.inject_fault,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation_async.from_gapic(
+            response,
+            self._client._transport.operations_client,
+            resources.Instance,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     async def restart_instance(
         self,
         request: Optional[Union[service.RestartInstanceRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -2734,14 +3273,546 @@
             response=response,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
+    async def list_users(
+        self,
+        request: Optional[Union[service.ListUsersRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> pagers.ListUsersAsyncPager:
+        r"""Lists Users in a given project and location.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            async def sample_list_users():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.ListUsersRequest(
+                    parent="parent_value",
+                )
+
+                # Make the request
+                page_result = client.list_users(request=request)
+
+                # Handle the response
+                async for response in page_result:
+                    print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1.types.ListUsersRequest, dict]]):
+                The request object. Message for requesting list of Users
+            parent (:class:`str`):
+                Required. Parent value for
+                ListUsersRequest
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1.services.alloy_db_admin.pagers.ListUsersAsyncPager:
+                Message for response to listing Users
+                Iterating over this object will yield
+                results and resolve additional pages
+                automatically.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.ListUsersRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.list_users,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # This method is paged; wrap the response in a pager, which provides
+        # an `__aiter__` convenience method.
+        response = pagers.ListUsersAsyncPager(
+            method=rpc,
+            request=request,
+            response=response,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def get_user(
+        self,
+        request: Optional[Union[service.GetUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Gets details of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            async def sample_get_user():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.GetUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                response = await client.get_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1.types.GetUserRequest, dict]]):
+                The request object. Message for getting a User
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.GetUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.get_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def create_user(
+        self,
+        request: Optional[Union[service.CreateUserRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        user: Optional[resources.User] = None,
+        user_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Creates a new User in a given project, location, and
+        cluster.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            async def sample_create_user():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.CreateUserRequest(
+                    parent="parent_value",
+                    user_id="user_id_value",
+                )
+
+                # Make the request
+                response = await client.create_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1.types.CreateUserRequest, dict]]):
+                The request object. Message for creating a User
+            parent (:class:`str`):
+                Required. Value for parent.
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user (:class:`google.cloud.alloydb_v1.types.User`):
+                Required. The resource being created
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user_id (:class:`str`):
+                Required. ID of the requesting
+                object.
+
+                This corresponds to the ``user_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, user, user_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.CreateUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+        if user is not None:
+            request.user = user
+        if user_id is not None:
+            request.user_id = user_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.create_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def update_user(
+        self,
+        request: Optional[Union[service.UpdateUserRequest, dict]] = None,
+        *,
+        user: Optional[resources.User] = None,
+        update_mask: Optional[field_mask_pb2.FieldMask] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Updates the parameters of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            async def sample_update_user():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.UpdateUserRequest(
+                )
+
+                # Make the request
+                response = await client.update_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1.types.UpdateUserRequest, dict]]):
+                The request object. Message for updating a User
+            user (:class:`google.cloud.alloydb_v1.types.User`):
+                Required. The resource being updated
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
+                Optional. Field mask is used to specify the fields to be
+                overwritten in the User resource by the update. The
+                fields specified in the update_mask are relative to the
+                resource, not the full request. A field will be
+                overwritten if it is in the mask. If the user does not
+                provide a mask then all fields will be overwritten.
+
+                This corresponds to the ``update_mask`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([user, update_mask])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.UpdateUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if user is not None:
+            request.user = user
+        if update_mask is not None:
+            request.update_mask = update_mask
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.update_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata(
+                (("user.name", request.user.name),)
+            ),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def delete_user(
+        self,
+        request: Optional[Union[service.DeleteUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> None:
+        r"""Deletes a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            async def sample_delete_user():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.DeleteUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                await client.delete_user(request=request)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1.types.DeleteUserRequest, dict]]):
+                The request object. Message for deleting a User
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.DeleteUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.delete_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
     async def list_operations(
         self,
         request: Optional[operations_pb2.ListOperationsRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/client.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/client.py`

 * *Files 11% similar despite different names*

```diff
@@ -317,14 +317,38 @@
         m = re.match(
             r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/flags/(?P<flag>.+?)$",
             path,
         )
         return m.groupdict() if m else {}
 
     @staticmethod
+    def user_path(
+        project: str,
+        location: str,
+        cluster: str,
+        user: str,
+    ) -> str:
+        """Returns a fully-qualified user string."""
+        return "projects/{project}/locations/{location}/clusters/{cluster}/users/{user}".format(
+            project=project,
+            location=location,
+            cluster=cluster,
+            user=user,
+        )
+
+    @staticmethod
+    def parse_user_path(path: str) -> Dict[str, str]:
+        """Parses a user path into its component segments."""
+        m = re.match(
+            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/clusters/(?P<cluster>.+?)/users/(?P<user>.+?)$",
+            path,
+        )
+        return m.groupdict() if m else {}
+
+    @staticmethod
     def common_billing_account_path(
         billing_account: str,
     ) -> str:
         """Returns a fully-qualified billing_account string."""
         return "billingAccounts/{billing_account}".format(
             billing_account=billing_account,
         )
@@ -840,16 +864,16 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Union[google.cloud.alloydb_v1.types.CreateClusterRequest, dict]):
                 The request object. Message for creating a Cluster
             parent (str):
-                Required. The name of the parent
-                resource. For the required format, see
+                Required. The location of the new
+                cluster. For the required format, see
                 the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (google.cloud.alloydb_v1.types.Cluster):
                 Required. The resource being created
@@ -1188,14 +1212,135 @@
             empty_pb2.Empty,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    def promote_cluster(
+        self,
+        request: Optional[Union[service.PromoteClusterRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation.Operation:
+        r"""Promotes a SECONDARY cluster. This turns down
+        replication from the PRIMARY cluster and promotes a
+        secondary cluster into its own standalone cluster.
+        Imperative only.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            def sample_promote_cluster():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.PromoteClusterRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                operation = client.promote_cluster(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = operation.result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1.types.PromoteClusterRequest, dict]):
+                The request object. Message for promoting a Cluster
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the Cluster.name field
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation.Operation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1.types.Cluster` A cluster is a collection of regional AlloyDB resources. It can include a
+                   primary instance and one or more read pool instances.
+                   All cluster resources share a storage layer, which
+                   scales as needed.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.PromoteClusterRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.PromoteClusterRequest):
+            request = service.PromoteClusterRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.promote_cluster]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation.from_gapic(
+            response,
+            self._transport.operations_client,
+            resources.Cluster,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     def restore_cluster(
         self,
         request: Optional[Union[service.RestoreClusterRequest, dict]] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
@@ -1299,14 +1444,160 @@
             resources.Cluster,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    def create_secondary_cluster(
+        self,
+        request: Optional[Union[service.CreateSecondaryClusterRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        cluster: Optional[resources.Cluster] = None,
+        cluster_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation.Operation:
+        r"""Creates a cluster of type SECONDARY in the given
+        location using the primary cluster as the source.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            def sample_create_secondary_cluster():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                cluster = alloydb_v1.Cluster()
+                cluster.backup_source.backup_name = "backup_name_value"
+                cluster.network = "network_value"
+
+                request = alloydb_v1.CreateSecondaryClusterRequest(
+                    parent="parent_value",
+                    cluster_id="cluster_id_value",
+                    cluster=cluster,
+                )
+
+                # Make the request
+                operation = client.create_secondary_cluster(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = operation.result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1.types.CreateSecondaryClusterRequest, dict]):
+                The request object.
+            parent (str):
+                Required. The location of the new
+                cluster. For the required format, see
+                the comment on the Cluster.name field.
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            cluster (google.cloud.alloydb_v1.types.Cluster):
+                Required. Configuration of the
+                requesting object (the secondary
+                cluster).
+
+                This corresponds to the ``cluster`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            cluster_id (str):
+                Required. ID of the requesting object
+                (the secondary cluster).
+
+                This corresponds to the ``cluster_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation.Operation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1.types.Cluster` A cluster is a collection of regional AlloyDB resources. It can include a
+                   primary instance and one or more read pool instances.
+                   All cluster resources share a storage layer, which
+                   scales as needed.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, cluster, cluster_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.CreateSecondaryClusterRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.CreateSecondaryClusterRequest):
+            request = service.CreateSecondaryClusterRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+            if cluster is not None:
+                request.cluster = cluster
+            if cluster_id is not None:
+                request.cluster_id = cluster_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.create_secondary_cluster]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation.from_gapic(
+            response,
+            self._transport.operations_client,
+            resources.Cluster,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     def list_instances(
         self,
         request: Optional[Union[service.ListInstancesRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -1664,14 +1955,157 @@
             resources.Instance,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    def create_secondary_instance(
+        self,
+        request: Optional[Union[service.CreateSecondaryInstanceRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        instance: Optional[resources.Instance] = None,
+        instance_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation.Operation:
+        r"""Creates a new SECONDARY Instance in a given project
+        and location.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            def sample_create_secondary_instance():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                instance = alloydb_v1.Instance()
+                instance.instance_type = "SECONDARY"
+
+                request = alloydb_v1.CreateSecondaryInstanceRequest(
+                    parent="parent_value",
+                    instance_id="instance_id_value",
+                    instance=instance,
+                )
+
+                # Make the request
+                operation = client.create_secondary_instance(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = operation.result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1.types.CreateSecondaryInstanceRequest, dict]):
+                The request object. Message for creating a Secondary
+                Instance
+            parent (str):
+                Required. The name of the parent
+                resource. For the required format, see
+                the comment on the Instance.name field.
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            instance (google.cloud.alloydb_v1.types.Instance):
+                Required. The resource being created
+                This corresponds to the ``instance`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            instance_id (str):
+                Required. ID of the requesting
+                object.
+
+                This corresponds to the ``instance_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation.Operation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1.types.Instance` An Instance is a computing unit that an end customer can connect to.
+                   It's the main unit of computing resources in AlloyDB.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, instance, instance_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.CreateSecondaryInstanceRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.CreateSecondaryInstanceRequest):
+            request = service.CreateSecondaryInstanceRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+            if instance is not None:
+                request.instance = instance
+            if instance_id is not None:
+                request.instance_id = instance_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[
+            self._transport.create_secondary_instance
+        ]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation.from_gapic(
+            response,
+            self._transport.operations_client,
+            resources.Instance,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     def batch_create_instances(
         self,
         request: Optional[Union[service.BatchCreateInstancesRequest, dict]] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
@@ -2153,14 +2587,143 @@
             resources.Instance,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    def inject_fault(
+        self,
+        request: Optional[Union[service.InjectFaultRequest, dict]] = None,
+        *,
+        fault_type: Optional[service.InjectFaultRequest.FaultType] = None,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation.Operation:
+        r"""Injects fault in an instance.
+        Imperative only.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            def sample_inject_fault():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.InjectFaultRequest(
+                    fault_type="STOP_VM",
+                    name="name_value",
+                )
+
+                # Make the request
+                operation = client.inject_fault(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = operation.result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1.types.InjectFaultRequest, dict]):
+                The request object. Message for triggering fault
+                injection on an instance
+            fault_type (google.cloud.alloydb_v1.types.InjectFaultRequest.FaultType):
+                Required. The type of fault to be
+                injected in an instance.
+
+                This corresponds to the ``fault_type`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the Instance.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation.Operation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1.types.Instance` An Instance is a computing unit that an end customer can connect to.
+                   It's the main unit of computing resources in AlloyDB.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([fault_type, name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.InjectFaultRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.InjectFaultRequest):
+            request = service.InjectFaultRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if fault_type is not None:
+                request.fault_type = fault_type
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.inject_fault]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation.from_gapic(
+            response,
+            self._transport.operations_client,
+            resources.Instance,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     def restart_instance(
         self,
         request: Optional[Union[service.RestartInstanceRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -3003,14 +3566,546 @@
             response=response,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
+    def list_users(
+        self,
+        request: Optional[Union[service.ListUsersRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> pagers.ListUsersPager:
+        r"""Lists Users in a given project and location.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            def sample_list_users():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.ListUsersRequest(
+                    parent="parent_value",
+                )
+
+                # Make the request
+                page_result = client.list_users(request=request)
+
+                # Handle the response
+                for response in page_result:
+                    print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1.types.ListUsersRequest, dict]):
+                The request object. Message for requesting list of Users
+            parent (str):
+                Required. Parent value for
+                ListUsersRequest
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1.services.alloy_db_admin.pagers.ListUsersPager:
+                Message for response to listing Users
+                Iterating over this object will yield
+                results and resolve additional pages
+                automatically.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.ListUsersRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.ListUsersRequest):
+            request = service.ListUsersRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.list_users]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # This method is paged; wrap the response in a pager, which provides
+        # an `__iter__` convenience method.
+        response = pagers.ListUsersPager(
+            method=rpc,
+            request=request,
+            response=response,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def get_user(
+        self,
+        request: Optional[Union[service.GetUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Gets details of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            def sample_get_user():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.GetUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                response = client.get_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1.types.GetUserRequest, dict]):
+                The request object. Message for getting a User
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.GetUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.GetUserRequest):
+            request = service.GetUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.get_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def create_user(
+        self,
+        request: Optional[Union[service.CreateUserRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        user: Optional[resources.User] = None,
+        user_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Creates a new User in a given project, location, and
+        cluster.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            def sample_create_user():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.CreateUserRequest(
+                    parent="parent_value",
+                    user_id="user_id_value",
+                )
+
+                # Make the request
+                response = client.create_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1.types.CreateUserRequest, dict]):
+                The request object. Message for creating a User
+            parent (str):
+                Required. Value for parent.
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user (google.cloud.alloydb_v1.types.User):
+                Required. The resource being created
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user_id (str):
+                Required. ID of the requesting
+                object.
+
+                This corresponds to the ``user_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, user, user_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.CreateUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.CreateUserRequest):
+            request = service.CreateUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+            if user is not None:
+                request.user = user
+            if user_id is not None:
+                request.user_id = user_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.create_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def update_user(
+        self,
+        request: Optional[Union[service.UpdateUserRequest, dict]] = None,
+        *,
+        user: Optional[resources.User] = None,
+        update_mask: Optional[field_mask_pb2.FieldMask] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Updates the parameters of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            def sample_update_user():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.UpdateUserRequest(
+                )
+
+                # Make the request
+                response = client.update_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1.types.UpdateUserRequest, dict]):
+                The request object. Message for updating a User
+            user (google.cloud.alloydb_v1.types.User):
+                Required. The resource being updated
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            update_mask (google.protobuf.field_mask_pb2.FieldMask):
+                Optional. Field mask is used to specify the fields to be
+                overwritten in the User resource by the update. The
+                fields specified in the update_mask are relative to the
+                resource, not the full request. A field will be
+                overwritten if it is in the mask. If the user does not
+                provide a mask then all fields will be overwritten.
+
+                This corresponds to the ``update_mask`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([user, update_mask])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.UpdateUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.UpdateUserRequest):
+            request = service.UpdateUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if user is not None:
+                request.user = user
+            if update_mask is not None:
+                request.update_mask = update_mask
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.update_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata(
+                (("user.name", request.user.name),)
+            ),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def delete_user(
+        self,
+        request: Optional[Union[service.DeleteUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> None:
+        r"""Deletes a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1
+
+            def sample_delete_user():
+                # Create a client
+                client = alloydb_v1.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1.DeleteUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                client.delete_user(request=request)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1.types.DeleteUserRequest, dict]):
+                The request object. Message for deleting a User
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.DeleteUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.DeleteUserRequest):
+            request = service.DeleteUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.delete_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
     def __enter__(self) -> "AlloyDBAdminClient":
         return self
 
     def __exit__(self, type, value, traceback):
         """Releases underlying transport's resources.
 
         .. warning::
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/pagers.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/pagers.py`

 * *Files 9% similar despite different names*

```diff
@@ -533,7 +533,135 @@
                 for response in page.supported_database_flags:
                     yield response
 
         return async_generator()
 
     def __repr__(self) -> str:
         return "{0}<{1!r}>".format(self.__class__.__name__, self._response)
+
+
+class ListUsersPager:
+    """A pager for iterating through ``list_users`` requests.
+
+    This class thinly wraps an initial
+    :class:`google.cloud.alloydb_v1.types.ListUsersResponse` object, and
+    provides an ``__iter__`` method to iterate through its
+    ``users`` field.
+
+    If there are more pages, the ``__iter__`` method will make additional
+    ``ListUsers`` requests and continue to iterate
+    through the ``users`` field on the
+    corresponding responses.
+
+    All the usual :class:`google.cloud.alloydb_v1.types.ListUsersResponse`
+    attributes are available on the pager. If multiple requests are made, only
+    the most recent response is retained, and thus used for attribute lookup.
+    """
+
+    def __init__(
+        self,
+        method: Callable[..., service.ListUsersResponse],
+        request: service.ListUsersRequest,
+        response: service.ListUsersResponse,
+        *,
+        metadata: Sequence[Tuple[str, str]] = ()
+    ):
+        """Instantiate the pager.
+
+        Args:
+            method (Callable): The method that was originally called, and
+                which instantiated this pager.
+            request (google.cloud.alloydb_v1.types.ListUsersRequest):
+                The initial request object.
+            response (google.cloud.alloydb_v1.types.ListUsersResponse):
+                The initial response object.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        self._method = method
+        self._request = service.ListUsersRequest(request)
+        self._response = response
+        self._metadata = metadata
+
+    def __getattr__(self, name: str) -> Any:
+        return getattr(self._response, name)
+
+    @property
+    def pages(self) -> Iterator[service.ListUsersResponse]:
+        yield self._response
+        while self._response.next_page_token:
+            self._request.page_token = self._response.next_page_token
+            self._response = self._method(self._request, metadata=self._metadata)
+            yield self._response
+
+    def __iter__(self) -> Iterator[resources.User]:
+        for page in self.pages:
+            yield from page.users
+
+    def __repr__(self) -> str:
+        return "{0}<{1!r}>".format(self.__class__.__name__, self._response)
+
+
+class ListUsersAsyncPager:
+    """A pager for iterating through ``list_users`` requests.
+
+    This class thinly wraps an initial
+    :class:`google.cloud.alloydb_v1.types.ListUsersResponse` object, and
+    provides an ``__aiter__`` method to iterate through its
+    ``users`` field.
+
+    If there are more pages, the ``__aiter__`` method will make additional
+    ``ListUsers`` requests and continue to iterate
+    through the ``users`` field on the
+    corresponding responses.
+
+    All the usual :class:`google.cloud.alloydb_v1.types.ListUsersResponse`
+    attributes are available on the pager. If multiple requests are made, only
+    the most recent response is retained, and thus used for attribute lookup.
+    """
+
+    def __init__(
+        self,
+        method: Callable[..., Awaitable[service.ListUsersResponse]],
+        request: service.ListUsersRequest,
+        response: service.ListUsersResponse,
+        *,
+        metadata: Sequence[Tuple[str, str]] = ()
+    ):
+        """Instantiates the pager.
+
+        Args:
+            method (Callable): The method that was originally called, and
+                which instantiated this pager.
+            request (google.cloud.alloydb_v1.types.ListUsersRequest):
+                The initial request object.
+            response (google.cloud.alloydb_v1.types.ListUsersResponse):
+                The initial response object.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        self._method = method
+        self._request = service.ListUsersRequest(request)
+        self._response = response
+        self._metadata = metadata
+
+    def __getattr__(self, name: str) -> Any:
+        return getattr(self._response, name)
+
+    @property
+    async def pages(self) -> AsyncIterator[service.ListUsersResponse]:
+        yield self._response
+        while self._response.next_page_token:
+            self._request.page_token = self._response.next_page_token
+            self._response = await self._method(self._request, metadata=self._metadata)
+            yield self._response
+
+    def __aiter__(self) -> AsyncIterator[resources.User]:
+        async def async_generator():
+            async for page in self.pages:
+                for response in page.users:
+                    yield response
+
+        return async_generator()
+
+    def __repr__(self) -> str:
+        return "{0}<{1!r}>".format(self.__class__.__name__, self._response)
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/base.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/base.py`

 * *Files 11% similar despite different names*

```diff
@@ -23,14 +23,15 @@
 import google.auth  # type: ignore
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 from google.oauth2 import service_account  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 
 from google.cloud.alloydb_v1 import gapic_version as package_version
 from google.cloud.alloydb_v1.types import resources, service
 
 DEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(
     gapic_version=package_version.__version__
 )
@@ -165,19 +166,29 @@
                 client_info=client_info,
             ),
             self.delete_cluster: gapic_v1.method.wrap_method(
                 self.delete_cluster,
                 default_timeout=None,
                 client_info=client_info,
             ),
+            self.promote_cluster: gapic_v1.method.wrap_method(
+                self.promote_cluster,
+                default_timeout=None,
+                client_info=client_info,
+            ),
             self.restore_cluster: gapic_v1.method.wrap_method(
                 self.restore_cluster,
                 default_timeout=None,
                 client_info=client_info,
             ),
+            self.create_secondary_cluster: gapic_v1.method.wrap_method(
+                self.create_secondary_cluster,
+                default_timeout=None,
+                client_info=client_info,
+            ),
             self.list_instances: gapic_v1.method.wrap_method(
                 self.list_instances,
                 default_retry=retries.Retry(
                     initial=1.0,
                     maximum=60.0,
                     multiplier=1.3,
                     predicate=retries.if_exception_type(
@@ -203,14 +214,19 @@
                 client_info=client_info,
             ),
             self.create_instance: gapic_v1.method.wrap_method(
                 self.create_instance,
                 default_timeout=None,
                 client_info=client_info,
             ),
+            self.create_secondary_instance: gapic_v1.method.wrap_method(
+                self.create_secondary_instance,
+                default_timeout=None,
+                client_info=client_info,
+            ),
             self.batch_create_instances: gapic_v1.method.wrap_method(
                 self.batch_create_instances,
                 default_timeout=None,
                 client_info=client_info,
             ),
             self.update_instance: gapic_v1.method.wrap_method(
                 self.update_instance,
@@ -223,14 +239,19 @@
                 client_info=client_info,
             ),
             self.failover_instance: gapic_v1.method.wrap_method(
                 self.failover_instance,
                 default_timeout=None,
                 client_info=client_info,
             ),
+            self.inject_fault: gapic_v1.method.wrap_method(
+                self.inject_fault,
+                default_timeout=None,
+                client_info=client_info,
+            ),
             self.restart_instance: gapic_v1.method.wrap_method(
                 self.restart_instance,
                 default_timeout=None,
                 client_info=client_info,
             ),
             self.list_backups: gapic_v1.method.wrap_method(
                 self.list_backups,
@@ -285,14 +306,39 @@
                         core_exceptions.ServiceUnavailable,
                     ),
                     deadline=60.0,
                 ),
                 default_timeout=60.0,
                 client_info=client_info,
             ),
+            self.list_users: gapic_v1.method.wrap_method(
+                self.list_users,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.get_user: gapic_v1.method.wrap_method(
+                self.get_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.create_user: gapic_v1.method.wrap_method(
+                self.create_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.update_user: gapic_v1.method.wrap_method(
+                self.update_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.delete_user: gapic_v1.method.wrap_method(
+                self.delete_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
         }
 
     def close(self):
         """Closes resources associated with the transport.
 
         .. warning::
              Only call this method if the transport is NOT shared
@@ -347,23 +393,41 @@
     ) -> Callable[
         [service.DeleteClusterRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
 
     @property
+    def promote_cluster(
+        self,
+    ) -> Callable[
+        [service.PromoteClusterRequest],
+        Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
+    ]:
+        raise NotImplementedError()
+
+    @property
     def restore_cluster(
         self,
     ) -> Callable[
         [service.RestoreClusterRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
 
     @property
+    def create_secondary_cluster(
+        self,
+    ) -> Callable[
+        [service.CreateSecondaryClusterRequest],
+        Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
+    ]:
+        raise NotImplementedError()
+
+    @property
     def list_instances(
         self,
     ) -> Callable[
         [service.ListInstancesRequest],
         Union[service.ListInstancesResponse, Awaitable[service.ListInstancesResponse]],
     ]:
         raise NotImplementedError()
@@ -383,14 +447,23 @@
     ) -> Callable[
         [service.CreateInstanceRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
 
     @property
+    def create_secondary_instance(
+        self,
+    ) -> Callable[
+        [service.CreateSecondaryInstanceRequest],
+        Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
+    ]:
+        raise NotImplementedError()
+
+    @property
     def batch_create_instances(
         self,
     ) -> Callable[
         [service.BatchCreateInstancesRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
@@ -419,14 +492,23 @@
     ) -> Callable[
         [service.FailoverInstanceRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
 
     @property
+    def inject_fault(
+        self,
+    ) -> Callable[
+        [service.InjectFaultRequest],
+        Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
+    ]:
+        raise NotImplementedError()
+
+    @property
     def restart_instance(
         self,
     ) -> Callable[
         [service.RestartInstanceRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
@@ -484,14 +566,55 @@
             service.ListSupportedDatabaseFlagsResponse,
             Awaitable[service.ListSupportedDatabaseFlagsResponse],
         ],
     ]:
         raise NotImplementedError()
 
     @property
+    def list_users(
+        self,
+    ) -> Callable[
+        [service.ListUsersRequest],
+        Union[service.ListUsersResponse, Awaitable[service.ListUsersResponse]],
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def get_user(
+        self,
+    ) -> Callable[
+        [service.GetUserRequest], Union[resources.User, Awaitable[resources.User]]
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def create_user(
+        self,
+    ) -> Callable[
+        [service.CreateUserRequest], Union[resources.User, Awaitable[resources.User]]
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def update_user(
+        self,
+    ) -> Callable[
+        [service.UpdateUserRequest], Union[resources.User, Awaitable[resources.User]]
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def delete_user(
+        self,
+    ) -> Callable[
+        [service.DeleteUserRequest], Union[empty_pb2.Empty, Awaitable[empty_pb2.Empty]]
+    ]:
+        raise NotImplementedError()
+
+    @property
     def list_operations(
         self,
     ) -> Callable[
         [operations_pb2.ListOperationsRequest],
         Union[
             operations_pb2.ListOperationsResponse,
             Awaitable[operations_pb2.ListOperationsResponse],
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/grpc.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/grpc.py`

 * *Files 12% similar despite different names*

```diff
@@ -20,14 +20,15 @@
 import google.auth  # type: ignore
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 import grpc  # type: ignore
 
 from google.cloud.alloydb_v1.types import resources, service
 
 from .base import DEFAULT_CLIENT_INFO, AlloyDBAdminTransport
 
 
@@ -373,14 +374,43 @@
                 "/google.cloud.alloydb.v1.AlloyDBAdmin/DeleteCluster",
                 request_serializer=service.DeleteClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_cluster"]
 
     @property
+    def promote_cluster(
+        self,
+    ) -> Callable[[service.PromoteClusterRequest], operations_pb2.Operation]:
+        r"""Return a callable for the promote cluster method over gRPC.
+
+        Promotes a SECONDARY cluster. This turns down
+        replication from the PRIMARY cluster and promotes a
+        secondary cluster into its own standalone cluster.
+        Imperative only.
+
+        Returns:
+            Callable[[~.PromoteClusterRequest],
+                    ~.Operation]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "promote_cluster" not in self._stubs:
+            self._stubs["promote_cluster"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/PromoteCluster",
+                request_serializer=service.PromoteClusterRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["promote_cluster"]
+
+    @property
     def restore_cluster(
         self,
     ) -> Callable[[service.RestoreClusterRequest], operations_pb2.Operation]:
         r"""Return a callable for the restore cluster method over gRPC.
 
         Creates a new Cluster in a given project and
         location, with a volume restored from the provided
@@ -402,14 +432,41 @@
                 "/google.cloud.alloydb.v1.AlloyDBAdmin/RestoreCluster",
                 request_serializer=service.RestoreClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["restore_cluster"]
 
     @property
+    def create_secondary_cluster(
+        self,
+    ) -> Callable[[service.CreateSecondaryClusterRequest], operations_pb2.Operation]:
+        r"""Return a callable for the create secondary cluster method over gRPC.
+
+        Creates a cluster of type SECONDARY in the given
+        location using the primary cluster as the source.
+
+        Returns:
+            Callable[[~.CreateSecondaryClusterRequest],
+                    ~.Operation]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_secondary_cluster" not in self._stubs:
+            self._stubs["create_secondary_cluster"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateSecondaryCluster",
+                request_serializer=service.CreateSecondaryClusterRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["create_secondary_cluster"]
+
+    @property
     def list_instances(
         self,
     ) -> Callable[[service.ListInstancesRequest], service.ListInstancesResponse]:
         r"""Return a callable for the list instances method over gRPC.
 
         Lists Instances in a given project and location.
 
@@ -481,14 +538,41 @@
                 "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateInstance",
                 request_serializer=service.CreateInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_instance"]
 
     @property
+    def create_secondary_instance(
+        self,
+    ) -> Callable[[service.CreateSecondaryInstanceRequest], operations_pb2.Operation]:
+        r"""Return a callable for the create secondary instance method over gRPC.
+
+        Creates a new SECONDARY Instance in a given project
+        and location.
+
+        Returns:
+            Callable[[~.CreateSecondaryInstanceRequest],
+                    ~.Operation]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_secondary_instance" not in self._stubs:
+            self._stubs["create_secondary_instance"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateSecondaryInstance",
+                request_serializer=service.CreateSecondaryInstanceRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["create_secondary_instance"]
+
+    @property
     def batch_create_instances(
         self,
     ) -> Callable[[service.BatchCreateInstancesRequest], operations_pb2.Operation]:
         r"""Return a callable for the batch create instances method over gRPC.
 
         Creates new instances under the given project,
         location and cluster. There can be only one primary
@@ -599,14 +683,41 @@
                 "/google.cloud.alloydb.v1.AlloyDBAdmin/FailoverInstance",
                 request_serializer=service.FailoverInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["failover_instance"]
 
     @property
+    def inject_fault(
+        self,
+    ) -> Callable[[service.InjectFaultRequest], operations_pb2.Operation]:
+        r"""Return a callable for the inject fault method over gRPC.
+
+        Injects fault in an instance.
+        Imperative only.
+
+        Returns:
+            Callable[[~.InjectFaultRequest],
+                    ~.Operation]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "inject_fault" not in self._stubs:
+            self._stubs["inject_fault"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/InjectFault",
+                request_serializer=service.InjectFaultRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["inject_fault"]
+
+    @property
     def restart_instance(
         self,
     ) -> Callable[[service.RestartInstanceRequest], operations_pb2.Operation]:
         r"""Return a callable for the restart instance method over gRPC.
 
         Restart an Instance in a cluster.
         Imperative only.
@@ -785,14 +896,137 @@
             ] = self.grpc_channel.unary_unary(
                 "/google.cloud.alloydb.v1.AlloyDBAdmin/ListSupportedDatabaseFlags",
                 request_serializer=service.ListSupportedDatabaseFlagsRequest.serialize,
                 response_deserializer=service.ListSupportedDatabaseFlagsResponse.deserialize,
             )
         return self._stubs["list_supported_database_flags"]
 
+    @property
+    def list_users(
+        self,
+    ) -> Callable[[service.ListUsersRequest], service.ListUsersResponse]:
+        r"""Return a callable for the list users method over gRPC.
+
+        Lists Users in a given project and location.
+
+        Returns:
+            Callable[[~.ListUsersRequest],
+                    ~.ListUsersResponse]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "list_users" not in self._stubs:
+            self._stubs["list_users"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListUsers",
+                request_serializer=service.ListUsersRequest.serialize,
+                response_deserializer=service.ListUsersResponse.deserialize,
+            )
+        return self._stubs["list_users"]
+
+    @property
+    def get_user(self) -> Callable[[service.GetUserRequest], resources.User]:
+        r"""Return a callable for the get user method over gRPC.
+
+        Gets details of a single User.
+
+        Returns:
+            Callable[[~.GetUserRequest],
+                    ~.User]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "get_user" not in self._stubs:
+            self._stubs["get_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/GetUser",
+                request_serializer=service.GetUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["get_user"]
+
+    @property
+    def create_user(self) -> Callable[[service.CreateUserRequest], resources.User]:
+        r"""Return a callable for the create user method over gRPC.
+
+        Creates a new User in a given project, location, and
+        cluster.
+
+        Returns:
+            Callable[[~.CreateUserRequest],
+                    ~.User]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_user" not in self._stubs:
+            self._stubs["create_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateUser",
+                request_serializer=service.CreateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["create_user"]
+
+    @property
+    def update_user(self) -> Callable[[service.UpdateUserRequest], resources.User]:
+        r"""Return a callable for the update user method over gRPC.
+
+        Updates the parameters of a single User.
+
+        Returns:
+            Callable[[~.UpdateUserRequest],
+                    ~.User]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "update_user" not in self._stubs:
+            self._stubs["update_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/UpdateUser",
+                request_serializer=service.UpdateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["update_user"]
+
+    @property
+    def delete_user(self) -> Callable[[service.DeleteUserRequest], empty_pb2.Empty]:
+        r"""Return a callable for the delete user method over gRPC.
+
+        Deletes a single User.
+
+        Returns:
+            Callable[[~.DeleteUserRequest],
+                    ~.Empty]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "delete_user" not in self._stubs:
+            self._stubs["delete_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/DeleteUser",
+                request_serializer=service.DeleteUserRequest.serialize,
+                response_deserializer=empty_pb2.Empty.FromString,
+            )
+        return self._stubs["delete_user"]
+
     def close(self):
         self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/grpc_asyncio.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/grpc_asyncio.py`

 * *Files 13% similar despite different names*

```diff
@@ -19,18 +19,19 @@
 from google.api_core import gapic_v1, grpc_helpers_async, operations_v1
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 import grpc  # type: ignore
 from grpc.experimental import aio  # type: ignore
 
-from google.cloud.alloydb_v1.types import resources, service
+from google.cloud.alloydb_v1alpha.types import resources, service
 
 from .base import DEFAULT_CLIENT_INFO, AlloyDBAdminTransport
 from .grpc import AlloyDBAdminGrpcTransport
 
 
 class AlloyDBAdminGrpcAsyncIOTransport(AlloyDBAdminTransport):
     """gRPC AsyncIO backend transport for AlloyDBAdmin.
@@ -270,15 +271,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_clusters" not in self._stubs:
             self._stubs["list_clusters"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListClusters",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListClusters",
                 request_serializer=service.ListClustersRequest.serialize,
                 response_deserializer=service.ListClustersResponse.deserialize,
             )
         return self._stubs["list_clusters"]
 
     @property
     def get_cluster(
@@ -296,15 +297,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_cluster" not in self._stubs:
             self._stubs["get_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/GetCluster",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetCluster",
                 request_serializer=service.GetClusterRequest.serialize,
                 response_deserializer=resources.Cluster.deserialize,
             )
         return self._stubs["get_cluster"]
 
     @property
     def create_cluster(
@@ -323,15 +324,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_cluster" not in self._stubs:
             self._stubs["create_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateCluster",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateCluster",
                 request_serializer=service.CreateClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_cluster"]
 
     @property
     def update_cluster(
@@ -349,15 +350,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "update_cluster" not in self._stubs:
             self._stubs["update_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/UpdateCluster",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/UpdateCluster",
                 request_serializer=service.UpdateClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_cluster"]
 
     @property
     def delete_cluster(
@@ -375,21 +376,50 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "delete_cluster" not in self._stubs:
             self._stubs["delete_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/DeleteCluster",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/DeleteCluster",
                 request_serializer=service.DeleteClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_cluster"]
 
     @property
+    def promote_cluster(
+        self,
+    ) -> Callable[[service.PromoteClusterRequest], Awaitable[operations_pb2.Operation]]:
+        r"""Return a callable for the promote cluster method over gRPC.
+
+        Promotes a SECONDARY cluster. This turns down
+        replication from the PRIMARY cluster and promotes a
+        secondary cluster into its own standalone cluster.
+        Imperative only.
+
+        Returns:
+            Callable[[~.PromoteClusterRequest],
+                    Awaitable[~.Operation]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "promote_cluster" not in self._stubs:
+            self._stubs["promote_cluster"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/PromoteCluster",
+                request_serializer=service.PromoteClusterRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["promote_cluster"]
+
+    @property
     def restore_cluster(
         self,
     ) -> Callable[[service.RestoreClusterRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the restore cluster method over gRPC.
 
         Creates a new Cluster in a given project and
         location, with a volume restored from the provided
@@ -404,21 +434,50 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "restore_cluster" not in self._stubs:
             self._stubs["restore_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/RestoreCluster",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/RestoreCluster",
                 request_serializer=service.RestoreClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["restore_cluster"]
 
     @property
+    def create_secondary_cluster(
+        self,
+    ) -> Callable[
+        [service.CreateSecondaryClusterRequest], Awaitable[operations_pb2.Operation]
+    ]:
+        r"""Return a callable for the create secondary cluster method over gRPC.
+
+        Creates a cluster of type SECONDARY in the given
+        location using the primary cluster as the source.
+
+        Returns:
+            Callable[[~.CreateSecondaryClusterRequest],
+                    Awaitable[~.Operation]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_secondary_cluster" not in self._stubs:
+            self._stubs["create_secondary_cluster"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateSecondaryCluster",
+                request_serializer=service.CreateSecondaryClusterRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["create_secondary_cluster"]
+
+    @property
     def list_instances(
         self,
     ) -> Callable[
         [service.ListInstancesRequest], Awaitable[service.ListInstancesResponse]
     ]:
         r"""Return a callable for the list instances method over gRPC.
 
@@ -432,15 +491,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_instances" not in self._stubs:
             self._stubs["list_instances"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListInstances",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListInstances",
                 request_serializer=service.ListInstancesRequest.serialize,
                 response_deserializer=service.ListInstancesResponse.deserialize,
             )
         return self._stubs["list_instances"]
 
     @property
     def get_instance(
@@ -458,15 +517,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_instance" not in self._stubs:
             self._stubs["get_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/GetInstance",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetInstance",
                 request_serializer=service.GetInstanceRequest.serialize,
                 response_deserializer=resources.Instance.deserialize,
             )
         return self._stubs["get_instance"]
 
     @property
     def create_instance(
@@ -485,21 +544,50 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_instance" not in self._stubs:
             self._stubs["create_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateInstance",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateInstance",
                 request_serializer=service.CreateInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_instance"]
 
     @property
+    def create_secondary_instance(
+        self,
+    ) -> Callable[
+        [service.CreateSecondaryInstanceRequest], Awaitable[operations_pb2.Operation]
+    ]:
+        r"""Return a callable for the create secondary instance method over gRPC.
+
+        Creates a new SECONDARY Instance in a given project
+        and location.
+
+        Returns:
+            Callable[[~.CreateSecondaryInstanceRequest],
+                    Awaitable[~.Operation]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_secondary_instance" not in self._stubs:
+            self._stubs["create_secondary_instance"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateSecondaryInstance",
+                request_serializer=service.CreateSecondaryInstanceRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["create_secondary_instance"]
+
+    @property
     def batch_create_instances(
         self,
     ) -> Callable[
         [service.BatchCreateInstancesRequest], Awaitable[operations_pb2.Operation]
     ]:
         r"""Return a callable for the batch create instances method over gRPC.
 
@@ -525,15 +613,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "batch_create_instances" not in self._stubs:
             self._stubs["batch_create_instances"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/BatchCreateInstances",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/BatchCreateInstances",
                 request_serializer=service.BatchCreateInstancesRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["batch_create_instances"]
 
     @property
     def update_instance(
@@ -551,15 +639,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "update_instance" not in self._stubs:
             self._stubs["update_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/UpdateInstance",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/UpdateInstance",
                 request_serializer=service.UpdateInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_instance"]
 
     @property
     def delete_instance(
@@ -577,15 +665,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "delete_instance" not in self._stubs:
             self._stubs["delete_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/DeleteInstance",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/DeleteInstance",
                 request_serializer=service.DeleteInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_instance"]
 
     @property
     def failover_instance(
@@ -607,21 +695,48 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "failover_instance" not in self._stubs:
             self._stubs["failover_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/FailoverInstance",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/FailoverInstance",
                 request_serializer=service.FailoverInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["failover_instance"]
 
     @property
+    def inject_fault(
+        self,
+    ) -> Callable[[service.InjectFaultRequest], Awaitable[operations_pb2.Operation]]:
+        r"""Return a callable for the inject fault method over gRPC.
+
+        Injects fault in an instance.
+        Imperative only.
+
+        Returns:
+            Callable[[~.InjectFaultRequest],
+                    Awaitable[~.Operation]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "inject_fault" not in self._stubs:
+            self._stubs["inject_fault"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/InjectFault",
+                request_serializer=service.InjectFaultRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["inject_fault"]
+
+    @property
     def restart_instance(
         self,
     ) -> Callable[
         [service.RestartInstanceRequest], Awaitable[operations_pb2.Operation]
     ]:
         r"""Return a callable for the restart instance method over gRPC.
 
@@ -636,15 +751,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "restart_instance" not in self._stubs:
             self._stubs["restart_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/RestartInstance",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/RestartInstance",
                 request_serializer=service.RestartInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["restart_instance"]
 
     @property
     def list_backups(
@@ -662,15 +777,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_backups" not in self._stubs:
             self._stubs["list_backups"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListBackups",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListBackups",
                 request_serializer=service.ListBackupsRequest.serialize,
                 response_deserializer=service.ListBackupsResponse.deserialize,
             )
         return self._stubs["list_backups"]
 
     @property
     def get_backup(
@@ -688,15 +803,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_backup" not in self._stubs:
             self._stubs["get_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/GetBackup",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetBackup",
                 request_serializer=service.GetBackupRequest.serialize,
                 response_deserializer=resources.Backup.deserialize,
             )
         return self._stubs["get_backup"]
 
     @property
     def create_backup(
@@ -714,15 +829,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_backup" not in self._stubs:
             self._stubs["create_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateBackup",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateBackup",
                 request_serializer=service.CreateBackupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_backup"]
 
     @property
     def update_backup(
@@ -740,15 +855,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "update_backup" not in self._stubs:
             self._stubs["update_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/UpdateBackup",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/UpdateBackup",
                 request_serializer=service.UpdateBackupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_backup"]
 
     @property
     def delete_backup(
@@ -766,15 +881,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "delete_backup" not in self._stubs:
             self._stubs["delete_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/DeleteBackup",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/DeleteBackup",
                 request_serializer=service.DeleteBackupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_backup"]
 
     @property
     def list_supported_database_flags(
@@ -798,20 +913,211 @@
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_supported_database_flags" not in self._stubs:
             self._stubs[
                 "list_supported_database_flags"
             ] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListSupportedDatabaseFlags",
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListSupportedDatabaseFlags",
                 request_serializer=service.ListSupportedDatabaseFlagsRequest.serialize,
                 response_deserializer=service.ListSupportedDatabaseFlagsResponse.deserialize,
             )
         return self._stubs["list_supported_database_flags"]
 
+    @property
+    def generate_client_certificate(
+        self,
+    ) -> Callable[
+        [service.GenerateClientCertificateRequest],
+        Awaitable[service.GenerateClientCertificateResponse],
+    ]:
+        r"""Return a callable for the generate client certificate method over gRPC.
+
+        Generate a client certificate signed by a Cluster CA.
+        The sole purpose of this endpoint is to support the Auth
+        Proxy client and the endpoint's behavior is subject to
+        change without notice, so do not rely on its behavior
+        remaining constant. Future changes will not break the
+        Auth Proxy client.
+
+        Returns:
+            Callable[[~.GenerateClientCertificateRequest],
+                    Awaitable[~.GenerateClientCertificateResponse]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "generate_client_certificate" not in self._stubs:
+            self._stubs["generate_client_certificate"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GenerateClientCertificate",
+                request_serializer=service.GenerateClientCertificateRequest.serialize,
+                response_deserializer=service.GenerateClientCertificateResponse.deserialize,
+            )
+        return self._stubs["generate_client_certificate"]
+
+    @property
+    def get_connection_info(
+        self,
+    ) -> Callable[
+        [service.GetConnectionInfoRequest], Awaitable[resources.ConnectionInfo]
+    ]:
+        r"""Return a callable for the get connection info method over gRPC.
+
+        Get instance metadata used for a connection.
+
+        Returns:
+            Callable[[~.GetConnectionInfoRequest],
+                    Awaitable[~.ConnectionInfo]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "get_connection_info" not in self._stubs:
+            self._stubs["get_connection_info"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetConnectionInfo",
+                request_serializer=service.GetConnectionInfoRequest.serialize,
+                response_deserializer=resources.ConnectionInfo.deserialize,
+            )
+        return self._stubs["get_connection_info"]
+
+    @property
+    def list_users(
+        self,
+    ) -> Callable[[service.ListUsersRequest], Awaitable[service.ListUsersResponse]]:
+        r"""Return a callable for the list users method over gRPC.
+
+        Lists Users in a given project and location.
+
+        Returns:
+            Callable[[~.ListUsersRequest],
+                    Awaitable[~.ListUsersResponse]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "list_users" not in self._stubs:
+            self._stubs["list_users"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListUsers",
+                request_serializer=service.ListUsersRequest.serialize,
+                response_deserializer=service.ListUsersResponse.deserialize,
+            )
+        return self._stubs["list_users"]
+
+    @property
+    def get_user(self) -> Callable[[service.GetUserRequest], Awaitable[resources.User]]:
+        r"""Return a callable for the get user method over gRPC.
+
+        Gets details of a single User.
+
+        Returns:
+            Callable[[~.GetUserRequest],
+                    Awaitable[~.User]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "get_user" not in self._stubs:
+            self._stubs["get_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetUser",
+                request_serializer=service.GetUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["get_user"]
+
+    @property
+    def create_user(
+        self,
+    ) -> Callable[[service.CreateUserRequest], Awaitable[resources.User]]:
+        r"""Return a callable for the create user method over gRPC.
+
+        Creates a new User in a given project, location, and
+        cluster.
+
+        Returns:
+            Callable[[~.CreateUserRequest],
+                    Awaitable[~.User]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_user" not in self._stubs:
+            self._stubs["create_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateUser",
+                request_serializer=service.CreateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["create_user"]
+
+    @property
+    def update_user(
+        self,
+    ) -> Callable[[service.UpdateUserRequest], Awaitable[resources.User]]:
+        r"""Return a callable for the update user method over gRPC.
+
+        Updates the parameters of a single User.
+
+        Returns:
+            Callable[[~.UpdateUserRequest],
+                    Awaitable[~.User]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "update_user" not in self._stubs:
+            self._stubs["update_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/UpdateUser",
+                request_serializer=service.UpdateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["update_user"]
+
+    @property
+    def delete_user(
+        self,
+    ) -> Callable[[service.DeleteUserRequest], Awaitable[empty_pb2.Empty]]:
+        r"""Return a callable for the delete user method over gRPC.
+
+        Deletes a single User.
+
+        Returns:
+            Callable[[~.DeleteUserRequest],
+                    Awaitable[~.Empty]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "delete_user" not in self._stubs:
+            self._stubs["delete_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/DeleteUser",
+                request_serializer=service.DeleteUserRequest.serialize,
+                response_deserializer=empty_pb2.Empty.FromString,
+            )
+        return self._stubs["delete_user"]
+
     def close(self):
         return self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/services/alloy_db_admin/transports/rest.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/rest.py`

 * *Files 12% similar despite different names*

```diff
@@ -43,16 +43,17 @@
 try:
     OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
 except AttributeError:  # pragma: NO COVER
     OptionalRetry = Union[retries.Retry, object]  # type: ignore
 
 
 from google.longrunning import operations_pb2  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 
-from google.cloud.alloydb_v1.types import resources, service
+from google.cloud.alloydb_v1beta.types import resources, service
 
 from .base import AlloyDBAdminTransport
 from .base import DEFAULT_CLIENT_INFO as BASE_DEFAULT_CLIENT_INFO
 
 DEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(
     gapic_version=BASE_DEFAULT_CLIENT_INFO.gapic_version,
     grpc_version=None,
@@ -103,14 +104,38 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_create_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_create_secondary_cluster(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_create_secondary_cluster(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
+            def pre_create_secondary_instance(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_create_secondary_instance(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
+            def pre_create_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_create_user(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_delete_backup(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_delete_backup(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -127,22 +152,34 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_delete_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_delete_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
             def pre_failover_instance(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_failover_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_generate_client_certificate(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_generate_client_certificate(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_get_backup(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_get_backup(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -151,22 +188,46 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_get_cluster(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_get_connection_info(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_get_connection_info(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_get_instance(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_get_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_get_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_get_user(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
+            def pre_inject_fault(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_inject_fault(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_list_backups(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_list_backups(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -191,14 +252,30 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_list_supported_database_flags(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_list_users(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_list_users(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
+            def pre_promote_cluster(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_promote_cluster(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_restart_instance(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_restart_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -231,14 +308,22 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_update_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_update_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_update_user(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
         transport = AlloyDBAdminRestTransport(interceptor=MyCustomAlloyDBAdminInterceptor())
         client = AlloyDBAdminClient(transport=transport)
 
 
     """
 
     def pre_batch_create_instances(
@@ -325,14 +410,79 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_create_secondary_cluster(
+        self,
+        request: service.CreateSecondaryClusterRequest,
+        metadata: Sequence[Tuple[str, str]],
+    ) -> Tuple[service.CreateSecondaryClusterRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for create_secondary_cluster
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_create_secondary_cluster(
+        self, response: operations_pb2.Operation
+    ) -> operations_pb2.Operation:
+        """Post-rpc interceptor for create_secondary_cluster
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
+    def pre_create_secondary_instance(
+        self,
+        request: service.CreateSecondaryInstanceRequest,
+        metadata: Sequence[Tuple[str, str]],
+    ) -> Tuple[service.CreateSecondaryInstanceRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for create_secondary_instance
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_create_secondary_instance(
+        self, response: operations_pb2.Operation
+    ) -> operations_pb2.Operation:
+        """Post-rpc interceptor for create_secondary_instance
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
+    def pre_create_user(
+        self, request: service.CreateUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.CreateUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for create_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_create_user(self, response: resources.User) -> resources.User:
+        """Post-rpc interceptor for create_user
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_delete_backup(
         self, request: service.DeleteBackupRequest, metadata: Sequence[Tuple[str, str]]
     ) -> Tuple[service.DeleteBackupRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for delete_backup
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
@@ -390,14 +540,24 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_delete_user(
+        self, request: service.DeleteUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.DeleteUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for delete_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
     def pre_failover_instance(
         self,
         request: service.FailoverInstanceRequest,
         metadata: Sequence[Tuple[str, str]],
     ) -> Tuple[service.FailoverInstanceRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for failover_instance
 
@@ -413,14 +573,37 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_generate_client_certificate(
+        self,
+        request: service.GenerateClientCertificateRequest,
+        metadata: Sequence[Tuple[str, str]],
+    ) -> Tuple[service.GenerateClientCertificateRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for generate_client_certificate
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_generate_client_certificate(
+        self, response: service.GenerateClientCertificateResponse
+    ) -> service.GenerateClientCertificateResponse:
+        """Post-rpc interceptor for generate_client_certificate
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_get_backup(
         self, request: service.GetBackupRequest, metadata: Sequence[Tuple[str, str]]
     ) -> Tuple[service.GetBackupRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for get_backup
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
@@ -451,14 +634,37 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_get_connection_info(
+        self,
+        request: service.GetConnectionInfoRequest,
+        metadata: Sequence[Tuple[str, str]],
+    ) -> Tuple[service.GetConnectionInfoRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for get_connection_info
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_get_connection_info(
+        self, response: resources.ConnectionInfo
+    ) -> resources.ConnectionInfo:
+        """Post-rpc interceptor for get_connection_info
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_get_instance(
         self, request: service.GetInstanceRequest, metadata: Sequence[Tuple[str, str]]
     ) -> Tuple[service.GetInstanceRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for get_instance
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
@@ -470,14 +676,54 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_get_user(
+        self, request: service.GetUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.GetUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for get_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_get_user(self, response: resources.User) -> resources.User:
+        """Post-rpc interceptor for get_user
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
+    def pre_inject_fault(
+        self, request: service.InjectFaultRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.InjectFaultRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for inject_fault
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_inject_fault(
+        self, response: operations_pb2.Operation
+    ) -> operations_pb2.Operation:
+        """Post-rpc interceptor for inject_fault
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_list_backups(
         self, request: service.ListBackupsRequest, metadata: Sequence[Tuple[str, str]]
     ) -> Tuple[service.ListBackupsRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for list_backups
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
@@ -556,14 +802,58 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_list_users(
+        self, request: service.ListUsersRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.ListUsersRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for list_users
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_list_users(
+        self, response: service.ListUsersResponse
+    ) -> service.ListUsersResponse:
+        """Post-rpc interceptor for list_users
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
+    def pre_promote_cluster(
+        self,
+        request: service.PromoteClusterRequest,
+        metadata: Sequence[Tuple[str, str]],
+    ) -> Tuple[service.PromoteClusterRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for promote_cluster
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_promote_cluster(
+        self, response: operations_pb2.Operation
+    ) -> operations_pb2.Operation:
+        """Post-rpc interceptor for promote_cluster
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_restart_instance(
         self,
         request: service.RestartInstanceRequest,
         metadata: Sequence[Tuple[str, str]],
     ) -> Tuple[service.RestartInstanceRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for restart_instance
 
@@ -667,14 +957,33 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_update_user(
+        self, request: service.UpdateUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.UpdateUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for update_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_update_user(self, response: resources.User) -> resources.User:
+        """Post-rpc interceptor for update_user
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_get_location(
         self,
         request: locations_pb2.GetLocationRequest,
         metadata: Sequence[Tuple[str, str]],
     ) -> Tuple[locations_pb2.GetLocationRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for get_location
 
@@ -912,45 +1221,44 @@
         """
         # Only create a new client if we do not already have one.
         if self._operations_client is None:
             http_options: Dict[str, List[Dict[str, str]]] = {
                 "google.longrunning.Operations.CancelOperation": [
                     {
                         "method": "post",
-                        "uri": "/v1/{name=projects/*/locations/*/operations/*}:cancel",
-                        "body": "*",
+                        "uri": "/v1beta/{name=projects/*/locations/*/operations/*}:cancel",
                     },
                 ],
                 "google.longrunning.Operations.DeleteOperation": [
                     {
                         "method": "delete",
-                        "uri": "/v1/{name=projects/*/locations/*/operations/*}",
+                        "uri": "/v1beta/{name=projects/*/locations/*/operations/*}",
                     },
                 ],
                 "google.longrunning.Operations.GetOperation": [
                     {
                         "method": "get",
-                        "uri": "/v1/{name=projects/*/locations/*/operations/*}",
+                        "uri": "/v1beta/{name=projects/*/locations/*/operations/*}",
                     },
                 ],
                 "google.longrunning.Operations.ListOperations": [
                     {
                         "method": "get",
-                        "uri": "/v1/{name=projects/*/locations/*}/operations",
+                        "uri": "/v1beta/{name=projects/*/locations/*}/operations",
                     },
                 ],
             }
 
             rest_transport = operations_v1.OperationsRestTransport(
                 host=self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 scopes=self._scopes,
                 http_options=http_options,
-                path_prefix="v1",
+                path_prefix="v1beta",
             )
 
             self._operations_client = operations_v1.AbstractOperationsClient(
                 transport=rest_transport
             )
 
         # Return the client from cache.
@@ -997,15 +1305,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1/{parent=projects/*/locations/*/clusters/*}/instances:batchCreate",
+                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/instances:batchCreate",
                     "body": "requests",
                 },
             ]
             request, metadata = self._interceptor.pre_batch_create_instances(
                 request, metadata
             )
             pb_request = service.BatchCreateInstancesRequest.pb(request)
@@ -1097,15 +1405,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1/{parent=projects/*/locations/*}/backups",
+                    "uri": "/v1beta/{parent=projects/*/locations/*}/backups",
                     "body": "backup",
                 },
             ]
             request, metadata = self._interceptor.pre_create_backup(request, metadata)
             pb_request = service.CreateBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -1195,15 +1503,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1/{parent=projects/*/locations/*}/clusters",
+                    "uri": "/v1beta/{parent=projects/*/locations/*}/clusters",
                     "body": "cluster",
                 },
             ]
             request, metadata = self._interceptor.pre_create_cluster(request, metadata)
             pb_request = service.CreateClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -1293,15 +1601,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1/{parent=projects/*/locations/*/clusters/*}/instances",
+                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/instances",
                     "body": "instance",
                 },
             ]
             request, metadata = self._interceptor.pre_create_instance(request, metadata)
             pb_request = service.CreateInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -1345,14 +1653,312 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_create_instance(resp)
             return resp
 
+    class _CreateSecondaryCluster(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("CreateSecondaryCluster")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {
+            "clusterId": "",
+        }
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.CreateSecondaryClusterRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> operations_pb2.Operation:
+            r"""Call the create secondary cluster method over HTTP.
+
+            Args:
+                request (~.service.CreateSecondaryClusterRequest):
+                    The request object.
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.operations_pb2.Operation:
+                    This resource represents a
+                long-running operation that is the
+                result of a network API call.
+
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1beta/{parent=projects/*/locations/*}/clusters:createsecondary",
+                    "body": "cluster",
+                },
+            ]
+            request, metadata = self._interceptor.pre_create_secondary_cluster(
+                request, metadata
+            )
+            pb_request = service.CreateSecondaryClusterRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = operations_pb2.Operation()
+            json_format.Parse(response.content, resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_create_secondary_cluster(resp)
+            return resp
+
+    class _CreateSecondaryInstance(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("CreateSecondaryInstance")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {
+            "instanceId": "",
+        }
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.CreateSecondaryInstanceRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> operations_pb2.Operation:
+            r"""Call the create secondary instance method over HTTP.
+
+            Args:
+                request (~.service.CreateSecondaryInstanceRequest):
+                    The request object. Message for creating a Secondary
+                Instance
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.operations_pb2.Operation:
+                    This resource represents a
+                long-running operation that is the
+                result of a network API call.
+
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/instances:createsecondary",
+                    "body": "instance",
+                },
+            ]
+            request, metadata = self._interceptor.pre_create_secondary_instance(
+                request, metadata
+            )
+            pb_request = service.CreateSecondaryInstanceRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = operations_pb2.Operation()
+            json_format.Parse(response.content, resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_create_secondary_instance(resp)
+            return resp
+
+    class _CreateUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("CreateUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {
+            "userId": "",
+        }
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.CreateUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> resources.User:
+            r"""Call the create user method over HTTP.
+
+            Args:
+                request (~.service.CreateUserRequest):
+                    The request object. Message for creating a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.resources.User:
+                    Message describing User object.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/users",
+                    "body": "user",
+                },
+            ]
+            request, metadata = self._interceptor.pre_create_user(request, metadata)
+            pb_request = service.CreateUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = resources.User()
+            pb_resp = resources.User.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_create_user(resp)
+            return resp
+
     class _DeleteBackup(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("DeleteBackup")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -1389,15 +1995,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1/{name=projects/*/locations/*/backups/*}",
+                    "uri": "/v1beta/{name=projects/*/locations/*/backups/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_delete_backup(request, metadata)
             pb_request = service.DeleteBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1476,15 +2082,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1/{name=projects/*/locations/*/clusters/*}",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_delete_cluster(request, metadata)
             pb_request = service.DeleteClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1563,15 +2169,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/instances/*}",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_delete_instance(request, metadata)
             pb_request = service.DeleteInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1606,14 +2212,88 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_delete_instance(resp)
             return resp
 
+    class _DeleteUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("DeleteUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.DeleteUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ):
+            r"""Call the delete user method over HTTP.
+
+            Args:
+                request (~.service.DeleteUserRequest):
+                    The request object. Message for deleting a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "delete",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/users/*}",
+                },
+            ]
+            request, metadata = self._interceptor.pre_delete_user(request, metadata)
+            pb_request = service.DeleteUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
     class _FailoverInstance(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("FailoverInstance")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -1651,15 +2331,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/instances/*}:failover",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}:failover",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_failover_instance(
                 request, metadata
             )
             pb_request = service.FailoverInstanceRequest.pb(request)
@@ -1705,14 +2385,116 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_failover_instance(resp)
             return resp
 
+    class _GenerateClientCertificate(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("GenerateClientCertificate")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.GenerateClientCertificateRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> service.GenerateClientCertificateResponse:
+            r"""Call the generate client
+            certificate method over HTTP.
+
+                Args:
+                    request (~.service.GenerateClientCertificateRequest):
+                        The request object. Message for requests to generate a
+                    client certificate signed by the Cluster
+                    CA.
+                    retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                        should be retried.
+                    timeout (float): The timeout for this request.
+                    metadata (Sequence[Tuple[str, str]]): Strings which should be
+                        sent along with the request as metadata.
+
+                Returns:
+                    ~.service.GenerateClientCertificateResponse:
+                        Message returned by a
+                    GenerateClientCertificate operation.
+
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}:generateClientCertificate",
+                    "body": "*",
+                },
+            ]
+            request, metadata = self._interceptor.pre_generate_client_certificate(
+                request, metadata
+            )
+            pb_request = service.GenerateClientCertificateRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = service.GenerateClientCertificateResponse()
+            pb_resp = service.GenerateClientCertificateResponse.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_generate_client_certificate(resp)
+            return resp
+
     class _GetBackup(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("GetBackup")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -1746,15 +2528,15 @@
                 ~.resources.Backup:
                     Message describing Backup object
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{name=projects/*/locations/*/backups/*}",
+                    "uri": "/v1beta/{name=projects/*/locations/*/backups/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_get_backup(request, metadata)
             pb_request = service.GetBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1838,15 +2620,15 @@
                 needed.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{name=projects/*/locations/*/clusters/*}",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_get_cluster(request, metadata)
             pb_request = service.GetClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1883,14 +2665,105 @@
             resp = resources.Cluster()
             pb_resp = resources.Cluster.pb(resp)
 
             json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_get_cluster(resp)
             return resp
 
+    class _GetConnectionInfo(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("GetConnectionInfo")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.GetConnectionInfoRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> resources.ConnectionInfo:
+            r"""Call the get connection info method over HTTP.
+
+            Args:
+                request (~.service.GetConnectionInfoRequest):
+                    The request object. Request message for
+                GetConnectionInfo.
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.resources.ConnectionInfo:
+                    ConnectionInfo singleton resource.
+                https://google.aip.dev/156
+
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "get",
+                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*/instances/*}/connectionInfo",
+                },
+            ]
+            request, metadata = self._interceptor.pre_get_connection_info(
+                request, metadata
+            )
+            pb_request = service.GetConnectionInfoRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = resources.ConnectionInfo()
+            pb_resp = resources.ConnectionInfo.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_get_connection_info(resp)
+            return resp
+
     class _GetInstance(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("GetInstance")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -1928,15 +2801,15 @@
                 AlloyDB.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/instances/*}",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_get_instance(request, metadata)
             pb_request = service.GetInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1973,14 +2846,197 @@
             resp = resources.Instance()
             pb_resp = resources.Instance.pb(resp)
 
             json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_get_instance(resp)
             return resp
 
+    class _GetUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("GetUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.GetUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> resources.User:
+            r"""Call the get user method over HTTP.
+
+            Args:
+                request (~.service.GetUserRequest):
+                    The request object. Message for getting a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.resources.User:
+                    Message describing User object.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "get",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/users/*}",
+                },
+            ]
+            request, metadata = self._interceptor.pre_get_user(request, metadata)
+            pb_request = service.GetUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = resources.User()
+            pb_resp = resources.User.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_get_user(resp)
+            return resp
+
+    class _InjectFault(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("InjectFault")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.InjectFaultRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> operations_pb2.Operation:
+            r"""Call the inject fault method over HTTP.
+
+            Args:
+                request (~.service.InjectFaultRequest):
+                    The request object. Message for triggering fault
+                injection on an instance
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.operations_pb2.Operation:
+                    This resource represents a
+                long-running operation that is the
+                result of a network API call.
+
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}:injectFault",
+                    "body": "*",
+                },
+            ]
+            request, metadata = self._interceptor.pre_inject_fault(request, metadata)
+            pb_request = service.InjectFaultRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = operations_pb2.Operation()
+            json_format.Parse(response.content, resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_inject_fault(resp)
+            return resp
+
     class _ListBackups(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("ListBackups")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -2017,15 +3073,15 @@
                 Backups
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{parent=projects/*/locations/*}/backups",
+                    "uri": "/v1beta/{parent=projects/*/locations/*}/backups",
                 },
             ]
             request, metadata = self._interceptor.pre_list_backups(request, metadata)
             pb_request = service.ListBackupsRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2106,15 +3162,15 @@
                 Clusters
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{parent=projects/*/locations/*}/clusters",
+                    "uri": "/v1beta/{parent=projects/*/locations/*}/clusters",
                 },
             ]
             request, metadata = self._interceptor.pre_list_clusters(request, metadata)
             pb_request = service.ListClustersRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2195,15 +3251,15 @@
                 Instances
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{parent=projects/*/locations/*/clusters/*}/instances",
+                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/instances",
                 },
             ]
             request, metadata = self._interceptor.pre_list_instances(request, metadata)
             pb_request = service.ListInstancesRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2285,15 +3341,15 @@
                     SupportedDatabaseFlags.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{parent=projects/*/locations/*}/supportedDatabaseFlags",
+                    "uri": "/v1beta/{parent=projects/*/locations/*}/supportedDatabaseFlags",
                 },
             ]
             request, metadata = self._interceptor.pre_list_supported_database_flags(
                 request, metadata
             )
             pb_request = service.ListSupportedDatabaseFlagsRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
@@ -2332,14 +3388,196 @@
             resp = service.ListSupportedDatabaseFlagsResponse()
             pb_resp = service.ListSupportedDatabaseFlagsResponse.pb(resp)
 
             json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_list_supported_database_flags(resp)
             return resp
 
+    class _ListUsers(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("ListUsers")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.ListUsersRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> service.ListUsersResponse:
+            r"""Call the list users method over HTTP.
+
+            Args:
+                request (~.service.ListUsersRequest):
+                    The request object. Message for requesting list of Users
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.service.ListUsersResponse:
+                    Message for response to listing Users
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "get",
+                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/users",
+                },
+            ]
+            request, metadata = self._interceptor.pre_list_users(request, metadata)
+            pb_request = service.ListUsersRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = service.ListUsersResponse()
+            pb_resp = service.ListUsersResponse.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_list_users(resp)
+            return resp
+
+    class _PromoteCluster(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("PromoteCluster")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.PromoteClusterRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> operations_pb2.Operation:
+            r"""Call the promote cluster method over HTTP.
+
+            Args:
+                request (~.service.PromoteClusterRequest):
+                    The request object. Message for promoting a Cluster
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.operations_pb2.Operation:
+                    This resource represents a
+                long-running operation that is the
+                result of a network API call.
+
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*}:promote",
+                    "body": "*",
+                },
+            ]
+            request, metadata = self._interceptor.pre_promote_cluster(request, metadata)
+            pb_request = service.PromoteClusterRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = operations_pb2.Operation()
+            json_format.Parse(response.content, resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_promote_cluster(resp)
+            return resp
+
     class _RestartInstance(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("RestartInstance")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -2376,15 +3614,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/instances/*}:restart",
+                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}:restart",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_restart_instance(
                 request, metadata
             )
             pb_request = service.RestartInstanceRequest.pb(request)
@@ -2476,15 +3714,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1/{parent=projects/*/locations/*}/clusters:restore",
+                    "uri": "/v1beta/{parent=projects/*/locations/*}/clusters:restore",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_restore_cluster(request, metadata)
             pb_request = service.RestoreClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -2572,15 +3810,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "patch",
-                    "uri": "/v1/{backup.name=projects/*/locations/*/backups/*}",
+                    "uri": "/v1beta/{backup.name=projects/*/locations/*/backups/*}",
                     "body": "backup",
                 },
             ]
             request, metadata = self._interceptor.pre_update_backup(request, metadata)
             pb_request = service.UpdateBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -2668,15 +3906,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "patch",
-                    "uri": "/v1/{cluster.name=projects/*/locations/*/clusters/*}",
+                    "uri": "/v1beta/{cluster.name=projects/*/locations/*/clusters/*}",
                     "body": "cluster",
                 },
             ]
             request, metadata = self._interceptor.pre_update_cluster(request, metadata)
             pb_request = service.UpdateClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -2764,15 +4002,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "patch",
-                    "uri": "/v1/{instance.name=projects/*/locations/*/clusters/*/instances/*}",
+                    "uri": "/v1beta/{instance.name=projects/*/locations/*/clusters/*/instances/*}",
                     "body": "instance",
                 },
             ]
             request, metadata = self._interceptor.pre_update_instance(request, metadata)
             pb_request = service.UpdateInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -2816,14 +4054,109 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_update_instance(resp)
             return resp
 
+    class _UpdateUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("UpdateUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.UpdateUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> resources.User:
+            r"""Call the update user method over HTTP.
+
+            Args:
+                request (~.service.UpdateUserRequest):
+                    The request object. Message for updating a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.resources.User:
+                    Message describing User object.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "patch",
+                    "uri": "/v1beta/{user.name=projects/*/locations/*/clusters/*/users/*}",
+                    "body": "user",
+                },
+            ]
+            request, metadata = self._interceptor.pre_update_user(request, metadata)
+            pb_request = service.UpdateUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = resources.User()
+            pb_resp = resources.User.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_update_user(resp)
+            return resp
+
     @property
     def batch_create_instances(
         self,
     ) -> Callable[[service.BatchCreateInstancesRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._BatchCreateInstances(self._session, self._host, self._interceptor)  # type: ignore
@@ -2849,14 +4182,36 @@
         self,
     ) -> Callable[[service.CreateInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._CreateInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def create_secondary_cluster(
+        self,
+    ) -> Callable[[service.CreateSecondaryClusterRequest], operations_pb2.Operation]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._CreateSecondaryCluster(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
+    def create_secondary_instance(
+        self,
+    ) -> Callable[[service.CreateSecondaryInstanceRequest], operations_pb2.Operation]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._CreateSecondaryInstance(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
+    def create_user(self) -> Callable[[service.CreateUserRequest], resources.User]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._CreateUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def delete_backup(
         self,
     ) -> Callable[[service.DeleteBackupRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._DeleteBackup(self._session, self._host, self._interceptor)  # type: ignore
 
@@ -2873,42 +4228,81 @@
         self,
     ) -> Callable[[service.DeleteInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._DeleteInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def delete_user(self) -> Callable[[service.DeleteUserRequest], empty_pb2.Empty]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._DeleteUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def failover_instance(
         self,
     ) -> Callable[[service.FailoverInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._FailoverInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def generate_client_certificate(
+        self,
+    ) -> Callable[
+        [service.GenerateClientCertificateRequest],
+        service.GenerateClientCertificateResponse,
+    ]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._GenerateClientCertificate(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def get_backup(self) -> Callable[[service.GetBackupRequest], resources.Backup]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._GetBackup(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
     def get_cluster(self) -> Callable[[service.GetClusterRequest], resources.Cluster]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._GetCluster(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def get_connection_info(
+        self,
+    ) -> Callable[[service.GetConnectionInfoRequest], resources.ConnectionInfo]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._GetConnectionInfo(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def get_instance(
         self,
     ) -> Callable[[service.GetInstanceRequest], resources.Instance]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._GetInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def get_user(self) -> Callable[[service.GetUserRequest], resources.User]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._GetUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
+    def inject_fault(
+        self,
+    ) -> Callable[[service.InjectFaultRequest], operations_pb2.Operation]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._InjectFault(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def list_backups(
         self,
     ) -> Callable[[service.ListBackupsRequest], service.ListBackupsResponse]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._ListBackups(self._session, self._host, self._interceptor)  # type: ignore
 
@@ -2936,14 +4330,30 @@
         service.ListSupportedDatabaseFlagsResponse,
     ]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._ListSupportedDatabaseFlags(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def list_users(
+        self,
+    ) -> Callable[[service.ListUsersRequest], service.ListUsersResponse]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._ListUsers(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
+    def promote_cluster(
+        self,
+    ) -> Callable[[service.PromoteClusterRequest], operations_pb2.Operation]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._PromoteCluster(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def restart_instance(
         self,
     ) -> Callable[[service.RestartInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._RestartInstance(self._session, self._host, self._interceptor)  # type: ignore
 
@@ -2976,14 +4386,20 @@
         self,
     ) -> Callable[[service.UpdateInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._UpdateInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def update_user(self) -> Callable[[service.UpdateUserRequest], resources.User]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._UpdateUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def get_location(self):
         return self._GetLocation(self._session, self._host, self._interceptor)  # type: ignore
 
     class _GetLocation(AlloyDBAdminRestStub):
         def __call__(
             self,
             request: locations_pb2.GetLocationRequest,
@@ -3007,15 +4423,15 @@
             Returns:
                 locations_pb2.Location: Response from GetLocation method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{name=projects/*/locations/*}",
+                    "uri": "/v1beta/{name=projects/*/locations/*}",
                 },
             ]
 
             request, metadata = self._interceptor.pre_get_location(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
@@ -3074,15 +4490,15 @@
             Returns:
                 locations_pb2.ListLocationsResponse: Response from ListLocations method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{name=projects/*}/locations",
+                    "uri": "/v1beta/{name=projects/*}/locations",
                 },
             ]
 
             request, metadata = self._interceptor.pre_list_locations(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
@@ -3138,26 +4554,24 @@
                 metadata (Sequence[Tuple[str, str]]): Strings which should be
                     sent along with the request as metadata.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1/{name=projects/*/locations/*/operations/*}:cancel",
-                    "body": "*",
+                    "uri": "/v1beta/{name=projects/*/locations/*/operations/*}:cancel",
                 },
             ]
 
             request, metadata = self._interceptor.pre_cancel_operation(
                 request, metadata
             )
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
-            body = json.loads(json.dumps(transcoded_request["body"]))
             uri = transcoded_request["uri"]
             method = transcoded_request["method"]
 
             # Jsonify the query params
             query_params = json.loads(json.dumps(transcoded_request["query_params"]))
 
             # Send the request
@@ -3165,15 +4579,14 @@
             headers["Content-Type"] = "application/json"
 
             response = getattr(self._session, method)(
                 "{host}{uri}".format(host=self._host, uri=uri),
                 timeout=timeout,
                 headers=headers,
                 params=rest_helpers.flatten_query_params(query_params),
-                data=body,
             )
 
             # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
             # subclass.
             if response.status_code >= 400:
                 raise core_exceptions.from_http_response(response)
 
@@ -3204,15 +4617,15 @@
                 metadata (Sequence[Tuple[str, str]]): Strings which should be
                     sent along with the request as metadata.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1/{name=projects/*/locations/*/operations/*}",
+                    "uri": "/v1beta/{name=projects/*/locations/*/operations/*}",
                 },
             ]
 
             request, metadata = self._interceptor.pre_delete_operation(
                 request, metadata
             )
             request_kwargs = json_format.MessageToDict(request)
@@ -3270,15 +4683,15 @@
             Returns:
                 operations_pb2.Operation: Response from GetOperation method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{name=projects/*/locations/*/operations/*}",
+                    "uri": "/v1beta/{name=projects/*/locations/*/operations/*}",
                 },
             ]
 
             request, metadata = self._interceptor.pre_get_operation(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
@@ -3337,15 +4750,15 @@
             Returns:
                 operations_pb2.ListOperationsResponse: Response from ListOperations method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1/{name=projects/*/locations/*}/operations",
+                    "uri": "/v1beta/{name=projects/*/locations/*}/operations",
                 },
             ]
 
             request, metadata = self._interceptor.pre_list_operations(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/types/resources.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/types/resources.py`

 * *Files 5% similar despite different names*

```diff
@@ -23,48 +23,36 @@
 from google.type import dayofweek_pb2  # type: ignore
 from google.type import timeofday_pb2  # type: ignore
 import proto  # type: ignore
 
 __protobuf__ = proto.module(
     package="google.cloud.alloydb.v1",
     manifest={
-        "DatabaseVersion",
         "InstanceView",
+        "ClusterView",
+        "DatabaseVersion",
         "UserPassword",
         "MigrationSource",
         "EncryptionConfig",
         "EncryptionInfo",
         "SslConfig",
         "AutomatedBackupPolicy",
+        "ContinuousBackupConfig",
+        "ContinuousBackupInfo",
         "BackupSource",
+        "ContinuousBackupSource",
         "Cluster",
         "Instance",
         "Backup",
         "SupportedDatabaseFlag",
+        "User",
     },
 )
 
 
-class DatabaseVersion(proto.Enum):
-    r"""The supported database engine versions.
-
-    Values:
-        DATABASE_VERSION_UNSPECIFIED (0):
-            This is an unknown database version.
-        POSTGRES_13 (1):
-            DEPRECATED - The database version is Postgres
-            13.
-        POSTGRES_14 (2):
-            The database version is Postgres 14.
-    """
-    DATABASE_VERSION_UNSPECIFIED = 0
-    POSTGRES_13 = 1
-    POSTGRES_14 = 2
-
-
 class InstanceView(proto.Enum):
     r"""View on Instance. Pass this enum to rpcs that returns an
     Instance message to control which subsets of fields to get.
 
     Values:
         INSTANCE_VIEW_UNSPECIFIED (0):
             INSTANCE_VIEW_UNSPECIFIED Not specified, equivalent to
@@ -81,14 +69,54 @@
             the pool.
     """
     INSTANCE_VIEW_UNSPECIFIED = 0
     INSTANCE_VIEW_BASIC = 1
     INSTANCE_VIEW_FULL = 2
 
 
+class ClusterView(proto.Enum):
+    r"""View on Cluster. Pass this enum to rpcs that returns a
+    cluster message to control which subsets of fields to get.
+
+    Values:
+        CLUSTER_VIEW_UNSPECIFIED (0):
+            CLUSTER_VIEW_UNSPECIFIED Not specified, equivalent to BASIC.
+        CLUSTER_VIEW_BASIC (1):
+            BASIC server responses include all the
+            relevant cluster details, excluding
+            Cluster.ContinuousBackupInfo.EarliestRestorableTime
+            and other view-specific fields. The default
+            value.
+        CLUSTER_VIEW_CONTINUOUS_BACKUP (2):
+            CONTINUOUS_BACKUP response returns all the fields from BASIC
+            plus the earliest restorable time if continuous backups are
+            enabled. May increase latency.
+    """
+    CLUSTER_VIEW_UNSPECIFIED = 0
+    CLUSTER_VIEW_BASIC = 1
+    CLUSTER_VIEW_CONTINUOUS_BACKUP = 2
+
+
+class DatabaseVersion(proto.Enum):
+    r"""The supported database engine versions.
+
+    Values:
+        DATABASE_VERSION_UNSPECIFIED (0):
+            This is an unknown database version.
+        POSTGRES_13 (1):
+            DEPRECATED - The database version is Postgres
+            13.
+        POSTGRES_14 (2):
+            The database version is Postgres 14.
+    """
+    DATABASE_VERSION_UNSPECIFIED = 0
+    POSTGRES_13 = 1
+    POSTGRES_14 = 2
+
+
 class UserPassword(proto.Message):
     r"""The username/password for a database user. Used for
     specifying initial users at cluster creation time.
 
     Attributes:
         user (str):
             The database username.
@@ -210,15 +238,15 @@
     kms_key_versions: MutableSequence[str] = proto.RepeatedField(
         proto.STRING,
         number=2,
     )
 
 
 class SslConfig(proto.Message):
-    r"""SSL configuration for an AlloyDB Cluster.
+    r"""SSL configuration.
 
     Attributes:
         ssl_mode (google.cloud.alloydb_v1.types.SslConfig.SslMode):
             Optional. SSL mode. Specifies client-server
             SSL/TLS connection behavior.
         ca_source (google.cloud.alloydb_v1.types.SslConfig.CaSource):
             Optional. Certificate Authority (CA) source. Only
@@ -227,33 +255,41 @@
     """
 
     class SslMode(proto.Enum):
         r"""SSL mode options.
 
         Values:
             SSL_MODE_UNSPECIFIED (0):
-                SSL mode not specified. Defaults to SSL_MODE_ALLOW.
+                SSL mode not specified. Defaults to ENCRYPTED_ONLY.
             SSL_MODE_ALLOW (1):
                 SSL connections are optional. CA verification
                 not enforced.
             SSL_MODE_REQUIRE (2):
                 SSL connections are required. CA verification
                 not enforced. Clients may use locally
                 self-signed certificates (default psql client
                 behavior).
             SSL_MODE_VERIFY_CA (3):
                 SSL connections are required. CA verification
                 enforced. Clients must have certificates signed
                 by a Cluster CA, e.g. via
                 GenerateClientCertificate.
+            ALLOW_UNENCRYPTED_AND_ENCRYPTED (4):
+                SSL connections are optional. CA verification
+                not enforced.
+            ENCRYPTED_ONLY (5):
+                SSL connections are required. CA verification
+                not enforced.
         """
         SSL_MODE_UNSPECIFIED = 0
         SSL_MODE_ALLOW = 1
         SSL_MODE_REQUIRE = 2
         SSL_MODE_VERIFY_CA = 3
+        ALLOW_UNENCRYPTED_AND_ENCRYPTED = 4
+        ENCRYPTED_ONLY = 5
 
     class CaSource(proto.Enum):
         r"""Certificate Authority (CA) source for SSL/TLS certificates.
 
         Values:
             CA_SOURCE_UNSPECIFIED (0):
                 Certificate Authority (CA) source not specified. Defaults to
@@ -438,14 +474,99 @@
     labels: MutableMapping[str, str] = proto.MapField(
         proto.STRING,
         proto.STRING,
         number=7,
     )
 
 
+class ContinuousBackupConfig(proto.Message):
+    r"""ContinuousBackupConfig describes the continuous backups
+    recovery configurations of a cluster.
+
+
+    .. _oneof: https://proto-plus-python.readthedocs.io/en/stable/fields.html#oneofs-mutually-exclusive-fields
+
+    Attributes:
+        enabled (bool):
+            Whether ContinuousBackup is enabled.
+
+            This field is a member of `oneof`_ ``_enabled``.
+        recovery_window_days (int):
+            The number of days backups and logs will be
+            retained, which determines the window of time
+            that data is recoverable for. If not set, it
+            defaults to 14 days.
+        encryption_config (google.cloud.alloydb_v1.types.EncryptionConfig):
+            The encryption config can be specified to
+            encrypt the backups with a customer-managed
+            encryption key (CMEK). When this field is not
+            specified, the backup will then use default
+            encryption scheme to protect the user data.
+    """
+
+    enabled: bool = proto.Field(
+        proto.BOOL,
+        number=1,
+        optional=True,
+    )
+    recovery_window_days: int = proto.Field(
+        proto.INT32,
+        number=4,
+    )
+    encryption_config: "EncryptionConfig" = proto.Field(
+        proto.MESSAGE,
+        number=3,
+        message="EncryptionConfig",
+    )
+
+
+class ContinuousBackupInfo(proto.Message):
+    r"""ContinuousBackupInfo describes the continuous backup
+    properties of a cluster.
+
+    Attributes:
+        encryption_info (google.cloud.alloydb_v1.types.EncryptionInfo):
+            Output only. The encryption information for
+            the WALs and backups required for
+            ContinuousBackup.
+        enabled_time (google.protobuf.timestamp_pb2.Timestamp):
+            Output only. When ContinuousBackup was most
+            recently enabled. Set to null if
+            ContinuousBackup is not enabled.
+        schedule (MutableSequence[google.type.dayofweek_pb2.DayOfWeek]):
+            Output only. Days of the week on which a
+            continuous backup is taken. Output only field.
+            Ignored if passed into the request.
+        earliest_restorable_time (google.protobuf.timestamp_pb2.Timestamp):
+            Output only. The earliest restorable time
+            that can be restored to. Output only field.
+    """
+
+    encryption_info: "EncryptionInfo" = proto.Field(
+        proto.MESSAGE,
+        number=1,
+        message="EncryptionInfo",
+    )
+    enabled_time: timestamp_pb2.Timestamp = proto.Field(
+        proto.MESSAGE,
+        number=2,
+        message=timestamp_pb2.Timestamp,
+    )
+    schedule: MutableSequence[dayofweek_pb2.DayOfWeek] = proto.RepeatedField(
+        proto.ENUM,
+        number=3,
+        enum=dayofweek_pb2.DayOfWeek,
+    )
+    earliest_restorable_time: timestamp_pb2.Timestamp = proto.Field(
+        proto.MESSAGE,
+        number=4,
+        message=timestamp_pb2.Timestamp,
+    )
+
+
 class BackupSource(proto.Message):
     r"""Message describing a BackupSource.
 
     Attributes:
         backup_uid (str):
             Output only. The system-generated UID of the
             backup which was used to create this resource.
@@ -463,14 +584,39 @@
     )
     backup_name: str = proto.Field(
         proto.STRING,
         number=1,
     )
 
 
+class ContinuousBackupSource(proto.Message):
+    r"""Message describing a ContinuousBackupSource.
+
+    Attributes:
+        cluster (str):
+            Required. The source cluster from which to
+            restore. This cluster must have continuous
+            backup enabled for this operation to succeed.
+            For the required format, see the comment on the
+            Cluster.name field.
+        point_in_time (google.protobuf.timestamp_pb2.Timestamp):
+            Required. The point in time to restore to.
+    """
+
+    cluster: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    point_in_time: timestamp_pb2.Timestamp = proto.Field(
+        proto.MESSAGE,
+        number=2,
+        message=timestamp_pb2.Timestamp,
+    )
+
+
 class Cluster(proto.Message):
     r"""A cluster is a collection of regional AlloyDB resources. It
     can include a primary instance and one or more read pool
     instances. All cluster resources share a storage layer, which
     scales as needed.
 
     This message has `oneof`_ fields (mutually exclusive fields).
@@ -563,26 +709,32 @@
             will be used. If backups are supported for the
             cluster, the default policy takes one backup a
             day, has a backup window of 1 hour, and retains
             backups for 14 days. For more information on the
             defaults, consult the documentation for the
             message type.
         ssl_config (google.cloud.alloydb_v1.types.SslConfig):
-            SSL configuration for this AlloyDB Cluster.
+            SSL configuration for this AlloyDB cluster.
         encryption_config (google.cloud.alloydb_v1.types.EncryptionConfig):
             Optional. The encryption config can be
             specified to encrypt the data disks and other
             persistent data resources of a cluster with a
             customer-managed encryption key (CMEK). When
             this field is not specified, the cluster will
             then use default encryption scheme to protect
             the user data.
         encryption_info (google.cloud.alloydb_v1.types.EncryptionInfo):
             Output only. The encryption information for
             the cluster.
+        continuous_backup_config (google.cloud.alloydb_v1.types.ContinuousBackupConfig):
+            Optional. Continuous backup configuration for
+            this cluster.
+        continuous_backup_info (google.cloud.alloydb_v1.types.ContinuousBackupInfo):
+            Output only. Continuous backup properties for
+            this cluster.
         secondary_config (google.cloud.alloydb_v1.types.Cluster.SecondaryConfig):
             Cross Region replication config specific to
             SECONDARY cluster.
         primary_config (google.cloud.alloydb_v1.types.Cluster.PrimaryConfig):
             Output only. Cross Region replication config
             specific to PRIMARY cluster.
     """
@@ -783,14 +935,24 @@
         message="EncryptionConfig",
     )
     encryption_info: "EncryptionInfo" = proto.Field(
         proto.MESSAGE,
         number=20,
         message="EncryptionInfo",
     )
+    continuous_backup_config: "ContinuousBackupConfig" = proto.Field(
+        proto.MESSAGE,
+        number=27,
+        message="ContinuousBackupConfig",
+    )
+    continuous_backup_info: "ContinuousBackupInfo" = proto.Field(
+        proto.MESSAGE,
+        number=28,
+        message="ContinuousBackupInfo",
+    )
     secondary_config: SecondaryConfig = proto.Field(
         proto.MESSAGE,
         number=22,
         message=SecondaryConfig,
     )
     primary_config: PrimaryConfig = proto.Field(
         proto.MESSAGE,
@@ -840,18 +1002,20 @@
         instance_type (google.cloud.alloydb_v1.types.Instance.InstanceType):
             Required. The type of the instance. Specified
             at creation time.
         machine_config (google.cloud.alloydb_v1.types.Instance.MachineConfig):
             Configurations for the machines that host the
             underlying database engine.
         availability_type (google.cloud.alloydb_v1.types.Instance.AvailabilityType):
-            Availability type of an Instance.
-            Defaults to REGIONAL for both primary and read
-            instances. Note that primary and read instances
-            can have different availability types.
+            Availability type of an Instance. If empty, defaults to
+            REGIONAL for primary instances. For read pools,
+            availability_type is always UNSPECIFIED. Instances in the
+            read pools are evenly distributed across available zones
+            within the region (i.e. read pools with more than one node
+            will have a node in at least two zones).
         gce_zone (str):
             The Compute Engine zone that the instance
             should serve from, per
             https://cloud.google.com/compute/docs/regions-zones
             This can ONLY be specified for ZONAL instances.
             If present for a REGIONAL instance, an error
             will be thrown. If this is absent for a ZONAL
@@ -975,17 +1139,17 @@
         PRIMARY = 1
         READ_POOL = 2
         SECONDARY = 3
 
     class AvailabilityType(proto.Enum):
         r"""The Availability type of an instance. Potential values:
         - ZONAL: The instance serves data from only one zone. Outages in
-        that zone affect instance availability.
+        that     zone affect instance availability.
         - REGIONAL: The instance can serve data from more than one zone
-        in a region (it is highly available).
+        in a     region (it is highly available).
 
         Values:
             AVAILABILITY_TYPE_UNSPECIFIED (0):
                 This is an unknown Availability type.
             ZONAL (1):
                 Zonal available instance.
             REGIONAL (2):
@@ -1254,15 +1418,16 @@
         description (str):
             User-provided description of the backup.
         cluster_uid (str):
             Output only. The system-generated UID of the
             cluster which was used to create this resource.
         cluster_name (str):
             Required. The full resource name of the backup source
-            cluster (e.g., projects//locations//clusters/<cluster_id>).
+            cluster (e.g.,
+            projects/{project}/locations/{region}/clusters/{cluster_id}).
         reconciling (bool):
             Output only. Reconciling
             (https://google.aip.dev/128#reconciliation), if
             true, indicates that the service is actively
             updating the resource. This can happen due to
             user-triggered updates or system actions like
             failover or maintenance.
@@ -1573,8 +1738,62 @@
     )
     requires_db_restart: bool = proto.Field(
         proto.BOOL,
         number=6,
     )
 
 
+class User(proto.Message):
+    r"""Message describing User object.
+
+    Attributes:
+        name (str):
+            Output only. Name of the resource in the form
+            of
+            projects/{project}/locations/{location}/cluster/{cluster}/users/{user}.
+        password (str):
+            Input only. Password for the user.
+        database_roles (MutableSequence[str]):
+            Optional. List of database roles this user
+            has. The database role strings are subject to
+            the PostgreSQL naming conventions.
+        user_type (google.cloud.alloydb_v1.types.User.UserType):
+            Optional. Type of this user.
+    """
+
+    class UserType(proto.Enum):
+        r"""Enum that details the user type.
+
+        Values:
+            USER_TYPE_UNSPECIFIED (0):
+                Unspecified user type.
+            ALLOYDB_BUILT_IN (1):
+                The default user type that authenticates via
+                password-based authentication.
+            ALLOYDB_IAM_USER (2):
+                Database user that can authenticate via
+                IAM-Based authentication.
+        """
+        USER_TYPE_UNSPECIFIED = 0
+        ALLOYDB_BUILT_IN = 1
+        ALLOYDB_IAM_USER = 2
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    password: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    database_roles: MutableSequence[str] = proto.RepeatedField(
+        proto.STRING,
+        number=4,
+    )
+    user_type: UserType = proto.Field(
+        proto.ENUM,
+        number=5,
+        enum=UserType,
+    )
+
+
 __all__ = tuple(sorted(__protobuf__.manifest))
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1/types/service.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/types/service.py`

 * *Files 12% similar despite different names*

```diff
@@ -26,40 +26,50 @@
 
 __protobuf__ = proto.module(
     package="google.cloud.alloydb.v1",
     manifest={
         "ListClustersRequest",
         "ListClustersResponse",
         "GetClusterRequest",
+        "CreateSecondaryClusterRequest",
         "CreateClusterRequest",
         "UpdateClusterRequest",
         "DeleteClusterRequest",
+        "PromoteClusterRequest",
         "RestoreClusterRequest",
         "ListInstancesRequest",
         "ListInstancesResponse",
         "GetInstanceRequest",
         "CreateInstanceRequest",
+        "CreateSecondaryInstanceRequest",
         "CreateInstanceRequests",
         "BatchCreateInstancesRequest",
         "BatchCreateInstancesResponse",
         "BatchCreateInstancesMetadata",
         "BatchCreateInstanceStatus",
         "UpdateInstanceRequest",
         "DeleteInstanceRequest",
         "FailoverInstanceRequest",
+        "InjectFaultRequest",
         "RestartInstanceRequest",
         "ListBackupsRequest",
         "ListBackupsResponse",
         "GetBackupRequest",
         "CreateBackupRequest",
         "UpdateBackupRequest",
         "DeleteBackupRequest",
         "ListSupportedDatabaseFlagsRequest",
         "ListSupportedDatabaseFlagsResponse",
         "OperationMetadata",
+        "ListUsersRequest",
+        "ListUsersResponse",
+        "GetUserRequest",
+        "CreateUserRequest",
+        "UpdateUserRequest",
+        "DeleteUserRequest",
     },
 )
 
 
 class ListClustersRequest(proto.Message):
     r"""Message for requesting list of Clusters
 
@@ -143,28 +153,98 @@
     r"""Message for getting a Cluster
 
     Attributes:
         name (str):
             Required. The name of the resource. For the
             required format, see the comment on the
             Cluster.name field.
+        view (google.cloud.alloydb_v1.types.ClusterView):
+            Optional. The view of the cluster to return.
+            Returns all default fields if not set.
     """
 
     name: str = proto.Field(
         proto.STRING,
         number=1,
     )
+    view: resources.ClusterView = proto.Field(
+        proto.ENUM,
+        number=2,
+        enum=resources.ClusterView,
+    )
+
+
+class CreateSecondaryClusterRequest(proto.Message):
+    r"""
+
+    Attributes:
+        parent (str):
+            Required. The location of the new cluster.
+            For the required format, see the comment on the
+            Cluster.name field.
+        cluster_id (str):
+            Required. ID of the requesting object (the
+            secondary cluster).
+        cluster (google.cloud.alloydb_v1.types.Cluster):
+            Required. Configuration of the requesting
+            object (the secondary cluster).
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes since the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, performs request validation
+            (e.g. permission checks and any other type of
+            validation), but do not actually execute the
+            create request.
+    """
+
+    parent: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    cluster_id: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    cluster: resources.Cluster = proto.Field(
+        proto.MESSAGE,
+        number=3,
+        message=resources.Cluster,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=5,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=6,
+    )
 
 
 class CreateClusterRequest(proto.Message):
     r"""Message for creating a Cluster
 
     Attributes:
         parent (str):
-            Required. The name of the parent resource.
+            Required. The location of the new cluster.
             For the required format, see the comment on the
             Cluster.name field.
         cluster_id (str):
             Required. ID of the requesting object.
         cluster (google.cloud.alloydb_v1.types.Cluster):
             Required. The resource being created
         request_id (str):
@@ -340,26 +420,92 @@
     )
     force: bool = proto.Field(
         proto.BOOL,
         number=5,
     )
 
 
+class PromoteClusterRequest(proto.Message):
+    r"""Message for promoting a Cluster
+
+    Attributes:
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            Cluster.name field
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes after the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        etag (str):
+            Optional. The current etag of the Cluster.
+            If an etag is provided and does not match the
+            current etag of the Cluster, deletion will be
+            blocked and an ABORTED error will be returned.
+        validate_only (bool):
+            Optional. If set, performs request validation
+            (e.g. permission checks and any other type of
+            validation), but do not actually execute the
+            delete.
+    """
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    etag: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=4,
+    )
+
+
 class RestoreClusterRequest(proto.Message):
     r"""Message for restoring a Cluster from a backup or another
     cluster at a given point in time.
 
+    This message has `oneof`_ fields (mutually exclusive fields).
+    For each oneof, at most one member field can be set at the same time.
+    Setting any member of the oneof automatically clears all other
+    members.
 
     .. _oneof: https://proto-plus-python.readthedocs.io/en/stable/fields.html#oneofs-mutually-exclusive-fields
 
     Attributes:
         backup_source (google.cloud.alloydb_v1.types.BackupSource):
             Backup source.
 
             This field is a member of `oneof`_ ``source``.
+        continuous_backup_source (google.cloud.alloydb_v1.types.ContinuousBackupSource):
+            ContinuousBackup source. Continuous backup
+            needs to be enabled in the source cluster for
+            this operation to succeed.
+
+            This field is a member of `oneof`_ ``source``.
         parent (str):
             Required. The name of the parent resource.
             For the required format, see the comment on the
             Cluster.name field.
         cluster_id (str):
             Required. ID of the requesting object.
         cluster (google.cloud.alloydb_v1.types.Cluster):
@@ -391,14 +537,20 @@
 
     backup_source: resources.BackupSource = proto.Field(
         proto.MESSAGE,
         number=4,
         oneof="source",
         message=resources.BackupSource,
     )
+    continuous_backup_source: resources.ContinuousBackupSource = proto.Field(
+        proto.MESSAGE,
+        number=8,
+        oneof="source",
+        message=resources.ContinuousBackupSource,
+    )
     parent: str = proto.Field(
         proto.STRING,
         number=1,
     )
     cluster_id: str = proto.Field(
         proto.STRING,
         number=2,
@@ -577,14 +729,74 @@
     )
     validate_only: bool = proto.Field(
         proto.BOOL,
         number=5,
     )
 
 
+class CreateSecondaryInstanceRequest(proto.Message):
+    r"""Message for creating a Secondary Instance
+
+    Attributes:
+        parent (str):
+            Required. The name of the parent resource.
+            For the required format, see the comment on the
+            Instance.name field.
+        instance_id (str):
+            Required. ID of the requesting object.
+        instance (google.cloud.alloydb_v1.types.Instance):
+            Required. The resource being created
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes since the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, performs request validation
+            (e.g. permission checks and any other type of
+            validation), but do not actually execute the
+            create request.
+    """
+
+    parent: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    instance_id: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    instance: resources.Instance = proto.Field(
+        proto.MESSAGE,
+        number=3,
+        message=resources.Instance,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=4,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=5,
+    )
+
+
 class CreateInstanceRequests(proto.Message):
     r"""See usage below for notes.
 
     Attributes:
         create_instance_requests (MutableSequence[google.cloud.alloydb_v1.types.CreateInstanceRequest]):
             Required. Primary and read replica instances
             to be created. This list should not be empty.
@@ -655,16 +867,16 @@
         proto.MESSAGE,
         number=1,
         message=resources.Instance,
     )
 
 
 class BatchCreateInstancesMetadata(proto.Message):
-    r"""Message for metadata that is specific to BatchCreateInstances
-    API.
+    r"""Message for metadata that is specific to BatchCreateInstances API.
+    NEXT_ID: 3
 
     Attributes:
         instance_targets (MutableSequence[str]):
             The instances being created in the API call.
             Each string in this list is the server defined
             resource path for target instances in the
             request and for the format of each string, see
@@ -701,18 +913,20 @@
     failed to create and the 4th was never picked up for creation
     because of failure of the previous one. Then, resulting states would
     look something like:
 
     1. Instance1 = ROLLED_BACK
     2. Instance2 = ROLLED_BACK
     3. Instance3 = FAILED
-    4. Instance4 = FAILED However, while the operation is running, the
-       instance might be in other states including PENDING_CREATE,
-       ACTIVE, DELETING and CREATING. The states / do not get further
-       updated once the operation is done.
+    4. Instance4 = FAILED
+
+    However, while the operation is running, the instance might be in
+    other states including PENDING_CREATE, ACTIVE, DELETING and
+    CREATING. The states / do not get further updated once the operation
+    is done.
 
     Attributes:
         state (google.cloud.alloydb_v1.types.BatchCreateInstanceStatus.State):
             The current state of an instance involved in the batch
             create operation. Once the operation is complete, the final
             state of the instances in the LRO can be one of:
 
@@ -955,14 +1169,82 @@
     )
     validate_only: bool = proto.Field(
         proto.BOOL,
         number=3,
     )
 
 
+class InjectFaultRequest(proto.Message):
+    r"""Message for triggering fault injection on an instance
+
+    Attributes:
+        fault_type (google.cloud.alloydb_v1.types.InjectFaultRequest.FaultType):
+            Required. The type of fault to be injected in
+            an instance.
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            Instance.name field.
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes after the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, performs request validation
+            (e.g. permission checks and any other type of
+            validation), but do not actually execute the
+            fault injection.
+    """
+
+    class FaultType(proto.Enum):
+        r"""FaultType contains all valid types of faults that can be
+        injected to an instance.
+
+        Values:
+            FAULT_TYPE_UNSPECIFIED (0):
+                The fault type is unknown.
+            STOP_VM (1):
+                Stop the VM
+        """
+        FAULT_TYPE_UNSPECIFIED = 0
+        STOP_VM = 1
+
+    fault_type: FaultType = proto.Field(
+        proto.ENUM,
+        number=1,
+        enum=FaultType,
+    )
+    name: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=4,
+    )
+
+
 class RestartInstanceRequest(proto.Message):
     r"""
 
     Attributes:
         name (str):
             Required. The name of the resource. For the
             required format, see the comment on the
@@ -1404,8 +1686,262 @@
     )
     api_version: str = proto.Field(
         proto.STRING,
         number=7,
     )
 
 
+class ListUsersRequest(proto.Message):
+    r"""Message for requesting list of Users
+
+    Attributes:
+        parent (str):
+            Required. Parent value for ListUsersRequest
+        page_size (int):
+            Optional. Requested page size. Server may
+            return fewer items than requested. If
+            unspecified, server will pick an appropriate
+            default.
+        page_token (str):
+            Optional. A token identifying a page of
+            results the server should return.
+        filter (str):
+            Optional. Filtering results
+        order_by (str):
+            Optional. Hint for how to order the results
+    """
+
+    parent: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    page_size: int = proto.Field(
+        proto.INT32,
+        number=2,
+    )
+    page_token: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    filter: str = proto.Field(
+        proto.STRING,
+        number=4,
+    )
+    order_by: str = proto.Field(
+        proto.STRING,
+        number=5,
+    )
+
+
+class ListUsersResponse(proto.Message):
+    r"""Message for response to listing Users
+
+    Attributes:
+        users (MutableSequence[google.cloud.alloydb_v1.types.User]):
+            The list of User
+        next_page_token (str):
+            A token identifying a page of results the
+            server should return.
+        unreachable (MutableSequence[str]):
+            Locations that could not be reached.
+    """
+
+    @property
+    def raw_page(self):
+        return self
+
+    users: MutableSequence[resources.User] = proto.RepeatedField(
+        proto.MESSAGE,
+        number=1,
+        message=resources.User,
+    )
+    next_page_token: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    unreachable: MutableSequence[str] = proto.RepeatedField(
+        proto.STRING,
+        number=3,
+    )
+
+
+class GetUserRequest(proto.Message):
+    r"""Message for getting a User
+
+    Attributes:
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            User.name field.
+    """
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+
+
+class CreateUserRequest(proto.Message):
+    r"""Message for creating a User
+
+    Attributes:
+        parent (str):
+            Required. Value for parent.
+        user_id (str):
+            Required. ID of the requesting object.
+        user (google.cloud.alloydb_v1.types.User):
+            Required. The resource being created
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes since the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, the backend validates the
+            request, but doesn't actually execute it.
+    """
+
+    parent: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    user_id: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    user: resources.User = proto.Field(
+        proto.MESSAGE,
+        number=3,
+        message=resources.User,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=4,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=5,
+    )
+
+
+class UpdateUserRequest(proto.Message):
+    r"""Message for updating a User
+
+    Attributes:
+        update_mask (google.protobuf.field_mask_pb2.FieldMask):
+            Optional. Field mask is used to specify the fields to be
+            overwritten in the User resource by the update. The fields
+            specified in the update_mask are relative to the resource,
+            not the full request. A field will be overwritten if it is
+            in the mask. If the user does not provide a mask then all
+            fields will be overwritten.
+        user (google.cloud.alloydb_v1.types.User):
+            Required. The resource being updated
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes since the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, the backend validates the
+            request, but doesn't actually execute it.
+        allow_missing (bool):
+            Optional. Allow missing fields in the update
+            mask.
+    """
+
+    update_mask: field_mask_pb2.FieldMask = proto.Field(
+        proto.MESSAGE,
+        number=1,
+        message=field_mask_pb2.FieldMask,
+    )
+    user: resources.User = proto.Field(
+        proto.MESSAGE,
+        number=2,
+        message=resources.User,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=4,
+    )
+    allow_missing: bool = proto.Field(
+        proto.BOOL,
+        number=5,
+    )
+
+
+class DeleteUserRequest(proto.Message):
+    r"""Message for deleting a User
+
+    Attributes:
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            User.name field.
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes after the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, the backend validates the
+            request, but doesn't actually execute it.
+    """
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=3,
+    )
+
+
 __all__ = tuple(sorted(__protobuf__.manifest))
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -20,115 +20,133 @@
 
 from .services.alloy_db_admin import AlloyDBAdminAsyncClient, AlloyDBAdminClient
 from .types.resources import (
     AutomatedBackupPolicy,
     Backup,
     BackupSource,
     Cluster,
+    ClusterView,
     ConnectionInfo,
     ContinuousBackupConfig,
     ContinuousBackupInfo,
     ContinuousBackupSource,
     DatabaseVersion,
     EncryptionConfig,
     EncryptionInfo,
     Instance,
     InstanceView,
     MigrationSource,
     SslConfig,
     SupportedDatabaseFlag,
+    User,
     UserPassword,
 )
 from .types.service import (
     BatchCreateInstancesMetadata,
     BatchCreateInstancesRequest,
     BatchCreateInstancesResponse,
     BatchCreateInstanceStatus,
     CreateBackupRequest,
     CreateClusterRequest,
     CreateInstanceRequest,
     CreateInstanceRequests,
     CreateSecondaryClusterRequest,
     CreateSecondaryInstanceRequest,
+    CreateUserRequest,
     DeleteBackupRequest,
     DeleteClusterRequest,
     DeleteInstanceRequest,
+    DeleteUserRequest,
     FailoverInstanceRequest,
     GenerateClientCertificateRequest,
     GenerateClientCertificateResponse,
     GetBackupRequest,
     GetClusterRequest,
     GetConnectionInfoRequest,
     GetInstanceRequest,
+    GetUserRequest,
+    InjectFaultRequest,
     ListBackupsRequest,
     ListBackupsResponse,
     ListClustersRequest,
     ListClustersResponse,
     ListInstancesRequest,
     ListInstancesResponse,
     ListSupportedDatabaseFlagsRequest,
     ListSupportedDatabaseFlagsResponse,
+    ListUsersRequest,
+    ListUsersResponse,
     OperationMetadata,
     PromoteClusterRequest,
     RestartInstanceRequest,
     RestoreClusterRequest,
     UpdateBackupRequest,
     UpdateClusterRequest,
     UpdateInstanceRequest,
+    UpdateUserRequest,
 )
 
 __all__ = (
     "AlloyDBAdminAsyncClient",
     "AlloyDBAdminClient",
     "AutomatedBackupPolicy",
     "Backup",
     "BackupSource",
     "BatchCreateInstanceStatus",
     "BatchCreateInstancesMetadata",
     "BatchCreateInstancesRequest",
     "BatchCreateInstancesResponse",
     "Cluster",
+    "ClusterView",
     "ConnectionInfo",
     "ContinuousBackupConfig",
     "ContinuousBackupInfo",
     "ContinuousBackupSource",
     "CreateBackupRequest",
     "CreateClusterRequest",
     "CreateInstanceRequest",
     "CreateInstanceRequests",
     "CreateSecondaryClusterRequest",
     "CreateSecondaryInstanceRequest",
+    "CreateUserRequest",
     "DatabaseVersion",
     "DeleteBackupRequest",
     "DeleteClusterRequest",
     "DeleteInstanceRequest",
+    "DeleteUserRequest",
     "EncryptionConfig",
     "EncryptionInfo",
     "FailoverInstanceRequest",
     "GenerateClientCertificateRequest",
     "GenerateClientCertificateResponse",
     "GetBackupRequest",
     "GetClusterRequest",
     "GetConnectionInfoRequest",
     "GetInstanceRequest",
+    "GetUserRequest",
+    "InjectFaultRequest",
     "Instance",
     "InstanceView",
     "ListBackupsRequest",
     "ListBackupsResponse",
     "ListClustersRequest",
     "ListClustersResponse",
     "ListInstancesRequest",
     "ListInstancesResponse",
     "ListSupportedDatabaseFlagsRequest",
     "ListSupportedDatabaseFlagsResponse",
+    "ListUsersRequest",
+    "ListUsersResponse",
     "MigrationSource",
     "OperationMetadata",
     "PromoteClusterRequest",
     "RestartInstanceRequest",
     "RestoreClusterRequest",
     "SslConfig",
     "SupportedDatabaseFlag",
     "UpdateBackupRequest",
     "UpdateClusterRequest",
     "UpdateInstanceRequest",
+    "UpdateUserRequest",
+    "User",
     "UserPassword",
 )
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/gapic_metadata.json` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/gapic_metadata.json`

 * *Files 10% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9994959677419355%*

 * *Differences: {"'services'": "{'AlloyDBAdmin': {'clients': {'grpc': {'rpcs': {'CreateUser': "*

 * *               "OrderedDict([('methods', ['create_user'])]), 'DeleteUser': "*

 * *               "OrderedDict([('methods', ['delete_user'])]), 'GetUser': OrderedDict([('methods', "*

 * *               "['get_user'])]), 'InjectFault': OrderedDict([('methods', ['inject_fault'])]), "*

 * *               "'ListUsers': OrderedDict([('methods', ['list_users'])]), 'UpdateUser': "*

 * *               "OrderedDict([('methods', ['update_user'])])}}, 'grpc-as [â€¦]*

```diff
@@ -36,14 +36,19 @@
                             ]
                         },
                         "CreateSecondaryInstance": {
                             "methods": [
                                 "create_secondary_instance"
                             ]
                         },
+                        "CreateUser": {
+                            "methods": [
+                                "create_user"
+                            ]
+                        },
                         "DeleteBackup": {
                             "methods": [
                                 "delete_backup"
                             ]
                         },
                         "DeleteCluster": {
                             "methods": [
@@ -51,14 +56,19 @@
                             ]
                         },
                         "DeleteInstance": {
                             "methods": [
                                 "delete_instance"
                             ]
                         },
+                        "DeleteUser": {
+                            "methods": [
+                                "delete_user"
+                            ]
+                        },
                         "FailoverInstance": {
                             "methods": [
                                 "failover_instance"
                             ]
                         },
                         "GenerateClientCertificate": {
                             "methods": [
@@ -81,14 +91,24 @@
                             ]
                         },
                         "GetInstance": {
                             "methods": [
                                 "get_instance"
                             ]
                         },
+                        "GetUser": {
+                            "methods": [
+                                "get_user"
+                            ]
+                        },
+                        "InjectFault": {
+                            "methods": [
+                                "inject_fault"
+                            ]
+                        },
                         "ListBackups": {
                             "methods": [
                                 "list_backups"
                             ]
                         },
                         "ListClusters": {
                             "methods": [
@@ -101,14 +121,19 @@
                             ]
                         },
                         "ListSupportedDatabaseFlags": {
                             "methods": [
                                 "list_supported_database_flags"
                             ]
                         },
+                        "ListUsers": {
+                            "methods": [
+                                "list_users"
+                            ]
+                        },
                         "PromoteCluster": {
                             "methods": [
                                 "promote_cluster"
                             ]
                         },
                         "RestartInstance": {
                             "methods": [
@@ -130,14 +155,19 @@
                                 "update_cluster"
                             ]
                         },
                         "UpdateInstance": {
                             "methods": [
                                 "update_instance"
                             ]
+                        },
+                        "UpdateUser": {
+                            "methods": [
+                                "update_user"
+                            ]
                         }
                     }
                 },
                 "grpc-async": {
                     "libraryClient": "AlloyDBAdminAsyncClient",
                     "rpcs": {
                         "BatchCreateInstances": {
@@ -166,14 +196,19 @@
                             ]
                         },
                         "CreateSecondaryInstance": {
                             "methods": [
                                 "create_secondary_instance"
                             ]
                         },
+                        "CreateUser": {
+                            "methods": [
+                                "create_user"
+                            ]
+                        },
                         "DeleteBackup": {
                             "methods": [
                                 "delete_backup"
                             ]
                         },
                         "DeleteCluster": {
                             "methods": [
@@ -181,14 +216,19 @@
                             ]
                         },
                         "DeleteInstance": {
                             "methods": [
                                 "delete_instance"
                             ]
                         },
+                        "DeleteUser": {
+                            "methods": [
+                                "delete_user"
+                            ]
+                        },
                         "FailoverInstance": {
                             "methods": [
                                 "failover_instance"
                             ]
                         },
                         "GenerateClientCertificate": {
                             "methods": [
@@ -211,14 +251,24 @@
                             ]
                         },
                         "GetInstance": {
                             "methods": [
                                 "get_instance"
                             ]
                         },
+                        "GetUser": {
+                            "methods": [
+                                "get_user"
+                            ]
+                        },
+                        "InjectFault": {
+                            "methods": [
+                                "inject_fault"
+                            ]
+                        },
                         "ListBackups": {
                             "methods": [
                                 "list_backups"
                             ]
                         },
                         "ListClusters": {
                             "methods": [
@@ -231,14 +281,19 @@
                             ]
                         },
                         "ListSupportedDatabaseFlags": {
                             "methods": [
                                 "list_supported_database_flags"
                             ]
                         },
+                        "ListUsers": {
+                            "methods": [
+                                "list_users"
+                            ]
+                        },
                         "PromoteCluster": {
                             "methods": [
                                 "promote_cluster"
                             ]
                         },
                         "RestartInstance": {
                             "methods": [
@@ -260,14 +315,19 @@
                                 "update_cluster"
                             ]
                         },
                         "UpdateInstance": {
                             "methods": [
                                 "update_instance"
                             ]
+                        },
+                        "UpdateUser": {
+                            "methods": [
+                                "update_user"
+                            ]
                         }
                     }
                 },
                 "rest": {
                     "libraryClient": "AlloyDBAdminClient",
                     "rpcs": {
                         "BatchCreateInstances": {
@@ -296,14 +356,19 @@
                             ]
                         },
                         "CreateSecondaryInstance": {
                             "methods": [
                                 "create_secondary_instance"
                             ]
                         },
+                        "CreateUser": {
+                            "methods": [
+                                "create_user"
+                            ]
+                        },
                         "DeleteBackup": {
                             "methods": [
                                 "delete_backup"
                             ]
                         },
                         "DeleteCluster": {
                             "methods": [
@@ -311,14 +376,19 @@
                             ]
                         },
                         "DeleteInstance": {
                             "methods": [
                                 "delete_instance"
                             ]
                         },
+                        "DeleteUser": {
+                            "methods": [
+                                "delete_user"
+                            ]
+                        },
                         "FailoverInstance": {
                             "methods": [
                                 "failover_instance"
                             ]
                         },
                         "GenerateClientCertificate": {
                             "methods": [
@@ -341,14 +411,24 @@
                             ]
                         },
                         "GetInstance": {
                             "methods": [
                                 "get_instance"
                             ]
                         },
+                        "GetUser": {
+                            "methods": [
+                                "get_user"
+                            ]
+                        },
+                        "InjectFault": {
+                            "methods": [
+                                "inject_fault"
+                            ]
+                        },
                         "ListBackups": {
                             "methods": [
                                 "list_backups"
                             ]
                         },
                         "ListClusters": {
                             "methods": [
@@ -361,14 +441,19 @@
                             ]
                         },
                         "ListSupportedDatabaseFlags": {
                             "methods": [
                                 "list_supported_database_flags"
                             ]
                         },
+                        "ListUsers": {
+                            "methods": [
+                                "list_users"
+                            ]
+                        },
                         "PromoteCluster": {
                             "methods": [
                                 "promote_cluster"
                             ]
                         },
                         "RestartInstance": {
                             "methods": [
@@ -390,14 +475,19 @@
                                 "update_cluster"
                             ]
                         },
                         "UpdateInstance": {
                             "methods": [
                                 "update_instance"
                             ]
+                        },
+                        "UpdateUser": {
+                            "methods": [
+                                "update_user"
+                            ]
                         }
                     }
                 }
             }
         }
     }
 }
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/gapic_version.py` & `google-cloud-alloydb-0.2.0/tests/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,17 +1,15 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2022 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-
-__version__ = "0.1.1"  # {x-release-please-version}
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/__init__.py` & `google-cloud-alloydb-0.2.0/tests/unit/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/async_client.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/async_client.py`

 * *Files 8% similar despite different names*

```diff
@@ -86,14 +86,16 @@
     parse_network_path = staticmethod(AlloyDBAdminClient.parse_network_path)
     supported_database_flag_path = staticmethod(
         AlloyDBAdminClient.supported_database_flag_path
     )
     parse_supported_database_flag_path = staticmethod(
         AlloyDBAdminClient.parse_supported_database_flag_path
     )
+    user_path = staticmethod(AlloyDBAdminClient.user_path)
+    parse_user_path = staticmethod(AlloyDBAdminClient.parse_user_path)
     common_billing_account_path = staticmethod(
         AlloyDBAdminClient.common_billing_account_path
     )
     parse_common_billing_account_path = staticmethod(
         AlloyDBAdminClient.parse_common_billing_account_path
     )
     common_folder_path = staticmethod(AlloyDBAdminClient.common_folder_path)
@@ -534,16 +536,16 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Optional[Union[google.cloud.alloydb_v1alpha.types.CreateClusterRequest, dict]]):
                 The request object. Message for creating a Cluster
             parent (:class:`str`):
-                Required. The name of the parent
-                resource. For the required format, see
+                Required. The location of the new
+                cluster. For the required format, see
                 the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (:class:`google.cloud.alloydb_v1alpha.types.Cluster`):
                 Required. The resource being created
@@ -1167,18 +1169,17 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Optional[Union[google.cloud.alloydb_v1alpha.types.CreateSecondaryClusterRequest, dict]]):
                 The request object.
             parent (:class:`str`):
-                Required. The name of the parent
-                resource (the primary cluster). For the
-                required format, see the comment on the
-                Cluster.name field.
+                Required. The location of the new
+                cluster. For the required format, see
+                the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (:class:`google.cloud.alloydb_v1alpha.types.Cluster`):
                 Required. Configuration of the
                 requesting object (the secondary
@@ -2272,14 +2273,143 @@
             resources.Instance,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    async def inject_fault(
+        self,
+        request: Optional[Union[service.InjectFaultRequest, dict]] = None,
+        *,
+        fault_type: Optional[service.InjectFaultRequest.FaultType] = None,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation_async.AsyncOperation:
+        r"""Injects fault in an instance.
+        Imperative only.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            async def sample_inject_fault():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.InjectFaultRequest(
+                    fault_type="STOP_VM",
+                    name="name_value",
+                )
+
+                # Make the request
+                operation = client.inject_fault(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = (await operation).result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1alpha.types.InjectFaultRequest, dict]]):
+                The request object. Message for triggering fault
+                injection on an instance
+            fault_type (:class:`google.cloud.alloydb_v1alpha.types.InjectFaultRequest.FaultType`):
+                Required. The type of fault to be
+                injected in an instance.
+
+                This corresponds to the ``fault_type`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the Instance.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation_async.AsyncOperation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1alpha.types.Instance` An Instance is a computing unit that an end customer can connect to.
+                   It's the main unit of computing resources in AlloyDB.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([fault_type, name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.InjectFaultRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if fault_type is not None:
+            request.fault_type = fault_type
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.inject_fault,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation_async.from_gapic(
+            response,
+            self._client._transport.operations_client,
+            resources.Instance,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     async def restart_instance(
         self,
         request: Optional[Union[service.RestartInstanceRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -3378,14 +3508,564 @@
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
+    async def list_users(
+        self,
+        request: Optional[Union[service.ListUsersRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> pagers.ListUsersAsyncPager:
+        r"""Lists Users in a given project and location.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            async def sample_list_users():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.ListUsersRequest(
+                    parent="parent_value",
+                )
+
+                # Make the request
+                page_result = client.list_users(request=request)
+
+                # Handle the response
+                async for response in page_result:
+                    print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1alpha.types.ListUsersRequest, dict]]):
+                The request object. Message for requesting list of Users
+            parent (:class:`str`):
+                Required. Parent value for
+                ListUsersRequest
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1alpha.services.alloy_db_admin.pagers.ListUsersAsyncPager:
+                Message for response to listing Users
+                Iterating over this object will yield
+                results and resolve additional pages
+                automatically.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.ListUsersRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.list_users,
+            default_retry=retries.Retry(
+                initial=1.0,
+                maximum=60.0,
+                multiplier=1.3,
+                predicate=retries.if_exception_type(
+                    core_exceptions.ServiceUnavailable,
+                ),
+                deadline=60.0,
+            ),
+            default_timeout=60.0,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # This method is paged; wrap the response in a pager, which provides
+        # an `__aiter__` convenience method.
+        response = pagers.ListUsersAsyncPager(
+            method=rpc,
+            request=request,
+            response=response,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def get_user(
+        self,
+        request: Optional[Union[service.GetUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Gets details of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            async def sample_get_user():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.GetUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                response = await client.get_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1alpha.types.GetUserRequest, dict]]):
+                The request object. Message for getting a User
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1alpha.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.GetUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.get_user,
+            default_retry=retries.Retry(
+                initial=1.0,
+                maximum=60.0,
+                multiplier=1.3,
+                predicate=retries.if_exception_type(
+                    core_exceptions.ServiceUnavailable,
+                ),
+                deadline=60.0,
+            ),
+            default_timeout=60.0,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def create_user(
+        self,
+        request: Optional[Union[service.CreateUserRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        user: Optional[resources.User] = None,
+        user_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Creates a new User in a given project, location, and
+        cluster.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            async def sample_create_user():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.CreateUserRequest(
+                    parent="parent_value",
+                    user_id="user_id_value",
+                )
+
+                # Make the request
+                response = await client.create_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1alpha.types.CreateUserRequest, dict]]):
+                The request object. Message for creating a User
+            parent (:class:`str`):
+                Required. Value for parent.
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user (:class:`google.cloud.alloydb_v1alpha.types.User`):
+                Required. The resource being created
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user_id (:class:`str`):
+                Required. ID of the requesting
+                object.
+
+                This corresponds to the ``user_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1alpha.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, user, user_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.CreateUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+        if user is not None:
+            request.user = user
+        if user_id is not None:
+            request.user_id = user_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.create_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def update_user(
+        self,
+        request: Optional[Union[service.UpdateUserRequest, dict]] = None,
+        *,
+        user: Optional[resources.User] = None,
+        update_mask: Optional[field_mask_pb2.FieldMask] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Updates the parameters of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            async def sample_update_user():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.UpdateUserRequest(
+                )
+
+                # Make the request
+                response = await client.update_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1alpha.types.UpdateUserRequest, dict]]):
+                The request object. Message for updating a User
+            user (:class:`google.cloud.alloydb_v1alpha.types.User`):
+                Required. The resource being updated
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
+                Optional. Field mask is used to specify the fields to be
+                overwritten in the User resource by the update. The
+                fields specified in the update_mask are relative to the
+                resource, not the full request. A field will be
+                overwritten if it is in the mask. If the user does not
+                provide a mask then all fields will be overwritten.
+
+                This corresponds to the ``update_mask`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1alpha.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([user, update_mask])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.UpdateUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if user is not None:
+            request.user = user
+        if update_mask is not None:
+            request.update_mask = update_mask
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.update_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata(
+                (("user.name", request.user.name),)
+            ),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def delete_user(
+        self,
+        request: Optional[Union[service.DeleteUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> None:
+        r"""Deletes a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            async def sample_delete_user():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.DeleteUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                await client.delete_user(request=request)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1alpha.types.DeleteUserRequest, dict]]):
+                The request object. Message for deleting a User
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.DeleteUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.delete_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
     async def list_operations(
         self,
         request: Optional[operations_pb2.ListOperationsRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/client.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/client.py`

 * *Files 1% similar despite different names*

```diff
@@ -341,14 +341,38 @@
         m = re.match(
             r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/flags/(?P<flag>.+?)$",
             path,
         )
         return m.groupdict() if m else {}
 
     @staticmethod
+    def user_path(
+        project: str,
+        location: str,
+        cluster: str,
+        user: str,
+    ) -> str:
+        """Returns a fully-qualified user string."""
+        return "projects/{project}/locations/{location}/clusters/{cluster}/users/{user}".format(
+            project=project,
+            location=location,
+            cluster=cluster,
+            user=user,
+        )
+
+    @staticmethod
+    def parse_user_path(path: str) -> Dict[str, str]:
+        """Parses a user path into its component segments."""
+        m = re.match(
+            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/clusters/(?P<cluster>.+?)/users/(?P<user>.+?)$",
+            path,
+        )
+        return m.groupdict() if m else {}
+
+    @staticmethod
     def common_billing_account_path(
         billing_account: str,
     ) -> str:
         """Returns a fully-qualified billing_account string."""
         return "billingAccounts/{billing_account}".format(
             billing_account=billing_account,
         )
@@ -864,16 +888,16 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Union[google.cloud.alloydb_v1alpha.types.CreateClusterRequest, dict]):
                 The request object. Message for creating a Cluster
             parent (str):
-                Required. The name of the parent
-                resource. For the required format, see
+                Required. The location of the new
+                cluster. For the required format, see
                 the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (google.cloud.alloydb_v1alpha.types.Cluster):
                 Required. The resource being created
@@ -1498,18 +1522,17 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Union[google.cloud.alloydb_v1alpha.types.CreateSecondaryClusterRequest, dict]):
                 The request object.
             parent (str):
-                Required. The name of the parent
-                resource (the primary cluster). For the
-                required format, see the comment on the
-                Cluster.name field.
+                Required. The location of the new
+                cluster. For the required format, see
+                the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (google.cloud.alloydb_v1alpha.types.Cluster):
                 Required. Configuration of the
                 requesting object (the secondary
@@ -2588,14 +2611,143 @@
             resources.Instance,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    def inject_fault(
+        self,
+        request: Optional[Union[service.InjectFaultRequest, dict]] = None,
+        *,
+        fault_type: Optional[service.InjectFaultRequest.FaultType] = None,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation.Operation:
+        r"""Injects fault in an instance.
+        Imperative only.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            def sample_inject_fault():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.InjectFaultRequest(
+                    fault_type="STOP_VM",
+                    name="name_value",
+                )
+
+                # Make the request
+                operation = client.inject_fault(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = operation.result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1alpha.types.InjectFaultRequest, dict]):
+                The request object. Message for triggering fault
+                injection on an instance
+            fault_type (google.cloud.alloydb_v1alpha.types.InjectFaultRequest.FaultType):
+                Required. The type of fault to be
+                injected in an instance.
+
+                This corresponds to the ``fault_type`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the Instance.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation.Operation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1alpha.types.Instance` An Instance is a computing unit that an end customer can connect to.
+                   It's the main unit of computing resources in AlloyDB.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([fault_type, name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.InjectFaultRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.InjectFaultRequest):
+            request = service.InjectFaultRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if fault_type is not None:
+                request.fault_type = fault_type
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.inject_fault]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation.from_gapic(
+            response,
+            self._transport.operations_client,
+            resources.Instance,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     def restart_instance(
         self,
         request: Optional[Union[service.RestartInstanceRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -3653,14 +3805,546 @@
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
+    def list_users(
+        self,
+        request: Optional[Union[service.ListUsersRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> pagers.ListUsersPager:
+        r"""Lists Users in a given project and location.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            def sample_list_users():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.ListUsersRequest(
+                    parent="parent_value",
+                )
+
+                # Make the request
+                page_result = client.list_users(request=request)
+
+                # Handle the response
+                for response in page_result:
+                    print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1alpha.types.ListUsersRequest, dict]):
+                The request object. Message for requesting list of Users
+            parent (str):
+                Required. Parent value for
+                ListUsersRequest
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1alpha.services.alloy_db_admin.pagers.ListUsersPager:
+                Message for response to listing Users
+                Iterating over this object will yield
+                results and resolve additional pages
+                automatically.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.ListUsersRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.ListUsersRequest):
+            request = service.ListUsersRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.list_users]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # This method is paged; wrap the response in a pager, which provides
+        # an `__iter__` convenience method.
+        response = pagers.ListUsersPager(
+            method=rpc,
+            request=request,
+            response=response,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def get_user(
+        self,
+        request: Optional[Union[service.GetUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Gets details of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            def sample_get_user():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.GetUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                response = client.get_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1alpha.types.GetUserRequest, dict]):
+                The request object. Message for getting a User
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1alpha.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.GetUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.GetUserRequest):
+            request = service.GetUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.get_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def create_user(
+        self,
+        request: Optional[Union[service.CreateUserRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        user: Optional[resources.User] = None,
+        user_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Creates a new User in a given project, location, and
+        cluster.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            def sample_create_user():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.CreateUserRequest(
+                    parent="parent_value",
+                    user_id="user_id_value",
+                )
+
+                # Make the request
+                response = client.create_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1alpha.types.CreateUserRequest, dict]):
+                The request object. Message for creating a User
+            parent (str):
+                Required. Value for parent.
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user (google.cloud.alloydb_v1alpha.types.User):
+                Required. The resource being created
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user_id (str):
+                Required. ID of the requesting
+                object.
+
+                This corresponds to the ``user_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1alpha.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, user, user_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.CreateUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.CreateUserRequest):
+            request = service.CreateUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+            if user is not None:
+                request.user = user
+            if user_id is not None:
+                request.user_id = user_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.create_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def update_user(
+        self,
+        request: Optional[Union[service.UpdateUserRequest, dict]] = None,
+        *,
+        user: Optional[resources.User] = None,
+        update_mask: Optional[field_mask_pb2.FieldMask] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Updates the parameters of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            def sample_update_user():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.UpdateUserRequest(
+                )
+
+                # Make the request
+                response = client.update_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1alpha.types.UpdateUserRequest, dict]):
+                The request object. Message for updating a User
+            user (google.cloud.alloydb_v1alpha.types.User):
+                Required. The resource being updated
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            update_mask (google.protobuf.field_mask_pb2.FieldMask):
+                Optional. Field mask is used to specify the fields to be
+                overwritten in the User resource by the update. The
+                fields specified in the update_mask are relative to the
+                resource, not the full request. A field will be
+                overwritten if it is in the mask. If the user does not
+                provide a mask then all fields will be overwritten.
+
+                This corresponds to the ``update_mask`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1alpha.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([user, update_mask])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.UpdateUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.UpdateUserRequest):
+            request = service.UpdateUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if user is not None:
+                request.user = user
+            if update_mask is not None:
+                request.update_mask = update_mask
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.update_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata(
+                (("user.name", request.user.name),)
+            ),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def delete_user(
+        self,
+        request: Optional[Union[service.DeleteUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> None:
+        r"""Deletes a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1alpha
+
+            def sample_delete_user():
+                # Create a client
+                client = alloydb_v1alpha.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1alpha.DeleteUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                client.delete_user(request=request)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1alpha.types.DeleteUserRequest, dict]):
+                The request object. Message for deleting a User
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.DeleteUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.DeleteUserRequest):
+            request = service.DeleteUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.delete_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
     def __enter__(self) -> "AlloyDBAdminClient":
         return self
 
     def __exit__(self, type, value, traceback):
         """Releases underlying transport's resources.
 
         .. warning::
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/pagers.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/pagers.py`

 * *Files 13% similar despite different names*

```diff
@@ -533,7 +533,135 @@
                 for response in page.supported_database_flags:
                     yield response
 
         return async_generator()
 
     def __repr__(self) -> str:
         return "{0}<{1!r}>".format(self.__class__.__name__, self._response)
+
+
+class ListUsersPager:
+    """A pager for iterating through ``list_users`` requests.
+
+    This class thinly wraps an initial
+    :class:`google.cloud.alloydb_v1alpha.types.ListUsersResponse` object, and
+    provides an ``__iter__`` method to iterate through its
+    ``users`` field.
+
+    If there are more pages, the ``__iter__`` method will make additional
+    ``ListUsers`` requests and continue to iterate
+    through the ``users`` field on the
+    corresponding responses.
+
+    All the usual :class:`google.cloud.alloydb_v1alpha.types.ListUsersResponse`
+    attributes are available on the pager. If multiple requests are made, only
+    the most recent response is retained, and thus used for attribute lookup.
+    """
+
+    def __init__(
+        self,
+        method: Callable[..., service.ListUsersResponse],
+        request: service.ListUsersRequest,
+        response: service.ListUsersResponse,
+        *,
+        metadata: Sequence[Tuple[str, str]] = ()
+    ):
+        """Instantiate the pager.
+
+        Args:
+            method (Callable): The method that was originally called, and
+                which instantiated this pager.
+            request (google.cloud.alloydb_v1alpha.types.ListUsersRequest):
+                The initial request object.
+            response (google.cloud.alloydb_v1alpha.types.ListUsersResponse):
+                The initial response object.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        self._method = method
+        self._request = service.ListUsersRequest(request)
+        self._response = response
+        self._metadata = metadata
+
+    def __getattr__(self, name: str) -> Any:
+        return getattr(self._response, name)
+
+    @property
+    def pages(self) -> Iterator[service.ListUsersResponse]:
+        yield self._response
+        while self._response.next_page_token:
+            self._request.page_token = self._response.next_page_token
+            self._response = self._method(self._request, metadata=self._metadata)
+            yield self._response
+
+    def __iter__(self) -> Iterator[resources.User]:
+        for page in self.pages:
+            yield from page.users
+
+    def __repr__(self) -> str:
+        return "{0}<{1!r}>".format(self.__class__.__name__, self._response)
+
+
+class ListUsersAsyncPager:
+    """A pager for iterating through ``list_users`` requests.
+
+    This class thinly wraps an initial
+    :class:`google.cloud.alloydb_v1alpha.types.ListUsersResponse` object, and
+    provides an ``__aiter__`` method to iterate through its
+    ``users`` field.
+
+    If there are more pages, the ``__aiter__`` method will make additional
+    ``ListUsers`` requests and continue to iterate
+    through the ``users`` field on the
+    corresponding responses.
+
+    All the usual :class:`google.cloud.alloydb_v1alpha.types.ListUsersResponse`
+    attributes are available on the pager. If multiple requests are made, only
+    the most recent response is retained, and thus used for attribute lookup.
+    """
+
+    def __init__(
+        self,
+        method: Callable[..., Awaitable[service.ListUsersResponse]],
+        request: service.ListUsersRequest,
+        response: service.ListUsersResponse,
+        *,
+        metadata: Sequence[Tuple[str, str]] = ()
+    ):
+        """Instantiates the pager.
+
+        Args:
+            method (Callable): The method that was originally called, and
+                which instantiated this pager.
+            request (google.cloud.alloydb_v1alpha.types.ListUsersRequest):
+                The initial request object.
+            response (google.cloud.alloydb_v1alpha.types.ListUsersResponse):
+                The initial response object.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        self._method = method
+        self._request = service.ListUsersRequest(request)
+        self._response = response
+        self._metadata = metadata
+
+    def __getattr__(self, name: str) -> Any:
+        return getattr(self._response, name)
+
+    @property
+    async def pages(self) -> AsyncIterator[service.ListUsersResponse]:
+        yield self._response
+        while self._response.next_page_token:
+            self._request.page_token = self._response.next_page_token
+            self._response = await self._method(self._request, metadata=self._metadata)
+            yield self._response
+
+    def __aiter__(self) -> AsyncIterator[resources.User]:
+        async def async_generator():
+            async for page in self.pages:
+                for response in page.users:
+                    yield response
+
+        return async_generator()
+
+    def __repr__(self) -> str:
+        return "{0}<{1!r}>".format(self.__class__.__name__, self._response)
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/base.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,14 +23,15 @@
 import google.auth  # type: ignore
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 from google.oauth2 import service_account  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 
 from google.cloud.alloydb_v1alpha import gapic_version as package_version
 from google.cloud.alloydb_v1alpha.types import resources, service
 
 DEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(
     gapic_version=package_version.__version__
 )
@@ -238,14 +239,19 @@
                 client_info=client_info,
             ),
             self.failover_instance: gapic_v1.method.wrap_method(
                 self.failover_instance,
                 default_timeout=None,
                 client_info=client_info,
             ),
+            self.inject_fault: gapic_v1.method.wrap_method(
+                self.inject_fault,
+                default_timeout=None,
+                client_info=client_info,
+            ),
             self.restart_instance: gapic_v1.method.wrap_method(
                 self.restart_instance,
                 default_timeout=None,
                 client_info=client_info,
             ),
             self.list_backups: gapic_v1.method.wrap_method(
                 self.list_backups,
@@ -328,14 +334,57 @@
                         core_exceptions.ServiceUnavailable,
                     ),
                     deadline=60.0,
                 ),
                 default_timeout=60.0,
                 client_info=client_info,
             ),
+            self.list_users: gapic_v1.method.wrap_method(
+                self.list_users,
+                default_retry=retries.Retry(
+                    initial=1.0,
+                    maximum=60.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.get_user: gapic_v1.method.wrap_method(
+                self.get_user,
+                default_retry=retries.Retry(
+                    initial=1.0,
+                    maximum=60.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.create_user: gapic_v1.method.wrap_method(
+                self.create_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.update_user: gapic_v1.method.wrap_method(
+                self.update_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.delete_user: gapic_v1.method.wrap_method(
+                self.delete_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
         }
 
     def close(self):
         """Closes resources associated with the transport.
 
         .. warning::
              Only call this method if the transport is NOT shared
@@ -489,14 +538,23 @@
     ) -> Callable[
         [service.FailoverInstanceRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
 
     @property
+    def inject_fault(
+        self,
+    ) -> Callable[
+        [service.InjectFaultRequest],
+        Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
+    ]:
+        raise NotImplementedError()
+
+    @property
     def restart_instance(
         self,
     ) -> Callable[
         [service.RestartInstanceRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
@@ -575,14 +633,55 @@
     ) -> Callable[
         [service.GetConnectionInfoRequest],
         Union[resources.ConnectionInfo, Awaitable[resources.ConnectionInfo]],
     ]:
         raise NotImplementedError()
 
     @property
+    def list_users(
+        self,
+    ) -> Callable[
+        [service.ListUsersRequest],
+        Union[service.ListUsersResponse, Awaitable[service.ListUsersResponse]],
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def get_user(
+        self,
+    ) -> Callable[
+        [service.GetUserRequest], Union[resources.User, Awaitable[resources.User]]
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def create_user(
+        self,
+    ) -> Callable[
+        [service.CreateUserRequest], Union[resources.User, Awaitable[resources.User]]
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def update_user(
+        self,
+    ) -> Callable[
+        [service.UpdateUserRequest], Union[resources.User, Awaitable[resources.User]]
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def delete_user(
+        self,
+    ) -> Callable[
+        [service.DeleteUserRequest], Union[empty_pb2.Empty, Awaitable[empty_pb2.Empty]]
+    ]:
+        raise NotImplementedError()
+
+    @property
     def list_operations(
         self,
     ) -> Callable[
         [operations_pb2.ListOperationsRequest],
         Union[
             operations_pb2.ListOperationsResponse,
             Awaitable[operations_pb2.ListOperationsResponse],
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/grpc.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/grpc.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,14 +20,15 @@
 import google.auth  # type: ignore
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 import grpc  # type: ignore
 
 from google.cloud.alloydb_v1alpha.types import resources, service
 
 from .base import DEFAULT_CLIENT_INFO, AlloyDBAdminTransport
 
 
@@ -682,14 +683,41 @@
                 "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/FailoverInstance",
                 request_serializer=service.FailoverInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["failover_instance"]
 
     @property
+    def inject_fault(
+        self,
+    ) -> Callable[[service.InjectFaultRequest], operations_pb2.Operation]:
+        r"""Return a callable for the inject fault method over gRPC.
+
+        Injects fault in an instance.
+        Imperative only.
+
+        Returns:
+            Callable[[~.InjectFaultRequest],
+                    ~.Operation]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "inject_fault" not in self._stubs:
+            self._stubs["inject_fault"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/InjectFault",
+                request_serializer=service.InjectFaultRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["inject_fault"]
+
+    @property
     def restart_instance(
         self,
     ) -> Callable[[service.RestartInstanceRequest], operations_pb2.Operation]:
         r"""Return a callable for the restart instance method over gRPC.
 
         Restart an Instance in a cluster.
         Imperative only.
@@ -928,14 +956,137 @@
             self._stubs["get_connection_info"] = self.grpc_channel.unary_unary(
                 "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetConnectionInfo",
                 request_serializer=service.GetConnectionInfoRequest.serialize,
                 response_deserializer=resources.ConnectionInfo.deserialize,
             )
         return self._stubs["get_connection_info"]
 
+    @property
+    def list_users(
+        self,
+    ) -> Callable[[service.ListUsersRequest], service.ListUsersResponse]:
+        r"""Return a callable for the list users method over gRPC.
+
+        Lists Users in a given project and location.
+
+        Returns:
+            Callable[[~.ListUsersRequest],
+                    ~.ListUsersResponse]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "list_users" not in self._stubs:
+            self._stubs["list_users"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListUsers",
+                request_serializer=service.ListUsersRequest.serialize,
+                response_deserializer=service.ListUsersResponse.deserialize,
+            )
+        return self._stubs["list_users"]
+
+    @property
+    def get_user(self) -> Callable[[service.GetUserRequest], resources.User]:
+        r"""Return a callable for the get user method over gRPC.
+
+        Gets details of a single User.
+
+        Returns:
+            Callable[[~.GetUserRequest],
+                    ~.User]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "get_user" not in self._stubs:
+            self._stubs["get_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetUser",
+                request_serializer=service.GetUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["get_user"]
+
+    @property
+    def create_user(self) -> Callable[[service.CreateUserRequest], resources.User]:
+        r"""Return a callable for the create user method over gRPC.
+
+        Creates a new User in a given project, location, and
+        cluster.
+
+        Returns:
+            Callable[[~.CreateUserRequest],
+                    ~.User]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_user" not in self._stubs:
+            self._stubs["create_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateUser",
+                request_serializer=service.CreateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["create_user"]
+
+    @property
+    def update_user(self) -> Callable[[service.UpdateUserRequest], resources.User]:
+        r"""Return a callable for the update user method over gRPC.
+
+        Updates the parameters of a single User.
+
+        Returns:
+            Callable[[~.UpdateUserRequest],
+                    ~.User]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "update_user" not in self._stubs:
+            self._stubs["update_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/UpdateUser",
+                request_serializer=service.UpdateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["update_user"]
+
+    @property
+    def delete_user(self) -> Callable[[service.DeleteUserRequest], empty_pb2.Empty]:
+        r"""Return a callable for the delete user method over gRPC.
+
+        Deletes a single User.
+
+        Returns:
+            Callable[[~.DeleteUserRequest],
+                    ~.Empty]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "delete_user" not in self._stubs:
+            self._stubs["delete_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/DeleteUser",
+                request_serializer=service.DeleteUserRequest.serialize,
+                response_deserializer=empty_pb2.Empty.FromString,
+            )
+        return self._stubs["delete_user"]
+
     def close(self):
         self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/grpc_asyncio.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/grpc.py`

 * *Files 3% similar despite different names*

```diff
@@ -9,100 +9,56 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from typing import Awaitable, Callable, Dict, Optional, Sequence, Tuple, Union
+from typing import Callable, Dict, Optional, Sequence, Tuple, Union
 import warnings
 
-from google.api_core import gapic_v1, grpc_helpers_async, operations_v1
+from google.api_core import gapic_v1, grpc_helpers, operations_v1
+import google.auth  # type: ignore
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 import grpc  # type: ignore
-from grpc.experimental import aio  # type: ignore
 
-from google.cloud.alloydb_v1alpha.types import resources, service
+from google.cloud.alloydb_v1beta.types import resources, service
 
 from .base import DEFAULT_CLIENT_INFO, AlloyDBAdminTransport
-from .grpc import AlloyDBAdminGrpcTransport
 
 
-class AlloyDBAdminGrpcAsyncIOTransport(AlloyDBAdminTransport):
-    """gRPC AsyncIO backend transport for AlloyDBAdmin.
+class AlloyDBAdminGrpcTransport(AlloyDBAdminTransport):
+    """gRPC backend transport for AlloyDBAdmin.
 
     Service describing handlers for resources
 
     This class defines the same methods as the primary client, so the
     primary client can load the underlying transport implementation
     and call it.
 
     It sends protocol buffers over the wire using gRPC (which is built on
     top of HTTP/2); the ``grpcio`` package must be installed.
     """
 
-    _grpc_channel: aio.Channel
-    _stubs: Dict[str, Callable] = {}
-
-    @classmethod
-    def create_channel(
-        cls,
-        host: str = "alloydb.googleapis.com",
-        credentials: Optional[ga_credentials.Credentials] = None,
-        credentials_file: Optional[str] = None,
-        scopes: Optional[Sequence[str]] = None,
-        quota_project_id: Optional[str] = None,
-        **kwargs,
-    ) -> aio.Channel:
-        """Create and return a gRPC AsyncIO channel object.
-        Args:
-            host (Optional[str]): The host for the channel to use.
-            credentials (Optional[~.Credentials]): The
-                authorization credentials to attach to requests. These
-                credentials identify this application to the service. If
-                none are specified, the client will attempt to ascertain
-                the credentials from the environment.
-            credentials_file (Optional[str]): A file with credentials that can
-                be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
-            scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
-                service. These are only used when credentials are not specified and
-                are passed to :func:`google.auth.default`.
-            quota_project_id (Optional[str]): An optional project to use for billing
-                and quota.
-            kwargs (Optional[dict]): Keyword arguments, which are passed to the
-                channel creation.
-        Returns:
-            aio.Channel: A gRPC AsyncIO channel object.
-        """
-
-        return grpc_helpers_async.create_channel(
-            host,
-            credentials=credentials,
-            credentials_file=credentials_file,
-            quota_project_id=quota_project_id,
-            default_scopes=cls.AUTH_SCOPES,
-            scopes=scopes,
-            default_host=cls.DEFAULT_HOST,
-            **kwargs,
-        )
+    _stubs: Dict[str, Callable]
 
     def __init__(
         self,
         *,
         host: str = "alloydb.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[aio.Channel] = None,
+        channel: Optional[grpc.Channel] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
@@ -118,18 +74,17 @@
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
                 This argument is ignored if ``channel`` is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
                 This argument is ignored if ``channel`` is provided.
-            scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
-                service. These are only used when credentials are not specified and
-                are passed to :func:`google.auth.default`.
-            channel (Optional[aio.Channel]): A ``Channel`` instance through
+            scopes (Optional(Sequence[str])): A list of scopes. This argument is
+                ignored if ``channel`` is provided.
+            channel (Optional[grpc.Channel]): A ``Channel`` instance through
                 which to make calls.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
@@ -148,35 +103,36 @@
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
             always_use_jwt_access (Optional[bool]): Whether self signed JWT should
                 be used for service account credentials.
 
         Raises:
-            google.auth.exceptions.MutualTlsChannelError: If mutual TLS transport
+          google.auth.exceptions.MutualTLSChannelError: If mutual TLS transport
               creation failed for any reason.
           google.api_core.exceptions.DuplicateCredentialArgs: If both ``credentials``
               and ``credentials_file`` are passed.
         """
         self._grpc_channel = None
         self._ssl_channel_credentials = ssl_channel_credentials
         self._stubs: Dict[str, Callable] = {}
-        self._operations_client: Optional[operations_v1.OperationsAsyncClient] = None
+        self._operations_client: Optional[operations_v1.OperationsClient] = None
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
         if channel:
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
+
         else:
             if api_mtls_endpoint:
                 host = api_mtls_endpoint
 
                 # Create SSL credentials with client_cert_source or application
                 # default SSL credentials.
                 if client_cert_source:
@@ -222,376 +178,404 @@
                     ("grpc.max_receive_message_length", -1),
                 ],
             )
 
         # Wrap messages. This must be done after self._grpc_channel exists
         self._prep_wrapped_messages(client_info)
 
-    @property
-    def grpc_channel(self) -> aio.Channel:
-        """Create the channel designed to connect to this service.
+    @classmethod
+    def create_channel(
+        cls,
+        host: str = "alloydb.googleapis.com",
+        credentials: Optional[ga_credentials.Credentials] = None,
+        credentials_file: Optional[str] = None,
+        scopes: Optional[Sequence[str]] = None,
+        quota_project_id: Optional[str] = None,
+        **kwargs,
+    ) -> grpc.Channel:
+        """Create and return a gRPC channel object.
+        Args:
+            host (Optional[str]): The host for the channel to use.
+            credentials (Optional[~.Credentials]): The
+                authorization credentials to attach to requests. These
+                credentials identify this application to the service. If
+                none are specified, the client will attempt to ascertain
+                the credentials from the environment.
+            credentials_file (Optional[str]): A file with credentials that can
+                be loaded with :func:`google.auth.load_credentials_from_file`.
+                This argument is mutually exclusive with credentials.
+            scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
+                service. These are only used when credentials are not specified and
+                are passed to :func:`google.auth.default`.
+            quota_project_id (Optional[str]): An optional project to use for billing
+                and quota.
+            kwargs (Optional[dict]): Keyword arguments, which are passed to the
+                channel creation.
+        Returns:
+            grpc.Channel: A gRPC channel object.
 
-        This property caches on the instance; repeated calls return
-        the same channel.
+        Raises:
+            google.api_core.exceptions.DuplicateCredentialArgs: If both ``credentials``
+              and ``credentials_file`` are passed.
         """
-        # Return the channel from cache.
+
+        return grpc_helpers.create_channel(
+            host,
+            credentials=credentials,
+            credentials_file=credentials_file,
+            quota_project_id=quota_project_id,
+            default_scopes=cls.AUTH_SCOPES,
+            scopes=scopes,
+            default_host=cls.DEFAULT_HOST,
+            **kwargs,
+        )
+
+    @property
+    def grpc_channel(self) -> grpc.Channel:
+        """Return the channel designed to connect to this service."""
         return self._grpc_channel
 
     @property
-    def operations_client(self) -> operations_v1.OperationsAsyncClient:
+    def operations_client(self) -> operations_v1.OperationsClient:
         """Create the client designed to process long-running operations.
 
         This property caches on the instance; repeated calls return the same
         client.
         """
         # Quick check: Only create a new client if we do not already have one.
         if self._operations_client is None:
-            self._operations_client = operations_v1.OperationsAsyncClient(
-                self.grpc_channel
-            )
+            self._operations_client = operations_v1.OperationsClient(self.grpc_channel)
 
         # Return the client from cache.
         return self._operations_client
 
     @property
     def list_clusters(
         self,
-    ) -> Callable[
-        [service.ListClustersRequest], Awaitable[service.ListClustersResponse]
-    ]:
+    ) -> Callable[[service.ListClustersRequest], service.ListClustersResponse]:
         r"""Return a callable for the list clusters method over gRPC.
 
         Lists Clusters in a given project and location.
 
         Returns:
             Callable[[~.ListClustersRequest],
-                    Awaitable[~.ListClustersResponse]]:
+                    ~.ListClustersResponse]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_clusters" not in self._stubs:
             self._stubs["list_clusters"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListClusters",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListClusters",
                 request_serializer=service.ListClustersRequest.serialize,
                 response_deserializer=service.ListClustersResponse.deserialize,
             )
         return self._stubs["list_clusters"]
 
     @property
-    def get_cluster(
-        self,
-    ) -> Callable[[service.GetClusterRequest], Awaitable[resources.Cluster]]:
+    def get_cluster(self) -> Callable[[service.GetClusterRequest], resources.Cluster]:
         r"""Return a callable for the get cluster method over gRPC.
 
         Gets details of a single Cluster.
 
         Returns:
             Callable[[~.GetClusterRequest],
-                    Awaitable[~.Cluster]]:
+                    ~.Cluster]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_cluster" not in self._stubs:
             self._stubs["get_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetCluster",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetCluster",
                 request_serializer=service.GetClusterRequest.serialize,
                 response_deserializer=resources.Cluster.deserialize,
             )
         return self._stubs["get_cluster"]
 
     @property
     def create_cluster(
         self,
-    ) -> Callable[[service.CreateClusterRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.CreateClusterRequest], operations_pb2.Operation]:
         r"""Return a callable for the create cluster method over gRPC.
 
         Creates a new Cluster in a given project and
         location.
 
         Returns:
             Callable[[~.CreateClusterRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_cluster" not in self._stubs:
             self._stubs["create_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateCluster",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateCluster",
                 request_serializer=service.CreateClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_cluster"]
 
     @property
     def update_cluster(
         self,
-    ) -> Callable[[service.UpdateClusterRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.UpdateClusterRequest], operations_pb2.Operation]:
         r"""Return a callable for the update cluster method over gRPC.
 
         Updates the parameters of a single Cluster.
 
         Returns:
             Callable[[~.UpdateClusterRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "update_cluster" not in self._stubs:
             self._stubs["update_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/UpdateCluster",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/UpdateCluster",
                 request_serializer=service.UpdateClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_cluster"]
 
     @property
     def delete_cluster(
         self,
-    ) -> Callable[[service.DeleteClusterRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.DeleteClusterRequest], operations_pb2.Operation]:
         r"""Return a callable for the delete cluster method over gRPC.
 
         Deletes a single Cluster.
 
         Returns:
             Callable[[~.DeleteClusterRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "delete_cluster" not in self._stubs:
             self._stubs["delete_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/DeleteCluster",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/DeleteCluster",
                 request_serializer=service.DeleteClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_cluster"]
 
     @property
     def promote_cluster(
         self,
-    ) -> Callable[[service.PromoteClusterRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.PromoteClusterRequest], operations_pb2.Operation]:
         r"""Return a callable for the promote cluster method over gRPC.
 
         Promotes a SECONDARY cluster. This turns down
         replication from the PRIMARY cluster and promotes a
         secondary cluster into its own standalone cluster.
         Imperative only.
 
         Returns:
             Callable[[~.PromoteClusterRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "promote_cluster" not in self._stubs:
             self._stubs["promote_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/PromoteCluster",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/PromoteCluster",
                 request_serializer=service.PromoteClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["promote_cluster"]
 
     @property
     def restore_cluster(
         self,
-    ) -> Callable[[service.RestoreClusterRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.RestoreClusterRequest], operations_pb2.Operation]:
         r"""Return a callable for the restore cluster method over gRPC.
 
         Creates a new Cluster in a given project and
         location, with a volume restored from the provided
         source, either a backup ID or a point-in-time and a
         source cluster.
 
         Returns:
             Callable[[~.RestoreClusterRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "restore_cluster" not in self._stubs:
             self._stubs["restore_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/RestoreCluster",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/RestoreCluster",
                 request_serializer=service.RestoreClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["restore_cluster"]
 
     @property
     def create_secondary_cluster(
         self,
-    ) -> Callable[
-        [service.CreateSecondaryClusterRequest], Awaitable[operations_pb2.Operation]
-    ]:
+    ) -> Callable[[service.CreateSecondaryClusterRequest], operations_pb2.Operation]:
         r"""Return a callable for the create secondary cluster method over gRPC.
 
         Creates a cluster of type SECONDARY in the given
         location using the primary cluster as the source.
 
         Returns:
             Callable[[~.CreateSecondaryClusterRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_secondary_cluster" not in self._stubs:
             self._stubs["create_secondary_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateSecondaryCluster",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateSecondaryCluster",
                 request_serializer=service.CreateSecondaryClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_secondary_cluster"]
 
     @property
     def list_instances(
         self,
-    ) -> Callable[
-        [service.ListInstancesRequest], Awaitable[service.ListInstancesResponse]
-    ]:
+    ) -> Callable[[service.ListInstancesRequest], service.ListInstancesResponse]:
         r"""Return a callable for the list instances method over gRPC.
 
         Lists Instances in a given project and location.
 
         Returns:
             Callable[[~.ListInstancesRequest],
-                    Awaitable[~.ListInstancesResponse]]:
+                    ~.ListInstancesResponse]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_instances" not in self._stubs:
             self._stubs["list_instances"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListInstances",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListInstances",
                 request_serializer=service.ListInstancesRequest.serialize,
                 response_deserializer=service.ListInstancesResponse.deserialize,
             )
         return self._stubs["list_instances"]
 
     @property
     def get_instance(
         self,
-    ) -> Callable[[service.GetInstanceRequest], Awaitable[resources.Instance]]:
+    ) -> Callable[[service.GetInstanceRequest], resources.Instance]:
         r"""Return a callable for the get instance method over gRPC.
 
         Gets details of a single Instance.
 
         Returns:
             Callable[[~.GetInstanceRequest],
-                    Awaitable[~.Instance]]:
+                    ~.Instance]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_instance" not in self._stubs:
             self._stubs["get_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetInstance",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetInstance",
                 request_serializer=service.GetInstanceRequest.serialize,
                 response_deserializer=resources.Instance.deserialize,
             )
         return self._stubs["get_instance"]
 
     @property
     def create_instance(
         self,
-    ) -> Callable[[service.CreateInstanceRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.CreateInstanceRequest], operations_pb2.Operation]:
         r"""Return a callable for the create instance method over gRPC.
 
         Creates a new Instance in a given project and
         location.
 
         Returns:
             Callable[[~.CreateInstanceRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_instance" not in self._stubs:
             self._stubs["create_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateInstance",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateInstance",
                 request_serializer=service.CreateInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_instance"]
 
     @property
     def create_secondary_instance(
         self,
-    ) -> Callable[
-        [service.CreateSecondaryInstanceRequest], Awaitable[operations_pb2.Operation]
-    ]:
+    ) -> Callable[[service.CreateSecondaryInstanceRequest], operations_pb2.Operation]:
         r"""Return a callable for the create secondary instance method over gRPC.
 
         Creates a new SECONDARY Instance in a given project
         and location.
 
         Returns:
             Callable[[~.CreateSecondaryInstanceRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_secondary_instance" not in self._stubs:
             self._stubs["create_secondary_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateSecondaryInstance",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateSecondaryInstance",
                 request_serializer=service.CreateSecondaryInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_secondary_instance"]
 
     @property
     def batch_create_instances(
         self,
-    ) -> Callable[
-        [service.BatchCreateInstancesRequest], Awaitable[operations_pb2.Operation]
-    ]:
+    ) -> Callable[[service.BatchCreateInstancesRequest], operations_pb2.Operation]:
         r"""Return a callable for the batch create instances method over gRPC.
 
         Creates new instances under the given project,
         location and cluster. There can be only one primary
         instance in a cluster. If the primary instance exists in
         the cluster as well as this request, then API will throw
         an error.
@@ -602,367 +586,509 @@
         here to support Google-internal use cases, and is not
         meant for external customers to consume. Please do not
         start relying on it; its behavior is subject to change
         without notice.
 
         Returns:
             Callable[[~.BatchCreateInstancesRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "batch_create_instances" not in self._stubs:
             self._stubs["batch_create_instances"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/BatchCreateInstances",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/BatchCreateInstances",
                 request_serializer=service.BatchCreateInstancesRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["batch_create_instances"]
 
     @property
     def update_instance(
         self,
-    ) -> Callable[[service.UpdateInstanceRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.UpdateInstanceRequest], operations_pb2.Operation]:
         r"""Return a callable for the update instance method over gRPC.
 
         Updates the parameters of a single Instance.
 
         Returns:
             Callable[[~.UpdateInstanceRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "update_instance" not in self._stubs:
             self._stubs["update_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/UpdateInstance",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/UpdateInstance",
                 request_serializer=service.UpdateInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_instance"]
 
     @property
     def delete_instance(
         self,
-    ) -> Callable[[service.DeleteInstanceRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.DeleteInstanceRequest], operations_pb2.Operation]:
         r"""Return a callable for the delete instance method over gRPC.
 
         Deletes a single Instance.
 
         Returns:
             Callable[[~.DeleteInstanceRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "delete_instance" not in self._stubs:
             self._stubs["delete_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/DeleteInstance",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/DeleteInstance",
                 request_serializer=service.DeleteInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_instance"]
 
     @property
     def failover_instance(
         self,
-    ) -> Callable[
-        [service.FailoverInstanceRequest], Awaitable[operations_pb2.Operation]
-    ]:
+    ) -> Callable[[service.FailoverInstanceRequest], operations_pb2.Operation]:
         r"""Return a callable for the failover instance method over gRPC.
 
         Forces a Failover for a highly available instance.
         Failover promotes the HA standby instance as the new
         primary. Imperative only.
 
         Returns:
             Callable[[~.FailoverInstanceRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "failover_instance" not in self._stubs:
             self._stubs["failover_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/FailoverInstance",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/FailoverInstance",
                 request_serializer=service.FailoverInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["failover_instance"]
 
     @property
+    def inject_fault(
+        self,
+    ) -> Callable[[service.InjectFaultRequest], operations_pb2.Operation]:
+        r"""Return a callable for the inject fault method over gRPC.
+
+        Injects fault in an instance.
+        Imperative only.
+
+        Returns:
+            Callable[[~.InjectFaultRequest],
+                    ~.Operation]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "inject_fault" not in self._stubs:
+            self._stubs["inject_fault"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/InjectFault",
+                request_serializer=service.InjectFaultRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["inject_fault"]
+
+    @property
     def restart_instance(
         self,
-    ) -> Callable[
-        [service.RestartInstanceRequest], Awaitable[operations_pb2.Operation]
-    ]:
+    ) -> Callable[[service.RestartInstanceRequest], operations_pb2.Operation]:
         r"""Return a callable for the restart instance method over gRPC.
 
         Restart an Instance in a cluster.
         Imperative only.
 
         Returns:
             Callable[[~.RestartInstanceRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "restart_instance" not in self._stubs:
             self._stubs["restart_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/RestartInstance",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/RestartInstance",
                 request_serializer=service.RestartInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["restart_instance"]
 
     @property
     def list_backups(
         self,
-    ) -> Callable[[service.ListBackupsRequest], Awaitable[service.ListBackupsResponse]]:
+    ) -> Callable[[service.ListBackupsRequest], service.ListBackupsResponse]:
         r"""Return a callable for the list backups method over gRPC.
 
         Lists Backups in a given project and location.
 
         Returns:
             Callable[[~.ListBackupsRequest],
-                    Awaitable[~.ListBackupsResponse]]:
+                    ~.ListBackupsResponse]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_backups" not in self._stubs:
             self._stubs["list_backups"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListBackups",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListBackups",
                 request_serializer=service.ListBackupsRequest.serialize,
                 response_deserializer=service.ListBackupsResponse.deserialize,
             )
         return self._stubs["list_backups"]
 
     @property
-    def get_backup(
-        self,
-    ) -> Callable[[service.GetBackupRequest], Awaitable[resources.Backup]]:
+    def get_backup(self) -> Callable[[service.GetBackupRequest], resources.Backup]:
         r"""Return a callable for the get backup method over gRPC.
 
         Gets details of a single Backup.
 
         Returns:
             Callable[[~.GetBackupRequest],
-                    Awaitable[~.Backup]]:
+                    ~.Backup]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_backup" not in self._stubs:
             self._stubs["get_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetBackup",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetBackup",
                 request_serializer=service.GetBackupRequest.serialize,
                 response_deserializer=resources.Backup.deserialize,
             )
         return self._stubs["get_backup"]
 
     @property
     def create_backup(
         self,
-    ) -> Callable[[service.CreateBackupRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.CreateBackupRequest], operations_pb2.Operation]:
         r"""Return a callable for the create backup method over gRPC.
 
         Creates a new Backup in a given project and location.
 
         Returns:
             Callable[[~.CreateBackupRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_backup" not in self._stubs:
             self._stubs["create_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/CreateBackup",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateBackup",
                 request_serializer=service.CreateBackupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_backup"]
 
     @property
     def update_backup(
         self,
-    ) -> Callable[[service.UpdateBackupRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.UpdateBackupRequest], operations_pb2.Operation]:
         r"""Return a callable for the update backup method over gRPC.
 
         Updates the parameters of a single Backup.
 
         Returns:
             Callable[[~.UpdateBackupRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "update_backup" not in self._stubs:
             self._stubs["update_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/UpdateBackup",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/UpdateBackup",
                 request_serializer=service.UpdateBackupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_backup"]
 
     @property
     def delete_backup(
         self,
-    ) -> Callable[[service.DeleteBackupRequest], Awaitable[operations_pb2.Operation]]:
+    ) -> Callable[[service.DeleteBackupRequest], operations_pb2.Operation]:
         r"""Return a callable for the delete backup method over gRPC.
 
         Deletes a single Backup.
 
         Returns:
             Callable[[~.DeleteBackupRequest],
-                    Awaitable[~.Operation]]:
+                    ~.Operation]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "delete_backup" not in self._stubs:
             self._stubs["delete_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/DeleteBackup",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/DeleteBackup",
                 request_serializer=service.DeleteBackupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_backup"]
 
     @property
     def list_supported_database_flags(
         self,
     ) -> Callable[
         [service.ListSupportedDatabaseFlagsRequest],
-        Awaitable[service.ListSupportedDatabaseFlagsResponse],
+        service.ListSupportedDatabaseFlagsResponse,
     ]:
         r"""Return a callable for the list supported database flags method over gRPC.
 
         Lists SupportedDatabaseFlags for a given project and
         location.
 
         Returns:
             Callable[[~.ListSupportedDatabaseFlagsRequest],
-                    Awaitable[~.ListSupportedDatabaseFlagsResponse]]:
+                    ~.ListSupportedDatabaseFlagsResponse]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_supported_database_flags" not in self._stubs:
             self._stubs[
                 "list_supported_database_flags"
             ] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/ListSupportedDatabaseFlags",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListSupportedDatabaseFlags",
                 request_serializer=service.ListSupportedDatabaseFlagsRequest.serialize,
                 response_deserializer=service.ListSupportedDatabaseFlagsResponse.deserialize,
             )
         return self._stubs["list_supported_database_flags"]
 
     @property
     def generate_client_certificate(
         self,
     ) -> Callable[
         [service.GenerateClientCertificateRequest],
-        Awaitable[service.GenerateClientCertificateResponse],
+        service.GenerateClientCertificateResponse,
     ]:
         r"""Return a callable for the generate client certificate method over gRPC.
 
         Generate a client certificate signed by a Cluster CA.
         The sole purpose of this endpoint is to support the Auth
         Proxy client and the endpoint's behavior is subject to
         change without notice, so do not rely on its behavior
         remaining constant. Future changes will not break the
         Auth Proxy client.
 
         Returns:
             Callable[[~.GenerateClientCertificateRequest],
-                    Awaitable[~.GenerateClientCertificateResponse]]:
+                    ~.GenerateClientCertificateResponse]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "generate_client_certificate" not in self._stubs:
             self._stubs["generate_client_certificate"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GenerateClientCertificate",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GenerateClientCertificate",
                 request_serializer=service.GenerateClientCertificateRequest.serialize,
                 response_deserializer=service.GenerateClientCertificateResponse.deserialize,
             )
         return self._stubs["generate_client_certificate"]
 
     @property
     def get_connection_info(
         self,
-    ) -> Callable[
-        [service.GetConnectionInfoRequest], Awaitable[resources.ConnectionInfo]
-    ]:
+    ) -> Callable[[service.GetConnectionInfoRequest], resources.ConnectionInfo]:
         r"""Return a callable for the get connection info method over gRPC.
 
         Get instance metadata used for a connection.
 
         Returns:
             Callable[[~.GetConnectionInfoRequest],
-                    Awaitable[~.ConnectionInfo]]:
+                    ~.ConnectionInfo]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_connection_info" not in self._stubs:
             self._stubs["get_connection_info"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1alpha.AlloyDBAdmin/GetConnectionInfo",
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetConnectionInfo",
                 request_serializer=service.GetConnectionInfoRequest.serialize,
                 response_deserializer=resources.ConnectionInfo.deserialize,
             )
         return self._stubs["get_connection_info"]
 
+    @property
+    def list_users(
+        self,
+    ) -> Callable[[service.ListUsersRequest], service.ListUsersResponse]:
+        r"""Return a callable for the list users method over gRPC.
+
+        Lists Users in a given project and location.
+
+        Returns:
+            Callable[[~.ListUsersRequest],
+                    ~.ListUsersResponse]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "list_users" not in self._stubs:
+            self._stubs["list_users"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListUsers",
+                request_serializer=service.ListUsersRequest.serialize,
+                response_deserializer=service.ListUsersResponse.deserialize,
+            )
+        return self._stubs["list_users"]
+
+    @property
+    def get_user(self) -> Callable[[service.GetUserRequest], resources.User]:
+        r"""Return a callable for the get user method over gRPC.
+
+        Gets details of a single User.
+
+        Returns:
+            Callable[[~.GetUserRequest],
+                    ~.User]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "get_user" not in self._stubs:
+            self._stubs["get_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetUser",
+                request_serializer=service.GetUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["get_user"]
+
+    @property
+    def create_user(self) -> Callable[[service.CreateUserRequest], resources.User]:
+        r"""Return a callable for the create user method over gRPC.
+
+        Creates a new User in a given project, location, and
+        cluster.
+
+        Returns:
+            Callable[[~.CreateUserRequest],
+                    ~.User]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_user" not in self._stubs:
+            self._stubs["create_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateUser",
+                request_serializer=service.CreateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["create_user"]
+
+    @property
+    def update_user(self) -> Callable[[service.UpdateUserRequest], resources.User]:
+        r"""Return a callable for the update user method over gRPC.
+
+        Updates the parameters of a single User.
+
+        Returns:
+            Callable[[~.UpdateUserRequest],
+                    ~.User]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "update_user" not in self._stubs:
+            self._stubs["update_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/UpdateUser",
+                request_serializer=service.UpdateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["update_user"]
+
+    @property
+    def delete_user(self) -> Callable[[service.DeleteUserRequest], empty_pb2.Empty]:
+        r"""Return a callable for the delete user method over gRPC.
+
+        Deletes a single User.
+
+        Returns:
+            Callable[[~.DeleteUserRequest],
+                    ~.Empty]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "delete_user" not in self._stubs:
+            self._stubs["delete_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/DeleteUser",
+                request_serializer=service.DeleteUserRequest.serialize,
+                response_deserializer=empty_pb2.Empty.FromString,
+            )
+        return self._stubs["delete_user"]
+
     def close(self):
-        return self.grpc_channel.close()
+        self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
         r"""Return a callable for the delete_operation method over gRPC."""
         # Generate a "stub function" on-the-fly which will actually make
@@ -1062,9 +1188,13 @@
             self._stubs["get_location"] = self.grpc_channel.unary_unary(
                 "/google.cloud.location.Locations/GetLocation",
                 request_serializer=locations_pb2.GetLocationRequest.SerializeToString,
                 response_deserializer=locations_pb2.Location.FromString,
             )
         return self._stubs["get_location"]
 
+    @property
+    def kind(self) -> str:
+        return "grpc"
+
 
-__all__ = ("AlloyDBAdminGrpcAsyncIOTransport",)
+__all__ = ("AlloyDBAdminGrpcTransport",)
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/rest.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/rest.py`

 * *Files 2% similar despite different names*

```diff
@@ -43,16 +43,17 @@
 try:
     OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
 except AttributeError:  # pragma: NO COVER
     OptionalRetry = Union[retries.Retry, object]  # type: ignore
 
 
 from google.longrunning import operations_pb2  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 
-from google.cloud.alloydb_v1alpha.types import resources, service
+from google.cloud.alloydb_v1.types import resources, service
 
 from .base import AlloyDBAdminTransport
 from .base import DEFAULT_CLIENT_INFO as BASE_DEFAULT_CLIENT_INFO
 
 DEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(
     gapic_version=BASE_DEFAULT_CLIENT_INFO.gapic_version,
     grpc_version=None,
@@ -119,14 +120,22 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_create_secondary_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_create_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_create_user(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_delete_backup(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_delete_backup(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -143,59 +152,63 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_delete_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_delete_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
             def pre_failover_instance(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_failover_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
-            def pre_generate_client_certificate(self, request, metadata):
+            def pre_get_backup(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
-            def post_generate_client_certificate(self, response):
+            def post_get_backup(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
-            def pre_get_backup(self, request, metadata):
+            def pre_get_cluster(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
-            def post_get_backup(self, response):
+            def post_get_cluster(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
-            def pre_get_cluster(self, request, metadata):
+            def pre_get_instance(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
-            def post_get_cluster(self, response):
+            def post_get_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
-            def pre_get_connection_info(self, request, metadata):
+            def pre_get_user(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
-            def post_get_connection_info(self, response):
+            def post_get_user(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
-            def pre_get_instance(self, request, metadata):
+            def pre_inject_fault(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
-            def post_get_instance(self, response):
+            def post_inject_fault(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
             def pre_list_backups(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
@@ -223,14 +236,22 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_list_supported_database_flags(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_list_users(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_list_users(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_promote_cluster(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_promote_cluster(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -271,14 +292,22 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_update_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_update_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_update_user(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
         transport = AlloyDBAdminRestTransport(interceptor=MyCustomAlloyDBAdminInterceptor())
         client = AlloyDBAdminClient(transport=transport)
 
 
     """
 
     def pre_batch_create_instances(
@@ -411,14 +440,33 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_create_user(
+        self, request: service.CreateUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.CreateUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for create_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_create_user(self, response: resources.User) -> resources.User:
+        """Post-rpc interceptor for create_user
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_delete_backup(
         self, request: service.DeleteBackupRequest, metadata: Sequence[Tuple[str, str]]
     ) -> Tuple[service.DeleteBackupRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for delete_backup
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
@@ -476,14 +524,24 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_delete_user(
+        self, request: service.DeleteUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.DeleteUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for delete_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
     def pre_failover_instance(
         self,
         request: service.FailoverInstanceRequest,
         metadata: Sequence[Tuple[str, str]],
     ) -> Tuple[service.FailoverInstanceRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for failover_instance
 
@@ -499,110 +557,104 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
-    def pre_generate_client_certificate(
-        self,
-        request: service.GenerateClientCertificateRequest,
-        metadata: Sequence[Tuple[str, str]],
-    ) -> Tuple[service.GenerateClientCertificateRequest, Sequence[Tuple[str, str]]]:
-        """Pre-rpc interceptor for generate_client_certificate
+    def pre_get_backup(
+        self, request: service.GetBackupRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.GetBackupRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for get_backup
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
         """
         return request, metadata
 
-    def post_generate_client_certificate(
-        self, response: service.GenerateClientCertificateResponse
-    ) -> service.GenerateClientCertificateResponse:
-        """Post-rpc interceptor for generate_client_certificate
+    def post_get_backup(self, response: resources.Backup) -> resources.Backup:
+        """Post-rpc interceptor for get_backup
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
-    def pre_get_backup(
-        self, request: service.GetBackupRequest, metadata: Sequence[Tuple[str, str]]
-    ) -> Tuple[service.GetBackupRequest, Sequence[Tuple[str, str]]]:
-        """Pre-rpc interceptor for get_backup
+    def pre_get_cluster(
+        self, request: service.GetClusterRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.GetClusterRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for get_cluster
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
         """
         return request, metadata
 
-    def post_get_backup(self, response: resources.Backup) -> resources.Backup:
-        """Post-rpc interceptor for get_backup
+    def post_get_cluster(self, response: resources.Cluster) -> resources.Cluster:
+        """Post-rpc interceptor for get_cluster
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
-    def pre_get_cluster(
-        self, request: service.GetClusterRequest, metadata: Sequence[Tuple[str, str]]
-    ) -> Tuple[service.GetClusterRequest, Sequence[Tuple[str, str]]]:
-        """Pre-rpc interceptor for get_cluster
+    def pre_get_instance(
+        self, request: service.GetInstanceRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.GetInstanceRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for get_instance
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
         """
         return request, metadata
 
-    def post_get_cluster(self, response: resources.Cluster) -> resources.Cluster:
-        """Post-rpc interceptor for get_cluster
+    def post_get_instance(self, response: resources.Instance) -> resources.Instance:
+        """Post-rpc interceptor for get_instance
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
-    def pre_get_connection_info(
-        self,
-        request: service.GetConnectionInfoRequest,
-        metadata: Sequence[Tuple[str, str]],
-    ) -> Tuple[service.GetConnectionInfoRequest, Sequence[Tuple[str, str]]]:
-        """Pre-rpc interceptor for get_connection_info
+    def pre_get_user(
+        self, request: service.GetUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.GetUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for get_user
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
         """
         return request, metadata
 
-    def post_get_connection_info(
-        self, response: resources.ConnectionInfo
-    ) -> resources.ConnectionInfo:
-        """Post-rpc interceptor for get_connection_info
+    def post_get_user(self, response: resources.User) -> resources.User:
+        """Post-rpc interceptor for get_user
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
-    def pre_get_instance(
-        self, request: service.GetInstanceRequest, metadata: Sequence[Tuple[str, str]]
-    ) -> Tuple[service.GetInstanceRequest, Sequence[Tuple[str, str]]]:
-        """Pre-rpc interceptor for get_instance
+    def pre_inject_fault(
+        self, request: service.InjectFaultRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.InjectFaultRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for inject_fault
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
         """
         return request, metadata
 
-    def post_get_instance(self, response: resources.Instance) -> resources.Instance:
-        """Post-rpc interceptor for get_instance
+    def post_inject_fault(
+        self, response: operations_pb2.Operation
+    ) -> operations_pb2.Operation:
+        """Post-rpc interceptor for inject_fault
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
@@ -688,14 +740,35 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_list_users(
+        self, request: service.ListUsersRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.ListUsersRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for list_users
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_list_users(
+        self, response: service.ListUsersResponse
+    ) -> service.ListUsersResponse:
+        """Post-rpc interceptor for list_users
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_promote_cluster(
         self,
         request: service.PromoteClusterRequest,
         metadata: Sequence[Tuple[str, str]],
     ) -> Tuple[service.PromoteClusterRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for promote_cluster
 
@@ -822,14 +895,33 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_update_user(
+        self, request: service.UpdateUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.UpdateUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for update_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_update_user(self, response: resources.User) -> resources.User:
+        """Post-rpc interceptor for update_user
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_get_location(
         self,
         request: locations_pb2.GetLocationRequest,
         metadata: Sequence[Tuple[str, str]],
     ) -> Tuple[locations_pb2.GetLocationRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for get_location
 
@@ -1067,45 +1159,45 @@
         """
         # Only create a new client if we do not already have one.
         if self._operations_client is None:
             http_options: Dict[str, List[Dict[str, str]]] = {
                 "google.longrunning.Operations.CancelOperation": [
                     {
                         "method": "post",
-                        "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}:cancel",
+                        "uri": "/v1/{name=projects/*/locations/*/operations/*}:cancel",
                         "body": "*",
                     },
                 ],
                 "google.longrunning.Operations.DeleteOperation": [
                     {
                         "method": "delete",
-                        "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}",
+                        "uri": "/v1/{name=projects/*/locations/*/operations/*}",
                     },
                 ],
                 "google.longrunning.Operations.GetOperation": [
                     {
                         "method": "get",
-                        "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}",
+                        "uri": "/v1/{name=projects/*/locations/*/operations/*}",
                     },
                 ],
                 "google.longrunning.Operations.ListOperations": [
                     {
                         "method": "get",
-                        "uri": "/v1alpha/{name=projects/*/locations/*}/operations",
+                        "uri": "/v1/{name=projects/*/locations/*}/operations",
                     },
                 ],
             }
 
             rest_transport = operations_v1.OperationsRestTransport(
                 host=self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 scopes=self._scopes,
                 http_options=http_options,
-                path_prefix="v1alpha",
+                path_prefix="v1",
             )
 
             self._operations_client = operations_v1.AbstractOperationsClient(
                 transport=rest_transport
             )
 
         # Return the client from cache.
@@ -1152,15 +1244,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/instances:batchCreate",
+                    "uri": "/v1/{parent=projects/*/locations/*/clusters/*}/instances:batchCreate",
                     "body": "requests",
                 },
             ]
             request, metadata = self._interceptor.pre_batch_create_instances(
                 request, metadata
             )
             pb_request = service.BatchCreateInstancesRequest.pb(request)
@@ -1252,15 +1344,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*}/backups",
+                    "uri": "/v1/{parent=projects/*/locations/*}/backups",
                     "body": "backup",
                 },
             ]
             request, metadata = self._interceptor.pre_create_backup(request, metadata)
             pb_request = service.CreateBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -1350,15 +1442,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*}/clusters",
+                    "uri": "/v1/{parent=projects/*/locations/*}/clusters",
                     "body": "cluster",
                 },
             ]
             request, metadata = self._interceptor.pre_create_cluster(request, metadata)
             pb_request = service.CreateClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -1448,15 +1540,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/instances",
+                    "uri": "/v1/{parent=projects/*/locations/*/clusters/*}/instances",
                     "body": "instance",
                 },
             ]
             request, metadata = self._interceptor.pre_create_instance(request, metadata)
             pb_request = service.CreateInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -1546,15 +1638,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*}/clusters:createsecondary",
+                    "uri": "/v1/{parent=projects/*/locations/*}/clusters:createsecondary",
                     "body": "cluster",
                 },
             ]
             request, metadata = self._interceptor.pre_create_secondary_cluster(
                 request, metadata
             )
             pb_request = service.CreateSecondaryClusterRequest.pb(request)
@@ -1647,15 +1739,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/instances:createsecondary",
+                    "uri": "/v1/{parent=projects/*/locations/*/clusters/*}/instances:createsecondary",
                     "body": "instance",
                 },
             ]
             request, metadata = self._interceptor.pre_create_secondary_instance(
                 request, metadata
             )
             pb_request = service.CreateSecondaryInstanceRequest.pb(request)
@@ -1701,14 +1793,111 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_create_secondary_instance(resp)
             return resp
 
+    class _CreateUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("CreateUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {
+            "userId": "",
+        }
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.CreateUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> resources.User:
+            r"""Call the create user method over HTTP.
+
+            Args:
+                request (~.service.CreateUserRequest):
+                    The request object. Message for creating a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.resources.User:
+                    Message describing User object.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1/{parent=projects/*/locations/*/clusters/*}/users",
+                    "body": "user",
+                },
+            ]
+            request, metadata = self._interceptor.pre_create_user(request, metadata)
+            pb_request = service.CreateUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = resources.User()
+            pb_resp = resources.User.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_create_user(resp)
+            return resp
+
     class _DeleteBackup(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("DeleteBackup")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -1745,15 +1934,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/backups/*}",
+                    "uri": "/v1/{name=projects/*/locations/*/backups/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_delete_backup(request, metadata)
             pb_request = service.DeleteBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1832,15 +2021,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*}",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_delete_cluster(request, metadata)
             pb_request = service.DeleteClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1919,15 +2108,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/instances/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_delete_instance(request, metadata)
             pb_request = service.DeleteInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1962,76 +2151,58 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_delete_instance(resp)
             return resp
 
-    class _FailoverInstance(AlloyDBAdminRestStub):
+    class _DeleteUser(AlloyDBAdminRestStub):
         def __hash__(self):
-            return hash("FailoverInstance")
+            return hash("DeleteUser")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
         def _get_unset_required_fields(cls, message_dict):
             return {
                 k: v
                 for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
                 if k not in message_dict
             }
 
         def __call__(
             self,
-            request: service.FailoverInstanceRequest,
+            request: service.DeleteUserRequest,
             *,
             retry: OptionalRetry = gapic_v1.method.DEFAULT,
             timeout: Optional[float] = None,
             metadata: Sequence[Tuple[str, str]] = (),
-        ) -> operations_pb2.Operation:
-            r"""Call the failover instance method over HTTP.
+        ):
+            r"""Call the delete user method over HTTP.
 
             Args:
-                request (~.service.FailoverInstanceRequest):
-                    The request object. Message for triggering failover on an
-                Instance
+                request (~.service.DeleteUserRequest):
+                    The request object. Message for deleting a User
                 retry (google.api_core.retry.Retry): Designation of what errors, if any,
                     should be retried.
                 timeout (float): The timeout for this request.
                 metadata (Sequence[Tuple[str, str]]): Strings which should be
                     sent along with the request as metadata.
-
-            Returns:
-                ~.operations_pb2.Operation:
-                    This resource represents a
-                long-running operation that is the
-                result of a network API call.
-
             """
 
             http_options: List[Dict[str, str]] = [
                 {
-                    "method": "post",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}:failover",
-                    "body": "*",
+                    "method": "delete",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/users/*}",
                 },
             ]
-            request, metadata = self._interceptor.pre_failover_instance(
-                request, metadata
-            )
-            pb_request = service.FailoverInstanceRequest.pb(request)
+            request, metadata = self._interceptor.pre_delete_user(request, metadata)
+            pb_request = service.DeleteUserRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
-            # Jsonify the request body
-
-            body = json_format.MessageToJson(
-                transcoded_request["body"],
-                including_default_value_fields=False,
-                use_integers_for_enums=True,
-            )
             uri = transcoded_request["uri"]
             method = transcoded_request["method"]
 
             # Jsonify the query params
             query_params = json.loads(
                 json_format.MessageToJson(
                     transcoded_request["query_params"],
@@ -2047,82 +2218,74 @@
             headers = dict(metadata)
             headers["Content-Type"] = "application/json"
             response = getattr(self._session, method)(
                 "{host}{uri}".format(host=self._host, uri=uri),
                 timeout=timeout,
                 headers=headers,
                 params=rest_helpers.flatten_query_params(query_params, strict=True),
-                data=body,
             )
 
             # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
             # subclass.
             if response.status_code >= 400:
                 raise core_exceptions.from_http_response(response)
 
-            # Return the response
-            resp = operations_pb2.Operation()
-            json_format.Parse(response.content, resp, ignore_unknown_fields=True)
-            resp = self._interceptor.post_failover_instance(resp)
-            return resp
-
-    class _GenerateClientCertificate(AlloyDBAdminRestStub):
+    class _FailoverInstance(AlloyDBAdminRestStub):
         def __hash__(self):
-            return hash("GenerateClientCertificate")
+            return hash("FailoverInstance")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
         def _get_unset_required_fields(cls, message_dict):
             return {
                 k: v
                 for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
                 if k not in message_dict
             }
 
         def __call__(
             self,
-            request: service.GenerateClientCertificateRequest,
+            request: service.FailoverInstanceRequest,
             *,
             retry: OptionalRetry = gapic_v1.method.DEFAULT,
             timeout: Optional[float] = None,
             metadata: Sequence[Tuple[str, str]] = (),
-        ) -> service.GenerateClientCertificateResponse:
-            r"""Call the generate client
-            certificate method over HTTP.
+        ) -> operations_pb2.Operation:
+            r"""Call the failover instance method over HTTP.
 
-                Args:
-                    request (~.service.GenerateClientCertificateRequest):
-                        The request object. Message for requests to generate a
-                    client certificate signed by the Cluster
-                    CA.
-                    retry (google.api_core.retry.Retry): Designation of what errors, if any,
-                        should be retried.
-                    timeout (float): The timeout for this request.
-                    metadata (Sequence[Tuple[str, str]]): Strings which should be
-                        sent along with the request as metadata.
+            Args:
+                request (~.service.FailoverInstanceRequest):
+                    The request object. Message for triggering failover on an
+                Instance
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
 
-                Returns:
-                    ~.service.GenerateClientCertificateResponse:
-                        Message returned by a
-                    GenerateClientCertificate operation.
+            Returns:
+                ~.operations_pb2.Operation:
+                    This resource represents a
+                long-running operation that is the
+                result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}:generateClientCertificate",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/instances/*}:failover",
                     "body": "*",
                 },
             ]
-            request, metadata = self._interceptor.pre_generate_client_certificate(
+            request, metadata = self._interceptor.pre_failover_instance(
                 request, metadata
             )
-            pb_request = service.GenerateClientCertificateRequest.pb(request)
+            pb_request = service.FailoverInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             # Jsonify the request body
 
             body = json_format.MessageToJson(
                 transcoded_request["body"],
                 including_default_value_fields=False,
@@ -2156,19 +2319,17 @@
 
             # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
             # subclass.
             if response.status_code >= 400:
                 raise core_exceptions.from_http_response(response)
 
             # Return the response
-            resp = service.GenerateClientCertificateResponse()
-            pb_resp = service.GenerateClientCertificateResponse.pb(resp)
-
-            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
-            resp = self._interceptor.post_generate_client_certificate(resp)
+            resp = operations_pb2.Operation()
+            json_format.Parse(response.content, resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_failover_instance(resp)
             return resp
 
     class _GetBackup(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("GetBackup")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
@@ -2204,15 +2365,15 @@
                 ~.resources.Backup:
                     Message describing Backup object
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/backups/*}",
+                    "uri": "/v1/{name=projects/*/locations/*/backups/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_get_backup(request, metadata)
             pb_request = service.GetBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2296,15 +2457,15 @@
                 needed.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*}",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_get_cluster(request, metadata)
             pb_request = service.GetClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2341,65 +2502,64 @@
             resp = resources.Cluster()
             pb_resp = resources.Cluster.pb(resp)
 
             json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_get_cluster(resp)
             return resp
 
-    class _GetConnectionInfo(AlloyDBAdminRestStub):
+    class _GetInstance(AlloyDBAdminRestStub):
         def __hash__(self):
-            return hash("GetConnectionInfo")
+            return hash("GetInstance")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
         def _get_unset_required_fields(cls, message_dict):
             return {
                 k: v
                 for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
                 if k not in message_dict
             }
 
         def __call__(
             self,
-            request: service.GetConnectionInfoRequest,
+            request: service.GetInstanceRequest,
             *,
             retry: OptionalRetry = gapic_v1.method.DEFAULT,
             timeout: Optional[float] = None,
             metadata: Sequence[Tuple[str, str]] = (),
-        ) -> resources.ConnectionInfo:
-            r"""Call the get connection info method over HTTP.
+        ) -> resources.Instance:
+            r"""Call the get instance method over HTTP.
 
             Args:
-                request (~.service.GetConnectionInfoRequest):
-                    The request object. Request message for
-                GetConnectionInfo.
+                request (~.service.GetInstanceRequest):
+                    The request object. Message for getting a Instance
                 retry (google.api_core.retry.Retry): Designation of what errors, if any,
                     should be retried.
                 timeout (float): The timeout for this request.
                 metadata (Sequence[Tuple[str, str]]): Strings which should be
                     sent along with the request as metadata.
 
             Returns:
-                ~.resources.ConnectionInfo:
-                    ConnectionInfo singleton resource.
-                https://google.aip.dev/156
+                ~.resources.Instance:
+                    An Instance is a computing unit that
+                an end customer can connect to. It's the
+                main unit of computing resources in
+                AlloyDB.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*/instances/*}/connectionInfo",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/instances/*}",
                 },
             ]
-            request, metadata = self._interceptor.pre_get_connection_info(
-                request, metadata
-            )
-            pb_request = service.GetConnectionInfoRequest.pb(request)
+            request, metadata = self._interceptor.pre_get_instance(request, metadata)
+            pb_request = service.GetInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
             method = transcoded_request["method"]
 
             # Jsonify the query params
             query_params = json.loads(
@@ -2425,71 +2585,67 @@
 
             # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
             # subclass.
             if response.status_code >= 400:
                 raise core_exceptions.from_http_response(response)
 
             # Return the response
-            resp = resources.ConnectionInfo()
-            pb_resp = resources.ConnectionInfo.pb(resp)
+            resp = resources.Instance()
+            pb_resp = resources.Instance.pb(resp)
 
             json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
-            resp = self._interceptor.post_get_connection_info(resp)
+            resp = self._interceptor.post_get_instance(resp)
             return resp
 
-    class _GetInstance(AlloyDBAdminRestStub):
+    class _GetUser(AlloyDBAdminRestStub):
         def __hash__(self):
-            return hash("GetInstance")
+            return hash("GetUser")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
         def _get_unset_required_fields(cls, message_dict):
             return {
                 k: v
                 for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
                 if k not in message_dict
             }
 
         def __call__(
             self,
-            request: service.GetInstanceRequest,
+            request: service.GetUserRequest,
             *,
             retry: OptionalRetry = gapic_v1.method.DEFAULT,
             timeout: Optional[float] = None,
             metadata: Sequence[Tuple[str, str]] = (),
-        ) -> resources.Instance:
-            r"""Call the get instance method over HTTP.
+        ) -> resources.User:
+            r"""Call the get user method over HTTP.
 
             Args:
-                request (~.service.GetInstanceRequest):
-                    The request object. Message for getting a Instance
+                request (~.service.GetUserRequest):
+                    The request object. Message for getting a User
                 retry (google.api_core.retry.Retry): Designation of what errors, if any,
                     should be retried.
                 timeout (float): The timeout for this request.
                 metadata (Sequence[Tuple[str, str]]): Strings which should be
                     sent along with the request as metadata.
 
             Returns:
-                ~.resources.Instance:
-                    An Instance is a computing unit that
-                an end customer can connect to. It's the
-                main unit of computing resources in
-                AlloyDB.
-
+                ~.resources.User:
+                    Message describing User object.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/users/*}",
                 },
             ]
-            request, metadata = self._interceptor.pre_get_instance(request, metadata)
-            pb_request = service.GetInstanceRequest.pb(request)
+            request, metadata = self._interceptor.pre_get_user(request, metadata)
+            pb_request = service.GetUserRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
             method = transcoded_request["method"]
 
             # Jsonify the query params
             query_params = json.loads(
@@ -2515,19 +2671,116 @@
 
             # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
             # subclass.
             if response.status_code >= 400:
                 raise core_exceptions.from_http_response(response)
 
             # Return the response
-            resp = resources.Instance()
-            pb_resp = resources.Instance.pb(resp)
+            resp = resources.User()
+            pb_resp = resources.User.pb(resp)
 
             json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
-            resp = self._interceptor.post_get_instance(resp)
+            resp = self._interceptor.post_get_user(resp)
+            return resp
+
+    class _InjectFault(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("InjectFault")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.InjectFaultRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> operations_pb2.Operation:
+            r"""Call the inject fault method over HTTP.
+
+            Args:
+                request (~.service.InjectFaultRequest):
+                    The request object. Message for triggering fault
+                injection on an instance
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.operations_pb2.Operation:
+                    This resource represents a
+                long-running operation that is the
+                result of a network API call.
+
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/instances/*}:injectFault",
+                    "body": "*",
+                },
+            ]
+            request, metadata = self._interceptor.pre_inject_fault(request, metadata)
+            pb_request = service.InjectFaultRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = operations_pb2.Operation()
+            json_format.Parse(response.content, resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_inject_fault(resp)
             return resp
 
     class _ListBackups(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("ListBackups")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
@@ -2566,15 +2819,15 @@
                 Backups
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*}/backups",
+                    "uri": "/v1/{parent=projects/*/locations/*}/backups",
                 },
             ]
             request, metadata = self._interceptor.pre_list_backups(request, metadata)
             pb_request = service.ListBackupsRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2655,15 +2908,15 @@
                 Clusters
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*}/clusters",
+                    "uri": "/v1/{parent=projects/*/locations/*}/clusters",
                 },
             ]
             request, metadata = self._interceptor.pre_list_clusters(request, metadata)
             pb_request = service.ListClustersRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2744,15 +2997,15 @@
                 Instances
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/instances",
+                    "uri": "/v1/{parent=projects/*/locations/*/clusters/*}/instances",
                 },
             ]
             request, metadata = self._interceptor.pre_list_instances(request, metadata)
             pb_request = service.ListInstancesRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2834,15 +3087,15 @@
                     SupportedDatabaseFlags.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*}/supportedDatabaseFlags",
+                    "uri": "/v1/{parent=projects/*/locations/*}/supportedDatabaseFlags",
                 },
             ]
             request, metadata = self._interceptor.pre_list_supported_database_flags(
                 request, metadata
             )
             pb_request = service.ListSupportedDatabaseFlagsRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
@@ -2881,14 +3134,100 @@
             resp = service.ListSupportedDatabaseFlagsResponse()
             pb_resp = service.ListSupportedDatabaseFlagsResponse.pb(resp)
 
             json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_list_supported_database_flags(resp)
             return resp
 
+    class _ListUsers(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("ListUsers")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.ListUsersRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> service.ListUsersResponse:
+            r"""Call the list users method over HTTP.
+
+            Args:
+                request (~.service.ListUsersRequest):
+                    The request object. Message for requesting list of Users
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.service.ListUsersResponse:
+                    Message for response to listing Users
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "get",
+                    "uri": "/v1/{parent=projects/*/locations/*/clusters/*}/users",
+                },
+            ]
+            request, metadata = self._interceptor.pre_list_users(request, metadata)
+            pb_request = service.ListUsersRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = service.ListUsersResponse()
+            pb_resp = service.ListUsersResponse.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_list_users(resp)
+            return resp
+
     class _PromoteCluster(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("PromoteCluster")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -2925,15 +3264,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*}:promote",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*}:promote",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_promote_cluster(request, metadata)
             pb_request = service.PromoteClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3021,15 +3360,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}:restart",
+                    "uri": "/v1/{name=projects/*/locations/*/clusters/*/instances/*}:restart",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_restart_instance(
                 request, metadata
             )
             pb_request = service.RestartInstanceRequest.pb(request)
@@ -3121,15 +3460,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{parent=projects/*/locations/*}/clusters:restore",
+                    "uri": "/v1/{parent=projects/*/locations/*}/clusters:restore",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_restore_cluster(request, metadata)
             pb_request = service.RestoreClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3217,15 +3556,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "patch",
-                    "uri": "/v1alpha/{backup.name=projects/*/locations/*/backups/*}",
+                    "uri": "/v1/{backup.name=projects/*/locations/*/backups/*}",
                     "body": "backup",
                 },
             ]
             request, metadata = self._interceptor.pre_update_backup(request, metadata)
             pb_request = service.UpdateBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3313,15 +3652,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "patch",
-                    "uri": "/v1alpha/{cluster.name=projects/*/locations/*/clusters/*}",
+                    "uri": "/v1/{cluster.name=projects/*/locations/*/clusters/*}",
                     "body": "cluster",
                 },
             ]
             request, metadata = self._interceptor.pre_update_cluster(request, metadata)
             pb_request = service.UpdateClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3409,15 +3748,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "patch",
-                    "uri": "/v1alpha/{instance.name=projects/*/locations/*/clusters/*/instances/*}",
+                    "uri": "/v1/{instance.name=projects/*/locations/*/clusters/*/instances/*}",
                     "body": "instance",
                 },
             ]
             request, metadata = self._interceptor.pre_update_instance(request, metadata)
             pb_request = service.UpdateInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3461,14 +3800,109 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_update_instance(resp)
             return resp
 
+    class _UpdateUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("UpdateUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.UpdateUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> resources.User:
+            r"""Call the update user method over HTTP.
+
+            Args:
+                request (~.service.UpdateUserRequest):
+                    The request object. Message for updating a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.resources.User:
+                    Message describing User object.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "patch",
+                    "uri": "/v1/{user.name=projects/*/locations/*/clusters/*/users/*}",
+                    "body": "user",
+                },
+            ]
+            request, metadata = self._interceptor.pre_update_user(request, metadata)
+            pb_request = service.UpdateUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = resources.User()
+            pb_resp = resources.User.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_update_user(resp)
+            return resp
+
     @property
     def batch_create_instances(
         self,
     ) -> Callable[[service.BatchCreateInstancesRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._BatchCreateInstances(self._session, self._host, self._interceptor)  # type: ignore
@@ -3510,14 +3944,20 @@
         self,
     ) -> Callable[[service.CreateSecondaryInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._CreateSecondaryInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def create_user(self) -> Callable[[service.CreateUserRequest], resources.User]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._CreateUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def delete_backup(
         self,
     ) -> Callable[[service.DeleteBackupRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._DeleteBackup(self._session, self._host, self._interceptor)  # type: ignore
 
@@ -3534,59 +3974,60 @@
         self,
     ) -> Callable[[service.DeleteInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._DeleteInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
-    def failover_instance(
-        self,
-    ) -> Callable[[service.FailoverInstanceRequest], operations_pb2.Operation]:
+    def delete_user(self) -> Callable[[service.DeleteUserRequest], empty_pb2.Empty]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
-        return self._FailoverInstance(self._session, self._host, self._interceptor)  # type: ignore
+        return self._DeleteUser(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
-    def generate_client_certificate(
+    def failover_instance(
         self,
-    ) -> Callable[
-        [service.GenerateClientCertificateRequest],
-        service.GenerateClientCertificateResponse,
-    ]:
+    ) -> Callable[[service.FailoverInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
-        return self._GenerateClientCertificate(self._session, self._host, self._interceptor)  # type: ignore
+        return self._FailoverInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
     def get_backup(self) -> Callable[[service.GetBackupRequest], resources.Backup]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._GetBackup(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
     def get_cluster(self) -> Callable[[service.GetClusterRequest], resources.Cluster]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._GetCluster(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
-    def get_connection_info(
+    def get_instance(
         self,
-    ) -> Callable[[service.GetConnectionInfoRequest], resources.ConnectionInfo]:
+    ) -> Callable[[service.GetInstanceRequest], resources.Instance]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
-        return self._GetConnectionInfo(self._session, self._host, self._interceptor)  # type: ignore
+        return self._GetInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
-    def get_instance(
+    def get_user(self) -> Callable[[service.GetUserRequest], resources.User]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._GetUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
+    def inject_fault(
         self,
-    ) -> Callable[[service.GetInstanceRequest], resources.Instance]:
+    ) -> Callable[[service.InjectFaultRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
-        return self._GetInstance(self._session, self._host, self._interceptor)  # type: ignore
+        return self._InjectFault(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
     def list_backups(
         self,
     ) -> Callable[[service.ListBackupsRequest], service.ListBackupsResponse]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
@@ -3616,14 +4057,22 @@
         service.ListSupportedDatabaseFlagsResponse,
     ]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._ListSupportedDatabaseFlags(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def list_users(
+        self,
+    ) -> Callable[[service.ListUsersRequest], service.ListUsersResponse]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._ListUsers(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def promote_cluster(
         self,
     ) -> Callable[[service.PromoteClusterRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._PromoteCluster(self._session, self._host, self._interceptor)  # type: ignore
 
@@ -3664,14 +4113,20 @@
         self,
     ) -> Callable[[service.UpdateInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._UpdateInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def update_user(self) -> Callable[[service.UpdateUserRequest], resources.User]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._UpdateUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def get_location(self):
         return self._GetLocation(self._session, self._host, self._interceptor)  # type: ignore
 
     class _GetLocation(AlloyDBAdminRestStub):
         def __call__(
             self,
             request: locations_pb2.GetLocationRequest,
@@ -3695,15 +4150,15 @@
             Returns:
                 locations_pb2.Location: Response from GetLocation method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{name=projects/*/locations/*}",
+                    "uri": "/v1/{name=projects/*/locations/*}",
                 },
             ]
 
             request, metadata = self._interceptor.pre_get_location(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
@@ -3762,15 +4217,15 @@
             Returns:
                 locations_pb2.ListLocationsResponse: Response from ListLocations method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{name=projects/*}/locations",
+                    "uri": "/v1/{name=projects/*}/locations",
                 },
             ]
 
             request, metadata = self._interceptor.pre_list_locations(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
@@ -3826,15 +4281,15 @@
                 metadata (Sequence[Tuple[str, str]]): Strings which should be
                     sent along with the request as metadata.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}:cancel",
+                    "uri": "/v1/{name=projects/*/locations/*/operations/*}:cancel",
                     "body": "*",
                 },
             ]
 
             request, metadata = self._interceptor.pre_cancel_operation(
                 request, metadata
             )
@@ -3892,15 +4347,15 @@
                 metadata (Sequence[Tuple[str, str]]): Strings which should be
                     sent along with the request as metadata.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}",
+                    "uri": "/v1/{name=projects/*/locations/*/operations/*}",
                 },
             ]
 
             request, metadata = self._interceptor.pre_delete_operation(
                 request, metadata
             )
             request_kwargs = json_format.MessageToDict(request)
@@ -3958,15 +4413,15 @@
             Returns:
                 operations_pb2.Operation: Response from GetOperation method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}",
+                    "uri": "/v1/{name=projects/*/locations/*/operations/*}",
                 },
             ]
 
             request, metadata = self._interceptor.pre_get_operation(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
@@ -4025,15 +4480,15 @@
             Returns:
                 operations_pb2.ListOperationsResponse: Response from ListOperations method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1alpha/{name=projects/*/locations/*}/operations",
+                    "uri": "/v1/{name=projects/*/locations/*}/operations",
                 },
             ]
 
             request, metadata = self._interceptor.pre_list_operations(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/types/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -9,118 +9,136 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from .resources import (
+from google.cloud.alloydb_v1 import gapic_version as package_version
+
+__version__ = package_version.__version__
+
+
+from .services.alloy_db_admin import AlloyDBAdminAsyncClient, AlloyDBAdminClient
+from .types.resources import (
     AutomatedBackupPolicy,
     Backup,
     BackupSource,
     Cluster,
-    ConnectionInfo,
+    ClusterView,
     ContinuousBackupConfig,
     ContinuousBackupInfo,
     ContinuousBackupSource,
     DatabaseVersion,
     EncryptionConfig,
     EncryptionInfo,
     Instance,
     InstanceView,
     MigrationSource,
     SslConfig,
     SupportedDatabaseFlag,
+    User,
     UserPassword,
 )
-from .service import (
+from .types.service import (
     BatchCreateInstancesMetadata,
     BatchCreateInstancesRequest,
     BatchCreateInstancesResponse,
     BatchCreateInstanceStatus,
     CreateBackupRequest,
     CreateClusterRequest,
     CreateInstanceRequest,
     CreateInstanceRequests,
     CreateSecondaryClusterRequest,
     CreateSecondaryInstanceRequest,
+    CreateUserRequest,
     DeleteBackupRequest,
     DeleteClusterRequest,
     DeleteInstanceRequest,
+    DeleteUserRequest,
     FailoverInstanceRequest,
-    GenerateClientCertificateRequest,
-    GenerateClientCertificateResponse,
     GetBackupRequest,
     GetClusterRequest,
-    GetConnectionInfoRequest,
     GetInstanceRequest,
+    GetUserRequest,
+    InjectFaultRequest,
     ListBackupsRequest,
     ListBackupsResponse,
     ListClustersRequest,
     ListClustersResponse,
     ListInstancesRequest,
     ListInstancesResponse,
     ListSupportedDatabaseFlagsRequest,
     ListSupportedDatabaseFlagsResponse,
+    ListUsersRequest,
+    ListUsersResponse,
     OperationMetadata,
     PromoteClusterRequest,
     RestartInstanceRequest,
     RestoreClusterRequest,
     UpdateBackupRequest,
     UpdateClusterRequest,
     UpdateInstanceRequest,
+    UpdateUserRequest,
 )
 
 __all__ = (
+    "AlloyDBAdminAsyncClient",
+    "AlloyDBAdminClient",
     "AutomatedBackupPolicy",
     "Backup",
     "BackupSource",
+    "BatchCreateInstanceStatus",
+    "BatchCreateInstancesMetadata",
+    "BatchCreateInstancesRequest",
+    "BatchCreateInstancesResponse",
     "Cluster",
-    "ConnectionInfo",
+    "ClusterView",
     "ContinuousBackupConfig",
     "ContinuousBackupInfo",
     "ContinuousBackupSource",
-    "EncryptionConfig",
-    "EncryptionInfo",
-    "Instance",
-    "MigrationSource",
-    "SslConfig",
-    "SupportedDatabaseFlag",
-    "UserPassword",
-    "DatabaseVersion",
-    "InstanceView",
-    "BatchCreateInstancesMetadata",
-    "BatchCreateInstancesRequest",
-    "BatchCreateInstancesResponse",
-    "BatchCreateInstanceStatus",
     "CreateBackupRequest",
     "CreateClusterRequest",
     "CreateInstanceRequest",
     "CreateInstanceRequests",
     "CreateSecondaryClusterRequest",
     "CreateSecondaryInstanceRequest",
+    "CreateUserRequest",
+    "DatabaseVersion",
     "DeleteBackupRequest",
     "DeleteClusterRequest",
     "DeleteInstanceRequest",
+    "DeleteUserRequest",
+    "EncryptionConfig",
+    "EncryptionInfo",
     "FailoverInstanceRequest",
-    "GenerateClientCertificateRequest",
-    "GenerateClientCertificateResponse",
     "GetBackupRequest",
     "GetClusterRequest",
-    "GetConnectionInfoRequest",
     "GetInstanceRequest",
+    "GetUserRequest",
+    "InjectFaultRequest",
+    "Instance",
+    "InstanceView",
     "ListBackupsRequest",
     "ListBackupsResponse",
     "ListClustersRequest",
     "ListClustersResponse",
     "ListInstancesRequest",
     "ListInstancesResponse",
     "ListSupportedDatabaseFlagsRequest",
     "ListSupportedDatabaseFlagsResponse",
+    "ListUsersRequest",
+    "ListUsersResponse",
+    "MigrationSource",
     "OperationMetadata",
     "PromoteClusterRequest",
     "RestartInstanceRequest",
     "RestoreClusterRequest",
+    "SslConfig",
+    "SupportedDatabaseFlag",
     "UpdateBackupRequest",
     "UpdateClusterRequest",
     "UpdateInstanceRequest",
+    "UpdateUserRequest",
+    "User",
+    "UserPassword",
 )
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/types/resources.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/types/resources.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,16 +23,17 @@
 from google.type import dayofweek_pb2  # type: ignore
 from google.type import timeofday_pb2  # type: ignore
 import proto  # type: ignore
 
 __protobuf__ = proto.module(
     package="google.cloud.alloydb.v1alpha",
     manifest={
-        "DatabaseVersion",
         "InstanceView",
+        "ClusterView",
+        "DatabaseVersion",
         "UserPassword",
         "MigrationSource",
         "EncryptionConfig",
         "EncryptionInfo",
         "SslConfig",
         "AutomatedBackupPolicy",
         "ContinuousBackupConfig",
@@ -40,35 +41,19 @@
         "BackupSource",
         "ContinuousBackupSource",
         "Cluster",
         "Instance",
         "ConnectionInfo",
         "Backup",
         "SupportedDatabaseFlag",
+        "User",
     },
 )
 
 
-class DatabaseVersion(proto.Enum):
-    r"""The supported database engine versions.
-
-    Values:
-        DATABASE_VERSION_UNSPECIFIED (0):
-            This is an unknown database version.
-        POSTGRES_13 (1):
-            DEPRECATED - The database version is Postgres
-            13.
-        POSTGRES_14 (2):
-            The database version is Postgres 14.
-    """
-    DATABASE_VERSION_UNSPECIFIED = 0
-    POSTGRES_13 = 1
-    POSTGRES_14 = 2
-
-
 class InstanceView(proto.Enum):
     r"""View on Instance. Pass this enum to rpcs that returns an
     Instance message to control which subsets of fields to get.
 
     Values:
         INSTANCE_VIEW_UNSPECIFIED (0):
             INSTANCE_VIEW_UNSPECIFIED Not specified, equivalent to
@@ -85,14 +70,54 @@
             the pool.
     """
     INSTANCE_VIEW_UNSPECIFIED = 0
     INSTANCE_VIEW_BASIC = 1
     INSTANCE_VIEW_FULL = 2
 
 
+class ClusterView(proto.Enum):
+    r"""View on Cluster. Pass this enum to rpcs that returns a
+    cluster message to control which subsets of fields to get.
+
+    Values:
+        CLUSTER_VIEW_UNSPECIFIED (0):
+            CLUSTER_VIEW_UNSPECIFIED Not specified, equivalent to BASIC.
+        CLUSTER_VIEW_BASIC (1):
+            BASIC server responses include all the
+            relevant cluster details, excluding
+            Cluster.ContinuousBackupInfo.EarliestRestorableTime
+            and other view-specific fields. The default
+            value.
+        CLUSTER_VIEW_CONTINUOUS_BACKUP (2):
+            CONTINUOUS_BACKUP response returns all the fields from BASIC
+            plus the earliest restorable time if continuous backups are
+            enabled. May increase latency.
+    """
+    CLUSTER_VIEW_UNSPECIFIED = 0
+    CLUSTER_VIEW_BASIC = 1
+    CLUSTER_VIEW_CONTINUOUS_BACKUP = 2
+
+
+class DatabaseVersion(proto.Enum):
+    r"""The supported database engine versions.
+
+    Values:
+        DATABASE_VERSION_UNSPECIFIED (0):
+            This is an unknown database version.
+        POSTGRES_13 (1):
+            DEPRECATED - The database version is Postgres
+            13.
+        POSTGRES_14 (2):
+            The database version is Postgres 14.
+    """
+    DATABASE_VERSION_UNSPECIFIED = 0
+    POSTGRES_13 = 1
+    POSTGRES_14 = 2
+
+
 class UserPassword(proto.Message):
     r"""The username/password for a database user. Used for
     specifying initial users at cluster creation time.
 
     Attributes:
         user (str):
             The database username.
@@ -214,15 +239,15 @@
     kms_key_versions: MutableSequence[str] = proto.RepeatedField(
         proto.STRING,
         number=2,
     )
 
 
 class SslConfig(proto.Message):
-    r"""SSL configuration for an AlloyDB Cluster.
+    r"""SSL configuration.
 
     Attributes:
         ssl_mode (google.cloud.alloydb_v1alpha.types.SslConfig.SslMode):
             Optional. SSL mode. Specifies client-server
             SSL/TLS connection behavior.
         ca_source (google.cloud.alloydb_v1alpha.types.SslConfig.CaSource):
             Optional. Certificate Authority (CA) source. Only
@@ -231,33 +256,41 @@
     """
 
     class SslMode(proto.Enum):
         r"""SSL mode options.
 
         Values:
             SSL_MODE_UNSPECIFIED (0):
-                SSL mode not specified. Defaults to SSL_MODE_ALLOW.
+                SSL mode not specified. Defaults to ENCRYPTED_ONLY.
             SSL_MODE_ALLOW (1):
                 SSL connections are optional. CA verification
                 not enforced.
             SSL_MODE_REQUIRE (2):
                 SSL connections are required. CA verification
                 not enforced. Clients may use locally
                 self-signed certificates (default psql client
                 behavior).
             SSL_MODE_VERIFY_CA (3):
                 SSL connections are required. CA verification
                 enforced. Clients must have certificates signed
                 by a Cluster CA, e.g. via
                 GenerateClientCertificate.
+            ALLOW_UNENCRYPTED_AND_ENCRYPTED (4):
+                SSL connections are optional. CA verification
+                not enforced.
+            ENCRYPTED_ONLY (5):
+                SSL connections are required. CA verification
+                not enforced.
         """
         SSL_MODE_UNSPECIFIED = 0
         SSL_MODE_ALLOW = 1
         SSL_MODE_REQUIRE = 2
         SSL_MODE_VERIFY_CA = 3
+        ALLOW_UNENCRYPTED_AND_ENCRYPTED = 4
+        ENCRYPTED_ONLY = 5
 
     class CaSource(proto.Enum):
         r"""Certificate Authority (CA) source for SSL/TLS certificates.
 
         Values:
             CA_SOURCE_UNSPECIFIED (0):
                 Certificate Authority (CA) source not specified. Defaults to
@@ -500,14 +533,17 @@
             Output only. When ContinuousBackup was most
             recently enabled. Set to null if
             ContinuousBackup is not enabled.
         schedule (MutableSequence[google.type.dayofweek_pb2.DayOfWeek]):
             Output only. Days of the week on which a
             continuous backup is taken. Output only field.
             Ignored if passed into the request.
+        earliest_restorable_time (google.protobuf.timestamp_pb2.Timestamp):
+            Output only. The earliest restorable time
+            that can be restored to. Output only field.
     """
 
     encryption_info: "EncryptionInfo" = proto.Field(
         proto.MESSAGE,
         number=1,
         message="EncryptionInfo",
     )
@@ -517,14 +553,19 @@
         message=timestamp_pb2.Timestamp,
     )
     schedule: MutableSequence[dayofweek_pb2.DayOfWeek] = proto.RepeatedField(
         proto.ENUM,
         number=3,
         enum=dayofweek_pb2.DayOfWeek,
     )
+    earliest_restorable_time: timestamp_pb2.Timestamp = proto.Field(
+        proto.MESSAGE,
+        number=4,
+        message=timestamp_pb2.Timestamp,
+    )
 
 
 class BackupSource(proto.Message):
     r"""Message describing a BackupSource.
 
     Attributes:
         backup_uid (str):
@@ -632,14 +673,16 @@
             which RPC was used to create the cluster (i.e.
             ``CreateCluster`` vs. ``CreateSecondaryCluster``
         database_version (google.cloud.alloydb_v1alpha.types.DatabaseVersion):
             Output only. The database engine major
             version. This is an output-only field and it's
             populated at the Cluster creation time. This
             field cannot be changed after cluster creation.
+        network_config (google.cloud.alloydb_v1alpha.types.Cluster.NetworkConfig):
+
         network (str):
             Required. The resource link for the VPC network in which
             cluster resources are created and from which they are
             accessible via Private IP. The network must belong to the
             same project as the cluster. It is specified in the form:
             "projects/{project_number}/global/networks/{network_id}".
             This is required to create a cluster. It can be updated, but
@@ -669,15 +712,15 @@
             will be used. If backups are supported for the
             cluster, the default policy takes one backup a
             day, has a backup window of 1 hour, and retains
             backups for 14 days. For more information on the
             defaults, consult the documentation for the
             message type.
         ssl_config (google.cloud.alloydb_v1alpha.types.SslConfig):
-            SSL configuration for this AlloyDB Cluster.
+            SSL configuration for this AlloyDB cluster.
         encryption_config (google.cloud.alloydb_v1alpha.types.EncryptionConfig):
             Optional. The encryption config can be
             specified to encrypt the data disks and other
             persistent data resources of a cluster with a
             customer-managed encryption key (CMEK). When
             this field is not specified, the cluster will
             then use default encryption scheme to protect
@@ -762,14 +805,46 @@
                 Secondary cluster that is replicating from
                 another region. This only supports read.
         """
         CLUSTER_TYPE_UNSPECIFIED = 0
         PRIMARY = 1
         SECONDARY = 2
 
+    class NetworkConfig(proto.Message):
+        r"""Metadata related to network configuration.
+
+        Attributes:
+            network (str):
+                Required. The resource link for the VPC network in which
+                cluster resources are created and from which they are
+                accessible via Private IP. The network must belong to the
+                same project as the cluster. It is specified in the form:
+                "projects/{project_number}/global/networks/{network_id}".
+                This is required to create a cluster. It can be updated, but
+                it cannot be removed.
+            allocated_ip_range (str):
+                Optional. The name of the allocated IP range for the private
+                IP AlloyDB cluster. For example:
+                "google-managed-services-default". If set, the instance IPs
+                for this cluster will be created in the allocated range. The
+                range name must comply with RFC 1035. Specifically, the name
+                must be 1-63 characters long and match the regular
+                expression `a-z <[-a-z0-9]*[a-z0-9]>`__?. Field name is
+                intended to be consistent with CloudSQL.
+        """
+
+        network: str = proto.Field(
+            proto.STRING,
+            number=1,
+        )
+        allocated_ip_range: str = proto.Field(
+            proto.STRING,
+            number=2,
+        )
+
     class SecondaryConfig(proto.Message):
         r"""Configuration information for the secondary cluster. This
         should be set if and only if the cluster is of type SECONDARY.
 
         Attributes:
             primary_cluster_name (str):
                 The name of the primary cluster name with the format:
@@ -853,14 +928,19 @@
         enum=ClusterType,
     )
     database_version: "DatabaseVersion" = proto.Field(
         proto.ENUM,
         number=9,
         enum="DatabaseVersion",
     )
+    network_config: NetworkConfig = proto.Field(
+        proto.MESSAGE,
+        number=29,
+        message=NetworkConfig,
+    )
     network: str = proto.Field(
         proto.STRING,
         number=10,
     )
     etag: str = proto.Field(
         proto.STRING,
         number=11,
@@ -962,18 +1042,20 @@
         instance_type (google.cloud.alloydb_v1alpha.types.Instance.InstanceType):
             Required. The type of the instance. Specified
             at creation time.
         machine_config (google.cloud.alloydb_v1alpha.types.Instance.MachineConfig):
             Configurations for the machines that host the
             underlying database engine.
         availability_type (google.cloud.alloydb_v1alpha.types.Instance.AvailabilityType):
-            Availability type of an Instance.
-            Defaults to REGIONAL for both primary and read
-            instances. Note that primary and read instances
-            can have different availability types.
+            Availability type of an Instance. If empty, defaults to
+            REGIONAL for primary instances. For read pools,
+            availability_type is always UNSPECIFIED. Instances in the
+            read pools are evenly distributed across available zones
+            within the region (i.e. read pools with more than one node
+            will have a node in at least two zones).
         gce_zone (str):
             The Compute Engine zone that the instance
             should serve from, per
             https://cloud.google.com/compute/docs/regions-zones
             This can ONLY be specified for ZONAL instances.
             If present for a REGIONAL instance, an error
             will be thrown. If this is absent for a ZONAL
@@ -1023,14 +1105,21 @@
         etag (str):
             For Resource freshness validation
             (https://google.aip.dev/154)
         annotations (MutableMapping[str, str]):
             Annotations to allow client tools to store
             small amount of arbitrary data. This is distinct
             from labels. https://google.aip.dev/128
+        update_policy (google.cloud.alloydb_v1alpha.types.Instance.UpdatePolicy):
+            Update policy that will be applied during
+            instance update. This field is not persisted
+            when you update the instance. To use a
+            non-default update policy, you must
+            specify explicitly specify the value in each
+            update request.
     """
 
     class State(proto.Enum):
         r"""Instance State
 
         Values:
             STATE_UNSPECIFIED (0):
@@ -1097,17 +1186,17 @@
         PRIMARY = 1
         READ_POOL = 2
         SECONDARY = 3
 
     class AvailabilityType(proto.Enum):
         r"""The Availability type of an instance. Potential values:
         - ZONAL: The instance serves data from only one zone. Outages in
-        that zone affect instance availability.
+        that     zone affect instance availability.
         - REGIONAL: The instance can serve data from more than one zone
-        in a region (it is highly available).
+        in a     region (it is highly available).
 
         Values:
             AVAILABILITY_TYPE_UNSPECIFIED (0):
                 This is an unknown Availability type.
             ZONAL (1):
                 Zonal available instance.
             REGIONAL (2):
@@ -1231,14 +1320,44 @@
         """
 
         node_count: int = proto.Field(
             proto.INT32,
             number=1,
         )
 
+    class UpdatePolicy(proto.Message):
+        r"""Policy to be used while updating the instance.
+
+        Attributes:
+            mode (google.cloud.alloydb_v1alpha.types.Instance.UpdatePolicy.Mode):
+                Mode for updating the instance.
+        """
+
+        class Mode(proto.Enum):
+            r"""Specifies the available modes of update.
+
+            Values:
+                MODE_UNSPECIFIED (0):
+                    Mode is unknown.
+                DEFAULT (1):
+                    Least disruptive way to apply the update.
+                FORCE_APPLY (2):
+                    Performs a forced update when applicable.
+                    This will be fast but may incur a downtime.
+            """
+            MODE_UNSPECIFIED = 0
+            DEFAULT = 1
+            FORCE_APPLY = 2
+
+        mode: "Instance.UpdatePolicy.Mode" = proto.Field(
+            proto.ENUM,
+            number=1,
+            enum="Instance.UpdatePolicy.Mode",
+        )
+
     name: str = proto.Field(
         proto.STRING,
         number=1,
     )
     display_name: str = proto.Field(
         proto.STRING,
         number=2,
@@ -1329,14 +1448,19 @@
         number=17,
     )
     annotations: MutableMapping[str, str] = proto.MapField(
         proto.STRING,
         proto.STRING,
         number=18,
     )
+    update_policy: UpdatePolicy = proto.Field(
+        proto.MESSAGE,
+        number=22,
+        message=UpdatePolicy,
+    )
 
 
 class ConnectionInfo(proto.Message):
     r"""ConnectionInfo singleton resource.
     https://google.aip.dev/156
 
     Attributes:
@@ -1416,15 +1540,16 @@
         description (str):
             User-provided description of the backup.
         cluster_uid (str):
             Output only. The system-generated UID of the
             cluster which was used to create this resource.
         cluster_name (str):
             Required. The full resource name of the backup source
-            cluster (e.g., projects//locations//clusters/<cluster_id>).
+            cluster (e.g.,
+            projects/{project}/locations/{region}/clusters/{cluster_id}).
         reconciling (bool):
             Output only. Reconciling
             (https://google.aip.dev/128#reconciliation), if
             true, indicates that the service is actively
             updating the resource. This can happen due to
             user-triggered updates or system actions like
             failover or maintenance.
@@ -1735,8 +1860,62 @@
     )
     requires_db_restart: bool = proto.Field(
         proto.BOOL,
         number=6,
     )
 
 
+class User(proto.Message):
+    r"""Message describing User object.
+
+    Attributes:
+        name (str):
+            Output only. Name of the resource in the form
+            of
+            projects/{project}/locations/{location}/cluster/{cluster}/users/{user}.
+        password (str):
+            Input only. Password for the user.
+        database_roles (MutableSequence[str]):
+            Optional. List of database roles this user
+            has. The database role strings are subject to
+            the PostgreSQL naming conventions.
+        user_type (google.cloud.alloydb_v1alpha.types.User.UserType):
+            Optional. Type of this user.
+    """
+
+    class UserType(proto.Enum):
+        r"""Enum that details the user type.
+
+        Values:
+            USER_TYPE_UNSPECIFIED (0):
+                Unspecified user type.
+            ALLOYDB_BUILT_IN (1):
+                The default user type that authenticates via
+                password-based authentication.
+            ALLOYDB_IAM_USER (2):
+                Database user that can authenticate via
+                IAM-Based authentication.
+        """
+        USER_TYPE_UNSPECIFIED = 0
+        ALLOYDB_BUILT_IN = 1
+        ALLOYDB_IAM_USER = 2
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    password: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    database_roles: MutableSequence[str] = proto.RepeatedField(
+        proto.STRING,
+        number=4,
+    )
+    user_type: UserType = proto.Field(
+        proto.ENUM,
+        number=5,
+        enum=UserType,
+    )
+
+
 __all__ = tuple(sorted(__protobuf__.manifest))
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1alpha/types/service.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/types/service.py`

 * *Files 8% similar despite different names*

```diff
@@ -46,27 +46,34 @@
         "BatchCreateInstancesRequest",
         "BatchCreateInstancesResponse",
         "BatchCreateInstancesMetadata",
         "BatchCreateInstanceStatus",
         "UpdateInstanceRequest",
         "DeleteInstanceRequest",
         "FailoverInstanceRequest",
+        "InjectFaultRequest",
         "RestartInstanceRequest",
         "ListBackupsRequest",
         "ListBackupsResponse",
         "GetBackupRequest",
         "CreateBackupRequest",
         "UpdateBackupRequest",
         "DeleteBackupRequest",
         "ListSupportedDatabaseFlagsRequest",
         "ListSupportedDatabaseFlagsResponse",
         "GenerateClientCertificateRequest",
         "GenerateClientCertificateResponse",
         "GetConnectionInfoRequest",
         "OperationMetadata",
+        "ListUsersRequest",
+        "ListUsersResponse",
+        "GetUserRequest",
+        "CreateUserRequest",
+        "UpdateUserRequest",
+        "DeleteUserRequest",
     },
 )
 
 
 class ListClustersRequest(proto.Message):
     r"""Message for requesting list of Clusters
 
@@ -150,30 +157,38 @@
     r"""Message for getting a Cluster
 
     Attributes:
         name (str):
             Required. The name of the resource. For the
             required format, see the comment on the
             Cluster.name field.
+        view (google.cloud.alloydb_v1alpha.types.ClusterView):
+            Optional. The view of the cluster to return.
+            Returns all default fields if not set.
     """
 
     name: str = proto.Field(
         proto.STRING,
         number=1,
     )
+    view: resources.ClusterView = proto.Field(
+        proto.ENUM,
+        number=2,
+        enum=resources.ClusterView,
+    )
 
 
 class CreateSecondaryClusterRequest(proto.Message):
     r"""
 
     Attributes:
         parent (str):
-            Required. The name of the parent resource
-            (the primary cluster). For the required format,
-            see the comment on the Cluster.name field.
+            Required. The location of the new cluster.
+            For the required format, see the comment on the
+            Cluster.name field.
         cluster_id (str):
             Required. ID of the requesting object (the
             secondary cluster).
         cluster (google.cloud.alloydb_v1alpha.types.Cluster):
             Required. Configuration of the requesting
             object (the secondary cluster).
         request_id (str):
@@ -225,15 +240,15 @@
 
 
 class CreateClusterRequest(proto.Message):
     r"""Message for creating a Cluster
 
     Attributes:
         parent (str):
-            Required. The name of the parent resource.
+            Required. The location of the new cluster.
             For the required format, see the comment on the
             Cluster.name field.
         cluster_id (str):
             Required. ID of the requesting object.
         cluster (google.cloud.alloydb_v1alpha.types.Cluster):
             Required. The resource being created
         request_id (str):
@@ -856,16 +871,16 @@
         proto.MESSAGE,
         number=1,
         message=resources.Instance,
     )
 
 
 class BatchCreateInstancesMetadata(proto.Message):
-    r"""Message for metadata that is specific to BatchCreateInstances
-    API.
+    r"""Message for metadata that is specific to BatchCreateInstances API.
+    NEXT_ID: 3
 
     Attributes:
         instance_targets (MutableSequence[str]):
             The instances being created in the API call.
             Each string in this list is the server defined
             resource path for target instances in the
             request and for the format of each string, see
@@ -902,18 +917,20 @@
     failed to create and the 4th was never picked up for creation
     because of failure of the previous one. Then, resulting states would
     look something like:
 
     1. Instance1 = ROLLED_BACK
     2. Instance2 = ROLLED_BACK
     3. Instance3 = FAILED
-    4. Instance4 = FAILED However, while the operation is running, the
-       instance might be in other states including PENDING_CREATE,
-       ACTIVE, DELETING and CREATING. The states / do not get further
-       updated once the operation is done.
+    4. Instance4 = FAILED
+
+    However, while the operation is running, the instance might be in
+    other states including PENDING_CREATE, ACTIVE, DELETING and
+    CREATING. The states / do not get further updated once the operation
+    is done.
 
     Attributes:
         state (google.cloud.alloydb_v1alpha.types.BatchCreateInstanceStatus.State):
             The current state of an instance involved in the batch
             create operation. Once the operation is complete, the final
             state of the instances in the LRO can be one of:
 
@@ -1156,14 +1173,82 @@
     )
     validate_only: bool = proto.Field(
         proto.BOOL,
         number=3,
     )
 
 
+class InjectFaultRequest(proto.Message):
+    r"""Message for triggering fault injection on an instance
+
+    Attributes:
+        fault_type (google.cloud.alloydb_v1alpha.types.InjectFaultRequest.FaultType):
+            Required. The type of fault to be injected in
+            an instance.
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            Instance.name field.
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes after the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, performs request validation
+            (e.g. permission checks and any other type of
+            validation), but do not actually execute the
+            fault injection.
+    """
+
+    class FaultType(proto.Enum):
+        r"""FaultType contains all valid types of faults that can be
+        injected to an instance.
+
+        Values:
+            FAULT_TYPE_UNSPECIFIED (0):
+                The fault type is unknown.
+            STOP_VM (1):
+                Stop the VM
+        """
+        FAULT_TYPE_UNSPECIFIED = 0
+        STOP_VM = 1
+
+    fault_type: FaultType = proto.Field(
+        proto.ENUM,
+        number=1,
+        enum=FaultType,
+    )
+    name: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=4,
+    )
+
+
 class RestartInstanceRequest(proto.Message):
     r"""
 
     Attributes:
         name (str):
             Required. The name of the resource. For the
             required format, see the comment on the
@@ -1569,14 +1654,16 @@
             Optional. An optional hint to the endpoint to
             generate the client certificate with the
             requested duration. The duration can be from 1
             hour to 24 hours. The endpoint may or may not
             honor the hint. If the hint is left unspecified
             or is not honored, then the endpoint will pick
             an appropriate default duration.
+        public_key (str):
+            Optional. The public key from the client.
     """
 
     parent: str = proto.Field(
         proto.STRING,
         number=1,
     )
     request_id: str = proto.Field(
@@ -1588,38 +1675,49 @@
         number=3,
     )
     cert_duration: duration_pb2.Duration = proto.Field(
         proto.MESSAGE,
         number=4,
         message=duration_pb2.Duration,
     )
+    public_key: str = proto.Field(
+        proto.STRING,
+        number=5,
+    )
 
 
 class GenerateClientCertificateResponse(proto.Message):
     r"""Message returned by a GenerateClientCertificate operation.
 
     Attributes:
         pem_certificate (str):
             Output only. The pem-encoded, signed X.509
             certificate.
         pem_certificate_chain (MutableSequence[str]):
             Output only. The pem-encoded chain that may
             be used to verify the X.509 certificate.
             Expected to be in issuer-to-root order according
             to RFC 5246.
+        ca_cert (str):
+            Optional. The pem-encoded cluster ca X.509
+            certificate.
     """
 
     pem_certificate: str = proto.Field(
         proto.STRING,
         number=1,
     )
     pem_certificate_chain: MutableSequence[str] = proto.RepeatedField(
         proto.STRING,
         number=2,
     )
+    ca_cert: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
 
 
 class GetConnectionInfoRequest(proto.Message):
     r"""Request message for GetConnectionInfo.
 
     Attributes:
         parent (str):
@@ -1727,8 +1825,262 @@
     )
     api_version: str = proto.Field(
         proto.STRING,
         number=7,
     )
 
 
+class ListUsersRequest(proto.Message):
+    r"""Message for requesting list of Users
+
+    Attributes:
+        parent (str):
+            Required. Parent value for ListUsersRequest
+        page_size (int):
+            Optional. Requested page size. Server may
+            return fewer items than requested. If
+            unspecified, server will pick an appropriate
+            default.
+        page_token (str):
+            Optional. A token identifying a page of
+            results the server should return.
+        filter (str):
+            Optional. Filtering results
+        order_by (str):
+            Optional. Hint for how to order the results
+    """
+
+    parent: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    page_size: int = proto.Field(
+        proto.INT32,
+        number=2,
+    )
+    page_token: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    filter: str = proto.Field(
+        proto.STRING,
+        number=4,
+    )
+    order_by: str = proto.Field(
+        proto.STRING,
+        number=5,
+    )
+
+
+class ListUsersResponse(proto.Message):
+    r"""Message for response to listing Users
+
+    Attributes:
+        users (MutableSequence[google.cloud.alloydb_v1alpha.types.User]):
+            The list of User
+        next_page_token (str):
+            A token identifying a page of results the
+            server should return.
+        unreachable (MutableSequence[str]):
+            Locations that could not be reached.
+    """
+
+    @property
+    def raw_page(self):
+        return self
+
+    users: MutableSequence[resources.User] = proto.RepeatedField(
+        proto.MESSAGE,
+        number=1,
+        message=resources.User,
+    )
+    next_page_token: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    unreachable: MutableSequence[str] = proto.RepeatedField(
+        proto.STRING,
+        number=3,
+    )
+
+
+class GetUserRequest(proto.Message):
+    r"""Message for getting a User
+
+    Attributes:
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            User.name field.
+    """
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+
+
+class CreateUserRequest(proto.Message):
+    r"""Message for creating a User
+
+    Attributes:
+        parent (str):
+            Required. Value for parent.
+        user_id (str):
+            Required. ID of the requesting object.
+        user (google.cloud.alloydb_v1alpha.types.User):
+            Required. The resource being created
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes since the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, the backend validates the
+            request, but doesn't actually execute it.
+    """
+
+    parent: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    user_id: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    user: resources.User = proto.Field(
+        proto.MESSAGE,
+        number=3,
+        message=resources.User,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=4,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=5,
+    )
+
+
+class UpdateUserRequest(proto.Message):
+    r"""Message for updating a User
+
+    Attributes:
+        update_mask (google.protobuf.field_mask_pb2.FieldMask):
+            Optional. Field mask is used to specify the fields to be
+            overwritten in the User resource by the update. The fields
+            specified in the update_mask are relative to the resource,
+            not the full request. A field will be overwritten if it is
+            in the mask. If the user does not provide a mask then all
+            fields will be overwritten.
+        user (google.cloud.alloydb_v1alpha.types.User):
+            Required. The resource being updated
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes since the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, the backend validates the
+            request, but doesn't actually execute it.
+        allow_missing (bool):
+            Optional. Allow missing fields in the update
+            mask.
+    """
+
+    update_mask: field_mask_pb2.FieldMask = proto.Field(
+        proto.MESSAGE,
+        number=1,
+        message=field_mask_pb2.FieldMask,
+    )
+    user: resources.User = proto.Field(
+        proto.MESSAGE,
+        number=2,
+        message=resources.User,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=4,
+    )
+    allow_missing: bool = proto.Field(
+        proto.BOOL,
+        number=5,
+    )
+
+
+class DeleteUserRequest(proto.Message):
+    r"""Message for deleting a User
+
+    Attributes:
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            User.name field.
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes after the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, the backend validates the
+            request, but doesn't actually execute it.
+    """
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=3,
+    )
+
+
 __all__ = tuple(sorted(__protobuf__.manifest))
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/types/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -9,126 +9,136 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from google.cloud.alloydb_v1beta import gapic_version as package_version
-
-__version__ = package_version.__version__
-
-
-from .services.alloy_db_admin import AlloyDBAdminAsyncClient, AlloyDBAdminClient
-from .types.resources import (
+from .resources import (
     AutomatedBackupPolicy,
     Backup,
     BackupSource,
     Cluster,
+    ClusterView,
     ConnectionInfo,
     ContinuousBackupConfig,
     ContinuousBackupInfo,
     ContinuousBackupSource,
     DatabaseVersion,
     EncryptionConfig,
     EncryptionInfo,
     Instance,
     InstanceView,
     MigrationSource,
     SslConfig,
     SupportedDatabaseFlag,
+    User,
     UserPassword,
 )
-from .types.service import (
+from .service import (
     BatchCreateInstancesMetadata,
     BatchCreateInstancesRequest,
     BatchCreateInstancesResponse,
     BatchCreateInstanceStatus,
     CreateBackupRequest,
     CreateClusterRequest,
     CreateInstanceRequest,
     CreateInstanceRequests,
     CreateSecondaryClusterRequest,
     CreateSecondaryInstanceRequest,
+    CreateUserRequest,
     DeleteBackupRequest,
     DeleteClusterRequest,
     DeleteInstanceRequest,
+    DeleteUserRequest,
     FailoverInstanceRequest,
     GenerateClientCertificateRequest,
     GenerateClientCertificateResponse,
     GetBackupRequest,
     GetClusterRequest,
     GetConnectionInfoRequest,
     GetInstanceRequest,
+    GetUserRequest,
+    InjectFaultRequest,
     ListBackupsRequest,
     ListBackupsResponse,
     ListClustersRequest,
     ListClustersResponse,
     ListInstancesRequest,
     ListInstancesResponse,
     ListSupportedDatabaseFlagsRequest,
     ListSupportedDatabaseFlagsResponse,
+    ListUsersRequest,
+    ListUsersResponse,
     OperationMetadata,
     PromoteClusterRequest,
     RestartInstanceRequest,
     RestoreClusterRequest,
     UpdateBackupRequest,
     UpdateClusterRequest,
     UpdateInstanceRequest,
+    UpdateUserRequest,
 )
 
 __all__ = (
-    "AlloyDBAdminAsyncClient",
-    "AlloyDBAdminClient",
     "AutomatedBackupPolicy",
     "Backup",
     "BackupSource",
-    "BatchCreateInstanceStatus",
-    "BatchCreateInstancesMetadata",
-    "BatchCreateInstancesRequest",
-    "BatchCreateInstancesResponse",
     "Cluster",
     "ConnectionInfo",
     "ContinuousBackupConfig",
     "ContinuousBackupInfo",
     "ContinuousBackupSource",
+    "EncryptionConfig",
+    "EncryptionInfo",
+    "Instance",
+    "MigrationSource",
+    "SslConfig",
+    "SupportedDatabaseFlag",
+    "User",
+    "UserPassword",
+    "ClusterView",
+    "DatabaseVersion",
+    "InstanceView",
+    "BatchCreateInstancesMetadata",
+    "BatchCreateInstancesRequest",
+    "BatchCreateInstancesResponse",
+    "BatchCreateInstanceStatus",
     "CreateBackupRequest",
     "CreateClusterRequest",
     "CreateInstanceRequest",
     "CreateInstanceRequests",
     "CreateSecondaryClusterRequest",
     "CreateSecondaryInstanceRequest",
-    "DatabaseVersion",
+    "CreateUserRequest",
     "DeleteBackupRequest",
     "DeleteClusterRequest",
     "DeleteInstanceRequest",
-    "EncryptionConfig",
-    "EncryptionInfo",
+    "DeleteUserRequest",
     "FailoverInstanceRequest",
     "GenerateClientCertificateRequest",
     "GenerateClientCertificateResponse",
     "GetBackupRequest",
     "GetClusterRequest",
     "GetConnectionInfoRequest",
     "GetInstanceRequest",
-    "Instance",
-    "InstanceView",
+    "GetUserRequest",
+    "InjectFaultRequest",
     "ListBackupsRequest",
     "ListBackupsResponse",
     "ListClustersRequest",
     "ListClustersResponse",
     "ListInstancesRequest",
     "ListInstancesResponse",
     "ListSupportedDatabaseFlagsRequest",
     "ListSupportedDatabaseFlagsResponse",
-    "MigrationSource",
+    "ListUsersRequest",
+    "ListUsersResponse",
     "OperationMetadata",
     "PromoteClusterRequest",
     "RestartInstanceRequest",
     "RestoreClusterRequest",
-    "SslConfig",
-    "SupportedDatabaseFlag",
     "UpdateBackupRequest",
     "UpdateClusterRequest",
     "UpdateInstanceRequest",
-    "UserPassword",
+    "UpdateUserRequest",
 )
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/gapic_metadata.json` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/gapic_metadata.json`

 * *Files 10% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9994959677419355%*

 * *Differences: {"'services'": "{'AlloyDBAdmin': {'clients': {'grpc': {'rpcs': {'CreateUser': "*

 * *               "OrderedDict([('methods', ['create_user'])]), 'DeleteUser': "*

 * *               "OrderedDict([('methods', ['delete_user'])]), 'GetUser': OrderedDict([('methods', "*

 * *               "['get_user'])]), 'InjectFault': OrderedDict([('methods', ['inject_fault'])]), "*

 * *               "'ListUsers': OrderedDict([('methods', ['list_users'])]), 'UpdateUser': "*

 * *               "OrderedDict([('methods', ['update_user'])])}}, 'grpc-as [â€¦]*

```diff
@@ -36,14 +36,19 @@
                             ]
                         },
                         "CreateSecondaryInstance": {
                             "methods": [
                                 "create_secondary_instance"
                             ]
                         },
+                        "CreateUser": {
+                            "methods": [
+                                "create_user"
+                            ]
+                        },
                         "DeleteBackup": {
                             "methods": [
                                 "delete_backup"
                             ]
                         },
                         "DeleteCluster": {
                             "methods": [
@@ -51,14 +56,19 @@
                             ]
                         },
                         "DeleteInstance": {
                             "methods": [
                                 "delete_instance"
                             ]
                         },
+                        "DeleteUser": {
+                            "methods": [
+                                "delete_user"
+                            ]
+                        },
                         "FailoverInstance": {
                             "methods": [
                                 "failover_instance"
                             ]
                         },
                         "GenerateClientCertificate": {
                             "methods": [
@@ -81,14 +91,24 @@
                             ]
                         },
                         "GetInstance": {
                             "methods": [
                                 "get_instance"
                             ]
                         },
+                        "GetUser": {
+                            "methods": [
+                                "get_user"
+                            ]
+                        },
+                        "InjectFault": {
+                            "methods": [
+                                "inject_fault"
+                            ]
+                        },
                         "ListBackups": {
                             "methods": [
                                 "list_backups"
                             ]
                         },
                         "ListClusters": {
                             "methods": [
@@ -101,14 +121,19 @@
                             ]
                         },
                         "ListSupportedDatabaseFlags": {
                             "methods": [
                                 "list_supported_database_flags"
                             ]
                         },
+                        "ListUsers": {
+                            "methods": [
+                                "list_users"
+                            ]
+                        },
                         "PromoteCluster": {
                             "methods": [
                                 "promote_cluster"
                             ]
                         },
                         "RestartInstance": {
                             "methods": [
@@ -130,14 +155,19 @@
                                 "update_cluster"
                             ]
                         },
                         "UpdateInstance": {
                             "methods": [
                                 "update_instance"
                             ]
+                        },
+                        "UpdateUser": {
+                            "methods": [
+                                "update_user"
+                            ]
                         }
                     }
                 },
                 "grpc-async": {
                     "libraryClient": "AlloyDBAdminAsyncClient",
                     "rpcs": {
                         "BatchCreateInstances": {
@@ -166,14 +196,19 @@
                             ]
                         },
                         "CreateSecondaryInstance": {
                             "methods": [
                                 "create_secondary_instance"
                             ]
                         },
+                        "CreateUser": {
+                            "methods": [
+                                "create_user"
+                            ]
+                        },
                         "DeleteBackup": {
                             "methods": [
                                 "delete_backup"
                             ]
                         },
                         "DeleteCluster": {
                             "methods": [
@@ -181,14 +216,19 @@
                             ]
                         },
                         "DeleteInstance": {
                             "methods": [
                                 "delete_instance"
                             ]
                         },
+                        "DeleteUser": {
+                            "methods": [
+                                "delete_user"
+                            ]
+                        },
                         "FailoverInstance": {
                             "methods": [
                                 "failover_instance"
                             ]
                         },
                         "GenerateClientCertificate": {
                             "methods": [
@@ -211,14 +251,24 @@
                             ]
                         },
                         "GetInstance": {
                             "methods": [
                                 "get_instance"
                             ]
                         },
+                        "GetUser": {
+                            "methods": [
+                                "get_user"
+                            ]
+                        },
+                        "InjectFault": {
+                            "methods": [
+                                "inject_fault"
+                            ]
+                        },
                         "ListBackups": {
                             "methods": [
                                 "list_backups"
                             ]
                         },
                         "ListClusters": {
                             "methods": [
@@ -231,14 +281,19 @@
                             ]
                         },
                         "ListSupportedDatabaseFlags": {
                             "methods": [
                                 "list_supported_database_flags"
                             ]
                         },
+                        "ListUsers": {
+                            "methods": [
+                                "list_users"
+                            ]
+                        },
                         "PromoteCluster": {
                             "methods": [
                                 "promote_cluster"
                             ]
                         },
                         "RestartInstance": {
                             "methods": [
@@ -260,14 +315,19 @@
                                 "update_cluster"
                             ]
                         },
                         "UpdateInstance": {
                             "methods": [
                                 "update_instance"
                             ]
+                        },
+                        "UpdateUser": {
+                            "methods": [
+                                "update_user"
+                            ]
                         }
                     }
                 },
                 "rest": {
                     "libraryClient": "AlloyDBAdminClient",
                     "rpcs": {
                         "BatchCreateInstances": {
@@ -296,14 +356,19 @@
                             ]
                         },
                         "CreateSecondaryInstance": {
                             "methods": [
                                 "create_secondary_instance"
                             ]
                         },
+                        "CreateUser": {
+                            "methods": [
+                                "create_user"
+                            ]
+                        },
                         "DeleteBackup": {
                             "methods": [
                                 "delete_backup"
                             ]
                         },
                         "DeleteCluster": {
                             "methods": [
@@ -311,14 +376,19 @@
                             ]
                         },
                         "DeleteInstance": {
                             "methods": [
                                 "delete_instance"
                             ]
                         },
+                        "DeleteUser": {
+                            "methods": [
+                                "delete_user"
+                            ]
+                        },
                         "FailoverInstance": {
                             "methods": [
                                 "failover_instance"
                             ]
                         },
                         "GenerateClientCertificate": {
                             "methods": [
@@ -341,14 +411,24 @@
                             ]
                         },
                         "GetInstance": {
                             "methods": [
                                 "get_instance"
                             ]
                         },
+                        "GetUser": {
+                            "methods": [
+                                "get_user"
+                            ]
+                        },
+                        "InjectFault": {
+                            "methods": [
+                                "inject_fault"
+                            ]
+                        },
                         "ListBackups": {
                             "methods": [
                                 "list_backups"
                             ]
                         },
                         "ListClusters": {
                             "methods": [
@@ -361,14 +441,19 @@
                             ]
                         },
                         "ListSupportedDatabaseFlags": {
                             "methods": [
                                 "list_supported_database_flags"
                             ]
                         },
+                        "ListUsers": {
+                            "methods": [
+                                "list_users"
+                            ]
+                        },
                         "PromoteCluster": {
                             "methods": [
                                 "promote_cluster"
                             ]
                         },
                         "RestartInstance": {
                             "methods": [
@@ -390,14 +475,19 @@
                                 "update_cluster"
                             ]
                         },
                         "UpdateInstance": {
                             "methods": [
                                 "update_instance"
                             ]
+                        },
+                        "UpdateUser": {
+                            "methods": [
+                                "update_user"
+                            ]
                         }
                     }
                 }
             }
         }
     }
 }
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/gapic_version.py` & `google-cloud-alloydb-0.2.0/tests/unit/gapic/__init__.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,17 +1,15 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2022 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-
-__version__ = "0.1.1"  # {x-release-please-version}
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/__init__.py` & `google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/async_client.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/async_client.py`

 * *Files 8% similar despite different names*

```diff
@@ -86,14 +86,16 @@
     parse_network_path = staticmethod(AlloyDBAdminClient.parse_network_path)
     supported_database_flag_path = staticmethod(
         AlloyDBAdminClient.supported_database_flag_path
     )
     parse_supported_database_flag_path = staticmethod(
         AlloyDBAdminClient.parse_supported_database_flag_path
     )
+    user_path = staticmethod(AlloyDBAdminClient.user_path)
+    parse_user_path = staticmethod(AlloyDBAdminClient.parse_user_path)
     common_billing_account_path = staticmethod(
         AlloyDBAdminClient.common_billing_account_path
     )
     parse_common_billing_account_path = staticmethod(
         AlloyDBAdminClient.parse_common_billing_account_path
     )
     common_folder_path = staticmethod(AlloyDBAdminClient.common_folder_path)
@@ -534,16 +536,16 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Optional[Union[google.cloud.alloydb_v1beta.types.CreateClusterRequest, dict]]):
                 The request object. Message for creating a Cluster
             parent (:class:`str`):
-                Required. The name of the parent
-                resource. For the required format, see
+                Required. The location of the new
+                cluster. For the required format, see
                 the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (:class:`google.cloud.alloydb_v1beta.types.Cluster`):
                 Required. The resource being created
@@ -1167,18 +1169,17 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Optional[Union[google.cloud.alloydb_v1beta.types.CreateSecondaryClusterRequest, dict]]):
                 The request object.
             parent (:class:`str`):
-                Required. The name of the parent
-                resource (the primary cluster). For the
-                required format, see the comment on the
-                Cluster.name field.
+                Required. The location of the new
+                cluster. For the required format, see
+                the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (:class:`google.cloud.alloydb_v1beta.types.Cluster`):
                 Required. Configuration of the
                 requesting object (the secondary
@@ -2272,14 +2273,143 @@
             resources.Instance,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    async def inject_fault(
+        self,
+        request: Optional[Union[service.InjectFaultRequest, dict]] = None,
+        *,
+        fault_type: Optional[service.InjectFaultRequest.FaultType] = None,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation_async.AsyncOperation:
+        r"""Injects fault in an instance.
+        Imperative only.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            async def sample_inject_fault():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.InjectFaultRequest(
+                    fault_type="STOP_VM",
+                    name="name_value",
+                )
+
+                # Make the request
+                operation = client.inject_fault(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = (await operation).result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1beta.types.InjectFaultRequest, dict]]):
+                The request object. Message for triggering fault
+                injection on an instance
+            fault_type (:class:`google.cloud.alloydb_v1beta.types.InjectFaultRequest.FaultType`):
+                Required. The type of fault to be
+                injected in an instance.
+
+                This corresponds to the ``fault_type`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the Instance.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation_async.AsyncOperation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1beta.types.Instance` An Instance is a computing unit that an end customer can connect to.
+                   It's the main unit of computing resources in AlloyDB.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([fault_type, name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.InjectFaultRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if fault_type is not None:
+            request.fault_type = fault_type
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.inject_fault,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation_async.from_gapic(
+            response,
+            self._client._transport.operations_client,
+            resources.Instance,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     async def restart_instance(
         self,
         request: Optional[Union[service.RestartInstanceRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -3378,14 +3508,564 @@
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
+    async def list_users(
+        self,
+        request: Optional[Union[service.ListUsersRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> pagers.ListUsersAsyncPager:
+        r"""Lists Users in a given project and location.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            async def sample_list_users():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.ListUsersRequest(
+                    parent="parent_value",
+                )
+
+                # Make the request
+                page_result = client.list_users(request=request)
+
+                # Handle the response
+                async for response in page_result:
+                    print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1beta.types.ListUsersRequest, dict]]):
+                The request object. Message for requesting list of Users
+            parent (:class:`str`):
+                Required. Parent value for
+                ListUsersRequest
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1beta.services.alloy_db_admin.pagers.ListUsersAsyncPager:
+                Message for response to listing Users
+                Iterating over this object will yield
+                results and resolve additional pages
+                automatically.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.ListUsersRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.list_users,
+            default_retry=retries.Retry(
+                initial=1.0,
+                maximum=60.0,
+                multiplier=1.3,
+                predicate=retries.if_exception_type(
+                    core_exceptions.ServiceUnavailable,
+                ),
+                deadline=60.0,
+            ),
+            default_timeout=60.0,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # This method is paged; wrap the response in a pager, which provides
+        # an `__aiter__` convenience method.
+        response = pagers.ListUsersAsyncPager(
+            method=rpc,
+            request=request,
+            response=response,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def get_user(
+        self,
+        request: Optional[Union[service.GetUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Gets details of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            async def sample_get_user():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.GetUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                response = await client.get_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1beta.types.GetUserRequest, dict]]):
+                The request object. Message for getting a User
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1beta.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.GetUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.get_user,
+            default_retry=retries.Retry(
+                initial=1.0,
+                maximum=60.0,
+                multiplier=1.3,
+                predicate=retries.if_exception_type(
+                    core_exceptions.ServiceUnavailable,
+                ),
+                deadline=60.0,
+            ),
+            default_timeout=60.0,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def create_user(
+        self,
+        request: Optional[Union[service.CreateUserRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        user: Optional[resources.User] = None,
+        user_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Creates a new User in a given project, location, and
+        cluster.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            async def sample_create_user():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.CreateUserRequest(
+                    parent="parent_value",
+                    user_id="user_id_value",
+                )
+
+                # Make the request
+                response = await client.create_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1beta.types.CreateUserRequest, dict]]):
+                The request object. Message for creating a User
+            parent (:class:`str`):
+                Required. Value for parent.
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user (:class:`google.cloud.alloydb_v1beta.types.User`):
+                Required. The resource being created
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user_id (:class:`str`):
+                Required. ID of the requesting
+                object.
+
+                This corresponds to the ``user_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1beta.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, user, user_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.CreateUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+        if user is not None:
+            request.user = user
+        if user_id is not None:
+            request.user_id = user_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.create_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def update_user(
+        self,
+        request: Optional[Union[service.UpdateUserRequest, dict]] = None,
+        *,
+        user: Optional[resources.User] = None,
+        update_mask: Optional[field_mask_pb2.FieldMask] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Updates the parameters of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            async def sample_update_user():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.UpdateUserRequest(
+                )
+
+                # Make the request
+                response = await client.update_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1beta.types.UpdateUserRequest, dict]]):
+                The request object. Message for updating a User
+            user (:class:`google.cloud.alloydb_v1beta.types.User`):
+                Required. The resource being updated
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
+                Optional. Field mask is used to specify the fields to be
+                overwritten in the User resource by the update. The
+                fields specified in the update_mask are relative to the
+                resource, not the full request. A field will be
+                overwritten if it is in the mask. If the user does not
+                provide a mask then all fields will be overwritten.
+
+                This corresponds to the ``update_mask`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1beta.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([user, update_mask])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.UpdateUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if user is not None:
+            request.user = user
+        if update_mask is not None:
+            request.update_mask = update_mask
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.update_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata(
+                (("user.name", request.user.name),)
+            ),
+        )
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    async def delete_user(
+        self,
+        request: Optional[Union[service.DeleteUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> None:
+        r"""Deletes a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            async def sample_delete_user():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminAsyncClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.DeleteUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                await client.delete_user(request=request)
+
+        Args:
+            request (Optional[Union[google.cloud.alloydb_v1beta.types.DeleteUserRequest, dict]]):
+                The request object. Message for deleting a User
+            name (:class:`str`):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        request = service.DeleteUserRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.delete_user,
+            default_timeout=None,
+            client_info=DEFAULT_CLIENT_INFO,
+        )
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
     async def list_operations(
         self,
         request: Optional[operations_pb2.ListOperationsRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/client.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/client.py`

 * *Files 5% similar despite different names*

```diff
@@ -341,14 +341,38 @@
         m = re.match(
             r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/flags/(?P<flag>.+?)$",
             path,
         )
         return m.groupdict() if m else {}
 
     @staticmethod
+    def user_path(
+        project: str,
+        location: str,
+        cluster: str,
+        user: str,
+    ) -> str:
+        """Returns a fully-qualified user string."""
+        return "projects/{project}/locations/{location}/clusters/{cluster}/users/{user}".format(
+            project=project,
+            location=location,
+            cluster=cluster,
+            user=user,
+        )
+
+    @staticmethod
+    def parse_user_path(path: str) -> Dict[str, str]:
+        """Parses a user path into its component segments."""
+        m = re.match(
+            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/clusters/(?P<cluster>.+?)/users/(?P<user>.+?)$",
+            path,
+        )
+        return m.groupdict() if m else {}
+
+    @staticmethod
     def common_billing_account_path(
         billing_account: str,
     ) -> str:
         """Returns a fully-qualified billing_account string."""
         return "billingAccounts/{billing_account}".format(
             billing_account=billing_account,
         )
@@ -864,16 +888,16 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Union[google.cloud.alloydb_v1beta.types.CreateClusterRequest, dict]):
                 The request object. Message for creating a Cluster
             parent (str):
-                Required. The name of the parent
-                resource. For the required format, see
+                Required. The location of the new
+                cluster. For the required format, see
                 the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (google.cloud.alloydb_v1beta.types.Cluster):
                 Required. The resource being created
@@ -1498,18 +1522,17 @@
                 # Handle the response
                 print(response)
 
         Args:
             request (Union[google.cloud.alloydb_v1beta.types.CreateSecondaryClusterRequest, dict]):
                 The request object.
             parent (str):
-                Required. The name of the parent
-                resource (the primary cluster). For the
-                required format, see the comment on the
-                Cluster.name field.
+                Required. The location of the new
+                cluster. For the required format, see
+                the comment on the Cluster.name field.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             cluster (google.cloud.alloydb_v1beta.types.Cluster):
                 Required. Configuration of the
                 requesting object (the secondary
@@ -2588,14 +2611,143 @@
             resources.Instance,
             metadata_type=service.OperationMetadata,
         )
 
         # Done; return the response.
         return response
 
+    def inject_fault(
+        self,
+        request: Optional[Union[service.InjectFaultRequest, dict]] = None,
+        *,
+        fault_type: Optional[service.InjectFaultRequest.FaultType] = None,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> operation.Operation:
+        r"""Injects fault in an instance.
+        Imperative only.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            def sample_inject_fault():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.InjectFaultRequest(
+                    fault_type="STOP_VM",
+                    name="name_value",
+                )
+
+                # Make the request
+                operation = client.inject_fault(request=request)
+
+                print("Waiting for operation to complete...")
+
+                response = operation.result()
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1beta.types.InjectFaultRequest, dict]):
+                The request object. Message for triggering fault
+                injection on an instance
+            fault_type (google.cloud.alloydb_v1beta.types.InjectFaultRequest.FaultType):
+                Required. The type of fault to be
+                injected in an instance.
+
+                This corresponds to the ``fault_type`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the Instance.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.api_core.operation.Operation:
+                An object representing a long-running operation.
+
+                The result type for the operation will be :class:`google.cloud.alloydb_v1beta.types.Instance` An Instance is a computing unit that an end customer can connect to.
+                   It's the main unit of computing resources in AlloyDB.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([fault_type, name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.InjectFaultRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.InjectFaultRequest):
+            request = service.InjectFaultRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if fault_type is not None:
+                request.fault_type = fault_type
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.inject_fault]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Wrap the response in an operation future.
+        response = operation.from_gapic(
+            response,
+            self._transport.operations_client,
+            resources.Instance,
+            metadata_type=service.OperationMetadata,
+        )
+
+        # Done; return the response.
+        return response
+
     def restart_instance(
         self,
         request: Optional[Union[service.RestartInstanceRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -3653,14 +3805,546 @@
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
+    def list_users(
+        self,
+        request: Optional[Union[service.ListUsersRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> pagers.ListUsersPager:
+        r"""Lists Users in a given project and location.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            def sample_list_users():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.ListUsersRequest(
+                    parent="parent_value",
+                )
+
+                # Make the request
+                page_result = client.list_users(request=request)
+
+                # Handle the response
+                for response in page_result:
+                    print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1beta.types.ListUsersRequest, dict]):
+                The request object. Message for requesting list of Users
+            parent (str):
+                Required. Parent value for
+                ListUsersRequest
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1beta.services.alloy_db_admin.pagers.ListUsersPager:
+                Message for response to listing Users
+                Iterating over this object will yield
+                results and resolve additional pages
+                automatically.
+
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.ListUsersRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.ListUsersRequest):
+            request = service.ListUsersRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.list_users]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # This method is paged; wrap the response in a pager, which provides
+        # an `__iter__` convenience method.
+        response = pagers.ListUsersPager(
+            method=rpc,
+            request=request,
+            response=response,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def get_user(
+        self,
+        request: Optional[Union[service.GetUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Gets details of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            def sample_get_user():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.GetUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                response = client.get_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1beta.types.GetUserRequest, dict]):
+                The request object. Message for getting a User
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1beta.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.GetUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.GetUserRequest):
+            request = service.GetUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.get_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def create_user(
+        self,
+        request: Optional[Union[service.CreateUserRequest, dict]] = None,
+        *,
+        parent: Optional[str] = None,
+        user: Optional[resources.User] = None,
+        user_id: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Creates a new User in a given project, location, and
+        cluster.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            def sample_create_user():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.CreateUserRequest(
+                    parent="parent_value",
+                    user_id="user_id_value",
+                )
+
+                # Make the request
+                response = client.create_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1beta.types.CreateUserRequest, dict]):
+                The request object. Message for creating a User
+            parent (str):
+                Required. Value for parent.
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user (google.cloud.alloydb_v1beta.types.User):
+                Required. The resource being created
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            user_id (str):
+                Required. ID of the requesting
+                object.
+
+                This corresponds to the ``user_id`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1beta.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, user, user_id])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.CreateUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.CreateUserRequest):
+            request = service.CreateUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+            if user is not None:
+                request.user = user
+            if user_id is not None:
+                request.user_id = user_id
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.create_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def update_user(
+        self,
+        request: Optional[Union[service.UpdateUserRequest, dict]] = None,
+        *,
+        user: Optional[resources.User] = None,
+        update_mask: Optional[field_mask_pb2.FieldMask] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> resources.User:
+        r"""Updates the parameters of a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            def sample_update_user():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.UpdateUserRequest(
+                )
+
+                # Make the request
+                response = client.update_user(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1beta.types.UpdateUserRequest, dict]):
+                The request object. Message for updating a User
+            user (google.cloud.alloydb_v1beta.types.User):
+                Required. The resource being updated
+                This corresponds to the ``user`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            update_mask (google.protobuf.field_mask_pb2.FieldMask):
+                Optional. Field mask is used to specify the fields to be
+                overwritten in the User resource by the update. The
+                fields specified in the update_mask are relative to the
+                resource, not the full request. A field will be
+                overwritten if it is in the mask. If the user does not
+                provide a mask then all fields will be overwritten.
+
+                This corresponds to the ``update_mask`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.alloydb_v1beta.types.User:
+                Message describing User object.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([user, update_mask])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.UpdateUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.UpdateUserRequest):
+            request = service.UpdateUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if user is not None:
+                request.user = user
+            if update_mask is not None:
+                request.update_mask = update_mask
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.update_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata(
+                (("user.name", request.user.name),)
+            ),
+        )
+
+        # Send the request.
+        response = rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
+    def delete_user(
+        self,
+        request: Optional[Union[service.DeleteUserRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> None:
+        r"""Deletes a single User.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import alloydb_v1beta
+
+            def sample_delete_user():
+                # Create a client
+                client = alloydb_v1beta.AlloyDBAdminClient()
+
+                # Initialize request argument(s)
+                request = alloydb_v1beta.DeleteUserRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                client.delete_user(request=request)
+
+        Args:
+            request (Union[google.cloud.alloydb_v1beta.types.DeleteUserRequest, dict]):
+                The request object. Message for deleting a User
+            name (str):
+                Required. The name of the resource.
+                For the required format, see the comment
+                on the User.name field.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        # Create or coerce a protobuf request object.
+        # Quick check: If we got a request object, we should *not* have
+        # gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # Minor optimization to avoid making a copy if the user passes
+        # in a service.DeleteUserRequest.
+        # There's no risk of modifying the input as we've already verified
+        # there are no flattened fields.
+        if not isinstance(request, service.DeleteUserRequest):
+            request = service.DeleteUserRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._transport._wrapped_methods[self._transport.delete_user]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Send the request.
+        rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
     def __enter__(self) -> "AlloyDBAdminClient":
         return self
 
     def __exit__(self, type, value, traceback):
         """Releases underlying transport's resources.
 
         .. warning::
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/pagers.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/pagers.py`

 * *Files 11% similar despite different names*

```diff
@@ -533,7 +533,135 @@
                 for response in page.supported_database_flags:
                     yield response
 
         return async_generator()
 
     def __repr__(self) -> str:
         return "{0}<{1!r}>".format(self.__class__.__name__, self._response)
+
+
+class ListUsersPager:
+    """A pager for iterating through ``list_users`` requests.
+
+    This class thinly wraps an initial
+    :class:`google.cloud.alloydb_v1beta.types.ListUsersResponse` object, and
+    provides an ``__iter__`` method to iterate through its
+    ``users`` field.
+
+    If there are more pages, the ``__iter__`` method will make additional
+    ``ListUsers`` requests and continue to iterate
+    through the ``users`` field on the
+    corresponding responses.
+
+    All the usual :class:`google.cloud.alloydb_v1beta.types.ListUsersResponse`
+    attributes are available on the pager. If multiple requests are made, only
+    the most recent response is retained, and thus used for attribute lookup.
+    """
+
+    def __init__(
+        self,
+        method: Callable[..., service.ListUsersResponse],
+        request: service.ListUsersRequest,
+        response: service.ListUsersResponse,
+        *,
+        metadata: Sequence[Tuple[str, str]] = ()
+    ):
+        """Instantiate the pager.
+
+        Args:
+            method (Callable): The method that was originally called, and
+                which instantiated this pager.
+            request (google.cloud.alloydb_v1beta.types.ListUsersRequest):
+                The initial request object.
+            response (google.cloud.alloydb_v1beta.types.ListUsersResponse):
+                The initial response object.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        self._method = method
+        self._request = service.ListUsersRequest(request)
+        self._response = response
+        self._metadata = metadata
+
+    def __getattr__(self, name: str) -> Any:
+        return getattr(self._response, name)
+
+    @property
+    def pages(self) -> Iterator[service.ListUsersResponse]:
+        yield self._response
+        while self._response.next_page_token:
+            self._request.page_token = self._response.next_page_token
+            self._response = self._method(self._request, metadata=self._metadata)
+            yield self._response
+
+    def __iter__(self) -> Iterator[resources.User]:
+        for page in self.pages:
+            yield from page.users
+
+    def __repr__(self) -> str:
+        return "{0}<{1!r}>".format(self.__class__.__name__, self._response)
+
+
+class ListUsersAsyncPager:
+    """A pager for iterating through ``list_users`` requests.
+
+    This class thinly wraps an initial
+    :class:`google.cloud.alloydb_v1beta.types.ListUsersResponse` object, and
+    provides an ``__aiter__`` method to iterate through its
+    ``users`` field.
+
+    If there are more pages, the ``__aiter__`` method will make additional
+    ``ListUsers`` requests and continue to iterate
+    through the ``users`` field on the
+    corresponding responses.
+
+    All the usual :class:`google.cloud.alloydb_v1beta.types.ListUsersResponse`
+    attributes are available on the pager. If multiple requests are made, only
+    the most recent response is retained, and thus used for attribute lookup.
+    """
+
+    def __init__(
+        self,
+        method: Callable[..., Awaitable[service.ListUsersResponse]],
+        request: service.ListUsersRequest,
+        response: service.ListUsersResponse,
+        *,
+        metadata: Sequence[Tuple[str, str]] = ()
+    ):
+        """Instantiates the pager.
+
+        Args:
+            method (Callable): The method that was originally called, and
+                which instantiated this pager.
+            request (google.cloud.alloydb_v1beta.types.ListUsersRequest):
+                The initial request object.
+            response (google.cloud.alloydb_v1beta.types.ListUsersResponse):
+                The initial response object.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        self._method = method
+        self._request = service.ListUsersRequest(request)
+        self._response = response
+        self._metadata = metadata
+
+    def __getattr__(self, name: str) -> Any:
+        return getattr(self._response, name)
+
+    @property
+    async def pages(self) -> AsyncIterator[service.ListUsersResponse]:
+        yield self._response
+        while self._response.next_page_token:
+            self._request.page_token = self._response.next_page_token
+            self._response = await self._method(self._request, metadata=self._metadata)
+            yield self._response
+
+    def __aiter__(self) -> AsyncIterator[resources.User]:
+        async def async_generator():
+            async for page in self.pages:
+                for response in page.users:
+                    yield response
+
+        return async_generator()
+
+    def __repr__(self) -> str:
+        return "{0}<{1!r}>".format(self.__class__.__name__, self._response)
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/base.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/base.py`

 * *Files 3% similar despite different names*

```diff
@@ -23,14 +23,15 @@
 import google.auth  # type: ignore
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 from google.oauth2 import service_account  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 
 from google.cloud.alloydb_v1beta import gapic_version as package_version
 from google.cloud.alloydb_v1beta.types import resources, service
 
 DEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(
     gapic_version=package_version.__version__
 )
@@ -238,14 +239,19 @@
                 client_info=client_info,
             ),
             self.failover_instance: gapic_v1.method.wrap_method(
                 self.failover_instance,
                 default_timeout=None,
                 client_info=client_info,
             ),
+            self.inject_fault: gapic_v1.method.wrap_method(
+                self.inject_fault,
+                default_timeout=None,
+                client_info=client_info,
+            ),
             self.restart_instance: gapic_v1.method.wrap_method(
                 self.restart_instance,
                 default_timeout=None,
                 client_info=client_info,
             ),
             self.list_backups: gapic_v1.method.wrap_method(
                 self.list_backups,
@@ -328,14 +334,57 @@
                         core_exceptions.ServiceUnavailable,
                     ),
                     deadline=60.0,
                 ),
                 default_timeout=60.0,
                 client_info=client_info,
             ),
+            self.list_users: gapic_v1.method.wrap_method(
+                self.list_users,
+                default_retry=retries.Retry(
+                    initial=1.0,
+                    maximum=60.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.get_user: gapic_v1.method.wrap_method(
+                self.get_user,
+                default_retry=retries.Retry(
+                    initial=1.0,
+                    maximum=60.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.create_user: gapic_v1.method.wrap_method(
+                self.create_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.update_user: gapic_v1.method.wrap_method(
+                self.update_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.delete_user: gapic_v1.method.wrap_method(
+                self.delete_user,
+                default_timeout=None,
+                client_info=client_info,
+            ),
         }
 
     def close(self):
         """Closes resources associated with the transport.
 
         .. warning::
              Only call this method if the transport is NOT shared
@@ -489,14 +538,23 @@
     ) -> Callable[
         [service.FailoverInstanceRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
 
     @property
+    def inject_fault(
+        self,
+    ) -> Callable[
+        [service.InjectFaultRequest],
+        Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
+    ]:
+        raise NotImplementedError()
+
+    @property
     def restart_instance(
         self,
     ) -> Callable[
         [service.RestartInstanceRequest],
         Union[operations_pb2.Operation, Awaitable[operations_pb2.Operation]],
     ]:
         raise NotImplementedError()
@@ -575,14 +633,55 @@
     ) -> Callable[
         [service.GetConnectionInfoRequest],
         Union[resources.ConnectionInfo, Awaitable[resources.ConnectionInfo]],
     ]:
         raise NotImplementedError()
 
     @property
+    def list_users(
+        self,
+    ) -> Callable[
+        [service.ListUsersRequest],
+        Union[service.ListUsersResponse, Awaitable[service.ListUsersResponse]],
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def get_user(
+        self,
+    ) -> Callable[
+        [service.GetUserRequest], Union[resources.User, Awaitable[resources.User]]
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def create_user(
+        self,
+    ) -> Callable[
+        [service.CreateUserRequest], Union[resources.User, Awaitable[resources.User]]
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def update_user(
+        self,
+    ) -> Callable[
+        [service.UpdateUserRequest], Union[resources.User, Awaitable[resources.User]]
+    ]:
+        raise NotImplementedError()
+
+    @property
+    def delete_user(
+        self,
+    ) -> Callable[
+        [service.DeleteUserRequest], Union[empty_pb2.Empty, Awaitable[empty_pb2.Empty]]
+    ]:
+        raise NotImplementedError()
+
+    @property
     def list_operations(
         self,
     ) -> Callable[
         [operations_pb2.ListOperationsRequest],
         Union[
             operations_pb2.ListOperationsResponse,
             Awaitable[operations_pb2.ListOperationsResponse],
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/grpc.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/grpc_asyncio.py`

 * *Files 5% similar despite different names*

```diff
@@ -9,55 +9,101 @@
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from typing import Callable, Dict, Optional, Sequence, Tuple, Union
+from typing import Awaitable, Callable, Dict, Optional, Sequence, Tuple, Union
 import warnings
 
-from google.api_core import gapic_v1, grpc_helpers, operations_v1
-import google.auth  # type: ignore
+from google.api_core import gapic_v1, grpc_helpers_async, operations_v1
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 import grpc  # type: ignore
+from grpc.experimental import aio  # type: ignore
 
 from google.cloud.alloydb_v1beta.types import resources, service
 
 from .base import DEFAULT_CLIENT_INFO, AlloyDBAdminTransport
+from .grpc import AlloyDBAdminGrpcTransport
 
 
-class AlloyDBAdminGrpcTransport(AlloyDBAdminTransport):
-    """gRPC backend transport for AlloyDBAdmin.
+class AlloyDBAdminGrpcAsyncIOTransport(AlloyDBAdminTransport):
+    """gRPC AsyncIO backend transport for AlloyDBAdmin.
 
     Service describing handlers for resources
 
     This class defines the same methods as the primary client, so the
     primary client can load the underlying transport implementation
     and call it.
 
     It sends protocol buffers over the wire using gRPC (which is built on
     top of HTTP/2); the ``grpcio`` package must be installed.
     """
 
-    _stubs: Dict[str, Callable]
+    _grpc_channel: aio.Channel
+    _stubs: Dict[str, Callable] = {}
+
+    @classmethod
+    def create_channel(
+        cls,
+        host: str = "alloydb.googleapis.com",
+        credentials: Optional[ga_credentials.Credentials] = None,
+        credentials_file: Optional[str] = None,
+        scopes: Optional[Sequence[str]] = None,
+        quota_project_id: Optional[str] = None,
+        **kwargs,
+    ) -> aio.Channel:
+        """Create and return a gRPC AsyncIO channel object.
+        Args:
+            host (Optional[str]): The host for the channel to use.
+            credentials (Optional[~.Credentials]): The
+                authorization credentials to attach to requests. These
+                credentials identify this application to the service. If
+                none are specified, the client will attempt to ascertain
+                the credentials from the environment.
+            credentials_file (Optional[str]): A file with credentials that can
+                be loaded with :func:`google.auth.load_credentials_from_file`.
+                This argument is ignored if ``channel`` is provided.
+            scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
+                service. These are only used when credentials are not specified and
+                are passed to :func:`google.auth.default`.
+            quota_project_id (Optional[str]): An optional project to use for billing
+                and quota.
+            kwargs (Optional[dict]): Keyword arguments, which are passed to the
+                channel creation.
+        Returns:
+            aio.Channel: A gRPC AsyncIO channel object.
+        """
+
+        return grpc_helpers_async.create_channel(
+            host,
+            credentials=credentials,
+            credentials_file=credentials_file,
+            quota_project_id=quota_project_id,
+            default_scopes=cls.AUTH_SCOPES,
+            scopes=scopes,
+            default_host=cls.DEFAULT_HOST,
+            **kwargs,
+        )
 
     def __init__(
         self,
         *,
         host: str = "alloydb.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[grpc.Channel] = None,
+        channel: Optional[aio.Channel] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
@@ -73,17 +119,18 @@
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
                 This argument is ignored if ``channel`` is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
                 This argument is ignored if ``channel`` is provided.
-            scopes (Optional(Sequence[str])): A list of scopes. This argument is
-                ignored if ``channel`` is provided.
-            channel (Optional[grpc.Channel]): A ``Channel`` instance through
+            scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
+                service. These are only used when credentials are not specified and
+                are passed to :func:`google.auth.default`.
+            channel (Optional[aio.Channel]): A ``Channel`` instance through
                 which to make calls.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
@@ -102,36 +149,35 @@
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
             always_use_jwt_access (Optional[bool]): Whether self signed JWT should
                 be used for service account credentials.
 
         Raises:
-          google.auth.exceptions.MutualTLSChannelError: If mutual TLS transport
+            google.auth.exceptions.MutualTlsChannelError: If mutual TLS transport
               creation failed for any reason.
           google.api_core.exceptions.DuplicateCredentialArgs: If both ``credentials``
               and ``credentials_file`` are passed.
         """
         self._grpc_channel = None
         self._ssl_channel_credentials = ssl_channel_credentials
         self._stubs: Dict[str, Callable] = {}
-        self._operations_client: Optional[operations_v1.OperationsClient] = None
+        self._operations_client: Optional[operations_v1.OperationsAsyncClient] = None
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
         if channel:
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
-
         else:
             if api_mtls_endpoint:
                 host = api_mtls_endpoint
 
                 # Create SSL credentials with client_cert_source or application
                 # default SSL credentials.
                 if client_cert_source:
@@ -177,91 +223,53 @@
                     ("grpc.max_receive_message_length", -1),
                 ],
             )
 
         # Wrap messages. This must be done after self._grpc_channel exists
         self._prep_wrapped_messages(client_info)
 
-    @classmethod
-    def create_channel(
-        cls,
-        host: str = "alloydb.googleapis.com",
-        credentials: Optional[ga_credentials.Credentials] = None,
-        credentials_file: Optional[str] = None,
-        scopes: Optional[Sequence[str]] = None,
-        quota_project_id: Optional[str] = None,
-        **kwargs,
-    ) -> grpc.Channel:
-        """Create and return a gRPC channel object.
-        Args:
-            host (Optional[str]): The host for the channel to use.
-            credentials (Optional[~.Credentials]): The
-                authorization credentials to attach to requests. These
-                credentials identify this application to the service. If
-                none are specified, the client will attempt to ascertain
-                the credentials from the environment.
-            credentials_file (Optional[str]): A file with credentials that can
-                be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is mutually exclusive with credentials.
-            scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
-                service. These are only used when credentials are not specified and
-                are passed to :func:`google.auth.default`.
-            quota_project_id (Optional[str]): An optional project to use for billing
-                and quota.
-            kwargs (Optional[dict]): Keyword arguments, which are passed to the
-                channel creation.
-        Returns:
-            grpc.Channel: A gRPC channel object.
+    @property
+    def grpc_channel(self) -> aio.Channel:
+        """Create the channel designed to connect to this service.
 
-        Raises:
-            google.api_core.exceptions.DuplicateCredentialArgs: If both ``credentials``
-              and ``credentials_file`` are passed.
+        This property caches on the instance; repeated calls return
+        the same channel.
         """
-
-        return grpc_helpers.create_channel(
-            host,
-            credentials=credentials,
-            credentials_file=credentials_file,
-            quota_project_id=quota_project_id,
-            default_scopes=cls.AUTH_SCOPES,
-            scopes=scopes,
-            default_host=cls.DEFAULT_HOST,
-            **kwargs,
-        )
-
-    @property
-    def grpc_channel(self) -> grpc.Channel:
-        """Return the channel designed to connect to this service."""
+        # Return the channel from cache.
         return self._grpc_channel
 
     @property
-    def operations_client(self) -> operations_v1.OperationsClient:
+    def operations_client(self) -> operations_v1.OperationsAsyncClient:
         """Create the client designed to process long-running operations.
 
         This property caches on the instance; repeated calls return the same
         client.
         """
         # Quick check: Only create a new client if we do not already have one.
         if self._operations_client is None:
-            self._operations_client = operations_v1.OperationsClient(self.grpc_channel)
+            self._operations_client = operations_v1.OperationsAsyncClient(
+                self.grpc_channel
+            )
 
         # Return the client from cache.
         return self._operations_client
 
     @property
     def list_clusters(
         self,
-    ) -> Callable[[service.ListClustersRequest], service.ListClustersResponse]:
+    ) -> Callable[
+        [service.ListClustersRequest], Awaitable[service.ListClustersResponse]
+    ]:
         r"""Return a callable for the list clusters method over gRPC.
 
         Lists Clusters in a given project and location.
 
         Returns:
             Callable[[~.ListClustersRequest],
-                    ~.ListClustersResponse]:
+                    Awaitable[~.ListClustersResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -270,22 +278,24 @@
                 "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListClusters",
                 request_serializer=service.ListClustersRequest.serialize,
                 response_deserializer=service.ListClustersResponse.deserialize,
             )
         return self._stubs["list_clusters"]
 
     @property
-    def get_cluster(self) -> Callable[[service.GetClusterRequest], resources.Cluster]:
+    def get_cluster(
+        self,
+    ) -> Callable[[service.GetClusterRequest], Awaitable[resources.Cluster]]:
         r"""Return a callable for the get cluster method over gRPC.
 
         Gets details of a single Cluster.
 
         Returns:
             Callable[[~.GetClusterRequest],
-                    ~.Cluster]:
+                    Awaitable[~.Cluster]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -296,23 +306,23 @@
                 response_deserializer=resources.Cluster.deserialize,
             )
         return self._stubs["get_cluster"]
 
     @property
     def create_cluster(
         self,
-    ) -> Callable[[service.CreateClusterRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.CreateClusterRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the create cluster method over gRPC.
 
         Creates a new Cluster in a given project and
         location.
 
         Returns:
             Callable[[~.CreateClusterRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -323,22 +333,22 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_cluster"]
 
     @property
     def update_cluster(
         self,
-    ) -> Callable[[service.UpdateClusterRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.UpdateClusterRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the update cluster method over gRPC.
 
         Updates the parameters of a single Cluster.
 
         Returns:
             Callable[[~.UpdateClusterRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -349,22 +359,22 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_cluster"]
 
     @property
     def delete_cluster(
         self,
-    ) -> Callable[[service.DeleteClusterRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.DeleteClusterRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the delete cluster method over gRPC.
 
         Deletes a single Cluster.
 
         Returns:
             Callable[[~.DeleteClusterRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -375,25 +385,25 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_cluster"]
 
     @property
     def promote_cluster(
         self,
-    ) -> Callable[[service.PromoteClusterRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.PromoteClusterRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the promote cluster method over gRPC.
 
         Promotes a SECONDARY cluster. This turns down
         replication from the PRIMARY cluster and promotes a
         secondary cluster into its own standalone cluster.
         Imperative only.
 
         Returns:
             Callable[[~.PromoteClusterRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -404,25 +414,25 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["promote_cluster"]
 
     @property
     def restore_cluster(
         self,
-    ) -> Callable[[service.RestoreClusterRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.RestoreClusterRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the restore cluster method over gRPC.
 
         Creates a new Cluster in a given project and
         location, with a volume restored from the provided
         source, either a backup ID or a point-in-time and a
         source cluster.
 
         Returns:
             Callable[[~.RestoreClusterRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -433,23 +443,25 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["restore_cluster"]
 
     @property
     def create_secondary_cluster(
         self,
-    ) -> Callable[[service.CreateSecondaryClusterRequest], operations_pb2.Operation]:
+    ) -> Callable[
+        [service.CreateSecondaryClusterRequest], Awaitable[operations_pb2.Operation]
+    ]:
         r"""Return a callable for the create secondary cluster method over gRPC.
 
         Creates a cluster of type SECONDARY in the given
         location using the primary cluster as the source.
 
         Returns:
             Callable[[~.CreateSecondaryClusterRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -460,22 +472,24 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_secondary_cluster"]
 
     @property
     def list_instances(
         self,
-    ) -> Callable[[service.ListInstancesRequest], service.ListInstancesResponse]:
+    ) -> Callable[
+        [service.ListInstancesRequest], Awaitable[service.ListInstancesResponse]
+    ]:
         r"""Return a callable for the list instances method over gRPC.
 
         Lists Instances in a given project and location.
 
         Returns:
             Callable[[~.ListInstancesRequest],
-                    ~.ListInstancesResponse]:
+                    Awaitable[~.ListInstancesResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -486,22 +500,22 @@
                 response_deserializer=service.ListInstancesResponse.deserialize,
             )
         return self._stubs["list_instances"]
 
     @property
     def get_instance(
         self,
-    ) -> Callable[[service.GetInstanceRequest], resources.Instance]:
+    ) -> Callable[[service.GetInstanceRequest], Awaitable[resources.Instance]]:
         r"""Return a callable for the get instance method over gRPC.
 
         Gets details of a single Instance.
 
         Returns:
             Callable[[~.GetInstanceRequest],
-                    ~.Instance]:
+                    Awaitable[~.Instance]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -512,23 +526,23 @@
                 response_deserializer=resources.Instance.deserialize,
             )
         return self._stubs["get_instance"]
 
     @property
     def create_instance(
         self,
-    ) -> Callable[[service.CreateInstanceRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.CreateInstanceRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the create instance method over gRPC.
 
         Creates a new Instance in a given project and
         location.
 
         Returns:
             Callable[[~.CreateInstanceRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -539,23 +553,25 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_instance"]
 
     @property
     def create_secondary_instance(
         self,
-    ) -> Callable[[service.CreateSecondaryInstanceRequest], operations_pb2.Operation]:
+    ) -> Callable[
+        [service.CreateSecondaryInstanceRequest], Awaitable[operations_pb2.Operation]
+    ]:
         r"""Return a callable for the create secondary instance method over gRPC.
 
         Creates a new SECONDARY Instance in a given project
         and location.
 
         Returns:
             Callable[[~.CreateSecondaryInstanceRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -566,15 +582,17 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_secondary_instance"]
 
     @property
     def batch_create_instances(
         self,
-    ) -> Callable[[service.BatchCreateInstancesRequest], operations_pb2.Operation]:
+    ) -> Callable[
+        [service.BatchCreateInstancesRequest], Awaitable[operations_pb2.Operation]
+    ]:
         r"""Return a callable for the batch create instances method over gRPC.
 
         Creates new instances under the given project,
         location and cluster. There can be only one primary
         instance in a cluster. If the primary instance exists in
         the cluster as well as this request, then API will throw
         an error.
@@ -585,15 +603,15 @@
         here to support Google-internal use cases, and is not
         meant for external customers to consume. Please do not
         start relying on it; its behavior is subject to change
         without notice.
 
         Returns:
             Callable[[~.BatchCreateInstancesRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -604,22 +622,22 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["batch_create_instances"]
 
     @property
     def update_instance(
         self,
-    ) -> Callable[[service.UpdateInstanceRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.UpdateInstanceRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the update instance method over gRPC.
 
         Updates the parameters of a single Instance.
 
         Returns:
             Callable[[~.UpdateInstanceRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -630,22 +648,22 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_instance"]
 
     @property
     def delete_instance(
         self,
-    ) -> Callable[[service.DeleteInstanceRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.DeleteInstanceRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the delete instance method over gRPC.
 
         Deletes a single Instance.
 
         Returns:
             Callable[[~.DeleteInstanceRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -656,24 +674,26 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_instance"]
 
     @property
     def failover_instance(
         self,
-    ) -> Callable[[service.FailoverInstanceRequest], operations_pb2.Operation]:
+    ) -> Callable[
+        [service.FailoverInstanceRequest], Awaitable[operations_pb2.Operation]
+    ]:
         r"""Return a callable for the failover instance method over gRPC.
 
         Forces a Failover for a highly available instance.
         Failover promotes the HA standby instance as the new
         primary. Imperative only.
 
         Returns:
             Callable[[~.FailoverInstanceRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -682,25 +702,54 @@
                 "/google.cloud.alloydb.v1beta.AlloyDBAdmin/FailoverInstance",
                 request_serializer=service.FailoverInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["failover_instance"]
 
     @property
+    def inject_fault(
+        self,
+    ) -> Callable[[service.InjectFaultRequest], Awaitable[operations_pb2.Operation]]:
+        r"""Return a callable for the inject fault method over gRPC.
+
+        Injects fault in an instance.
+        Imperative only.
+
+        Returns:
+            Callable[[~.InjectFaultRequest],
+                    Awaitable[~.Operation]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "inject_fault" not in self._stubs:
+            self._stubs["inject_fault"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/InjectFault",
+                request_serializer=service.InjectFaultRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["inject_fault"]
+
+    @property
     def restart_instance(
         self,
-    ) -> Callable[[service.RestartInstanceRequest], operations_pb2.Operation]:
+    ) -> Callable[
+        [service.RestartInstanceRequest], Awaitable[operations_pb2.Operation]
+    ]:
         r"""Return a callable for the restart instance method over gRPC.
 
         Restart an Instance in a cluster.
         Imperative only.
 
         Returns:
             Callable[[~.RestartInstanceRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -711,22 +760,22 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["restart_instance"]
 
     @property
     def list_backups(
         self,
-    ) -> Callable[[service.ListBackupsRequest], service.ListBackupsResponse]:
+    ) -> Callable[[service.ListBackupsRequest], Awaitable[service.ListBackupsResponse]]:
         r"""Return a callable for the list backups method over gRPC.
 
         Lists Backups in a given project and location.
 
         Returns:
             Callable[[~.ListBackupsRequest],
-                    ~.ListBackupsResponse]:
+                    Awaitable[~.ListBackupsResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -735,22 +784,24 @@
                 "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListBackups",
                 request_serializer=service.ListBackupsRequest.serialize,
                 response_deserializer=service.ListBackupsResponse.deserialize,
             )
         return self._stubs["list_backups"]
 
     @property
-    def get_backup(self) -> Callable[[service.GetBackupRequest], resources.Backup]:
+    def get_backup(
+        self,
+    ) -> Callable[[service.GetBackupRequest], Awaitable[resources.Backup]]:
         r"""Return a callable for the get backup method over gRPC.
 
         Gets details of a single Backup.
 
         Returns:
             Callable[[~.GetBackupRequest],
-                    ~.Backup]:
+                    Awaitable[~.Backup]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -761,22 +812,22 @@
                 response_deserializer=resources.Backup.deserialize,
             )
         return self._stubs["get_backup"]
 
     @property
     def create_backup(
         self,
-    ) -> Callable[[service.CreateBackupRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.CreateBackupRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the create backup method over gRPC.
 
         Creates a new Backup in a given project and location.
 
         Returns:
             Callable[[~.CreateBackupRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -787,22 +838,22 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_backup"]
 
     @property
     def update_backup(
         self,
-    ) -> Callable[[service.UpdateBackupRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.UpdateBackupRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the update backup method over gRPC.
 
         Updates the parameters of a single Backup.
 
         Returns:
             Callable[[~.UpdateBackupRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -813,22 +864,22 @@
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_backup"]
 
     @property
     def delete_backup(
         self,
-    ) -> Callable[[service.DeleteBackupRequest], operations_pb2.Operation]:
+    ) -> Callable[[service.DeleteBackupRequest], Awaitable[operations_pb2.Operation]]:
         r"""Return a callable for the delete backup method over gRPC.
 
         Deletes a single Backup.
 
         Returns:
             Callable[[~.DeleteBackupRequest],
-                    ~.Operation]:
+                    Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -841,24 +892,24 @@
         return self._stubs["delete_backup"]
 
     @property
     def list_supported_database_flags(
         self,
     ) -> Callable[
         [service.ListSupportedDatabaseFlagsRequest],
-        service.ListSupportedDatabaseFlagsResponse,
+        Awaitable[service.ListSupportedDatabaseFlagsResponse],
     ]:
         r"""Return a callable for the list supported database flags method over gRPC.
 
         Lists SupportedDatabaseFlags for a given project and
         location.
 
         Returns:
             Callable[[~.ListSupportedDatabaseFlagsRequest],
-                    ~.ListSupportedDatabaseFlagsResponse]:
+                    Awaitable[~.ListSupportedDatabaseFlagsResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -873,28 +924,28 @@
         return self._stubs["list_supported_database_flags"]
 
     @property
     def generate_client_certificate(
         self,
     ) -> Callable[
         [service.GenerateClientCertificateRequest],
-        service.GenerateClientCertificateResponse,
+        Awaitable[service.GenerateClientCertificateResponse],
     ]:
         r"""Return a callable for the generate client certificate method over gRPC.
 
         Generate a client certificate signed by a Cluster CA.
         The sole purpose of this endpoint is to support the Auth
         Proxy client and the endpoint's behavior is subject to
         change without notice, so do not rely on its behavior
         remaining constant. Future changes will not break the
         Auth Proxy client.
 
         Returns:
             Callable[[~.GenerateClientCertificateRequest],
-                    ~.GenerateClientCertificateResponse]:
+                    Awaitable[~.GenerateClientCertificateResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -905,22 +956,24 @@
                 response_deserializer=service.GenerateClientCertificateResponse.deserialize,
             )
         return self._stubs["generate_client_certificate"]
 
     @property
     def get_connection_info(
         self,
-    ) -> Callable[[service.GetConnectionInfoRequest], resources.ConnectionInfo]:
+    ) -> Callable[
+        [service.GetConnectionInfoRequest], Awaitable[resources.ConnectionInfo]
+    ]:
         r"""Return a callable for the get connection info method over gRPC.
 
         Get instance metadata used for a connection.
 
         Returns:
             Callable[[~.GetConnectionInfoRequest],
-                    ~.ConnectionInfo]:
+                    Awaitable[~.ConnectionInfo]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
@@ -928,16 +981,145 @@
             self._stubs["get_connection_info"] = self.grpc_channel.unary_unary(
                 "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetConnectionInfo",
                 request_serializer=service.GetConnectionInfoRequest.serialize,
                 response_deserializer=resources.ConnectionInfo.deserialize,
             )
         return self._stubs["get_connection_info"]
 
+    @property
+    def list_users(
+        self,
+    ) -> Callable[[service.ListUsersRequest], Awaitable[service.ListUsersResponse]]:
+        r"""Return a callable for the list users method over gRPC.
+
+        Lists Users in a given project and location.
+
+        Returns:
+            Callable[[~.ListUsersRequest],
+                    Awaitable[~.ListUsersResponse]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "list_users" not in self._stubs:
+            self._stubs["list_users"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListUsers",
+                request_serializer=service.ListUsersRequest.serialize,
+                response_deserializer=service.ListUsersResponse.deserialize,
+            )
+        return self._stubs["list_users"]
+
+    @property
+    def get_user(self) -> Callable[[service.GetUserRequest], Awaitable[resources.User]]:
+        r"""Return a callable for the get user method over gRPC.
+
+        Gets details of a single User.
+
+        Returns:
+            Callable[[~.GetUserRequest],
+                    Awaitable[~.User]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "get_user" not in self._stubs:
+            self._stubs["get_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetUser",
+                request_serializer=service.GetUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["get_user"]
+
+    @property
+    def create_user(
+        self,
+    ) -> Callable[[service.CreateUserRequest], Awaitable[resources.User]]:
+        r"""Return a callable for the create user method over gRPC.
+
+        Creates a new User in a given project, location, and
+        cluster.
+
+        Returns:
+            Callable[[~.CreateUserRequest],
+                    Awaitable[~.User]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_user" not in self._stubs:
+            self._stubs["create_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateUser",
+                request_serializer=service.CreateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["create_user"]
+
+    @property
+    def update_user(
+        self,
+    ) -> Callable[[service.UpdateUserRequest], Awaitable[resources.User]]:
+        r"""Return a callable for the update user method over gRPC.
+
+        Updates the parameters of a single User.
+
+        Returns:
+            Callable[[~.UpdateUserRequest],
+                    Awaitable[~.User]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "update_user" not in self._stubs:
+            self._stubs["update_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/UpdateUser",
+                request_serializer=service.UpdateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["update_user"]
+
+    @property
+    def delete_user(
+        self,
+    ) -> Callable[[service.DeleteUserRequest], Awaitable[empty_pb2.Empty]]:
+        r"""Return a callable for the delete user method over gRPC.
+
+        Deletes a single User.
+
+        Returns:
+            Callable[[~.DeleteUserRequest],
+                    Awaitable[~.Empty]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "delete_user" not in self._stubs:
+            self._stubs["delete_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/DeleteUser",
+                request_serializer=service.DeleteUserRequest.serialize,
+                response_deserializer=empty_pb2.Empty.FromString,
+            )
+        return self._stubs["delete_user"]
+
     def close(self):
-        self.grpc_channel.close()
+        return self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
         r"""Return a callable for the delete_operation method over gRPC."""
         # Generate a "stub function" on-the-fly which will actually make
@@ -1037,13 +1219,9 @@
             self._stubs["get_location"] = self.grpc_channel.unary_unary(
                 "/google.cloud.location.Locations/GetLocation",
                 request_serializer=locations_pb2.GetLocationRequest.SerializeToString,
                 response_deserializer=locations_pb2.Location.FromString,
             )
         return self._stubs["get_location"]
 
-    @property
-    def kind(self) -> str:
-        return "grpc"
-
 
-__all__ = ("AlloyDBAdminGrpcTransport",)
+__all__ = ("AlloyDBAdminGrpcAsyncIOTransport",)
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/grpc_asyncio.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1/services/alloy_db_admin/transports/grpc_asyncio.py`

 * *Files 7% similar despite different names*

```diff
@@ -19,18 +19,19 @@
 from google.api_core import gapic_v1, grpc_helpers_async, operations_v1
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 import grpc  # type: ignore
 from grpc.experimental import aio  # type: ignore
 
-from google.cloud.alloydb_v1beta.types import resources, service
+from google.cloud.alloydb_v1.types import resources, service
 
 from .base import DEFAULT_CLIENT_INFO, AlloyDBAdminTransport
 from .grpc import AlloyDBAdminGrpcTransport
 
 
 class AlloyDBAdminGrpcAsyncIOTransport(AlloyDBAdminTransport):
     """gRPC AsyncIO backend transport for AlloyDBAdmin.
@@ -270,15 +271,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_clusters" not in self._stubs:
             self._stubs["list_clusters"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListClusters",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListClusters",
                 request_serializer=service.ListClustersRequest.serialize,
                 response_deserializer=service.ListClustersResponse.deserialize,
             )
         return self._stubs["list_clusters"]
 
     @property
     def get_cluster(
@@ -296,15 +297,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_cluster" not in self._stubs:
             self._stubs["get_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetCluster",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/GetCluster",
                 request_serializer=service.GetClusterRequest.serialize,
                 response_deserializer=resources.Cluster.deserialize,
             )
         return self._stubs["get_cluster"]
 
     @property
     def create_cluster(
@@ -323,15 +324,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_cluster" not in self._stubs:
             self._stubs["create_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateCluster",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateCluster",
                 request_serializer=service.CreateClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_cluster"]
 
     @property
     def update_cluster(
@@ -349,15 +350,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "update_cluster" not in self._stubs:
             self._stubs["update_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/UpdateCluster",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/UpdateCluster",
                 request_serializer=service.UpdateClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_cluster"]
 
     @property
     def delete_cluster(
@@ -375,15 +376,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "delete_cluster" not in self._stubs:
             self._stubs["delete_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/DeleteCluster",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/DeleteCluster",
                 request_serializer=service.DeleteClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_cluster"]
 
     @property
     def promote_cluster(
@@ -404,15 +405,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "promote_cluster" not in self._stubs:
             self._stubs["promote_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/PromoteCluster",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/PromoteCluster",
                 request_serializer=service.PromoteClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["promote_cluster"]
 
     @property
     def restore_cluster(
@@ -433,15 +434,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "restore_cluster" not in self._stubs:
             self._stubs["restore_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/RestoreCluster",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/RestoreCluster",
                 request_serializer=service.RestoreClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["restore_cluster"]
 
     @property
     def create_secondary_cluster(
@@ -462,15 +463,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_secondary_cluster" not in self._stubs:
             self._stubs["create_secondary_cluster"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateSecondaryCluster",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateSecondaryCluster",
                 request_serializer=service.CreateSecondaryClusterRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_secondary_cluster"]
 
     @property
     def list_instances(
@@ -490,15 +491,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_instances" not in self._stubs:
             self._stubs["list_instances"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListInstances",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListInstances",
                 request_serializer=service.ListInstancesRequest.serialize,
                 response_deserializer=service.ListInstancesResponse.deserialize,
             )
         return self._stubs["list_instances"]
 
     @property
     def get_instance(
@@ -516,15 +517,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_instance" not in self._stubs:
             self._stubs["get_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetInstance",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/GetInstance",
                 request_serializer=service.GetInstanceRequest.serialize,
                 response_deserializer=resources.Instance.deserialize,
             )
         return self._stubs["get_instance"]
 
     @property
     def create_instance(
@@ -543,15 +544,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_instance" not in self._stubs:
             self._stubs["create_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateInstance",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateInstance",
                 request_serializer=service.CreateInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_instance"]
 
     @property
     def create_secondary_instance(
@@ -572,15 +573,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_secondary_instance" not in self._stubs:
             self._stubs["create_secondary_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateSecondaryInstance",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateSecondaryInstance",
                 request_serializer=service.CreateSecondaryInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_secondary_instance"]
 
     @property
     def batch_create_instances(
@@ -612,15 +613,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "batch_create_instances" not in self._stubs:
             self._stubs["batch_create_instances"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/BatchCreateInstances",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/BatchCreateInstances",
                 request_serializer=service.BatchCreateInstancesRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["batch_create_instances"]
 
     @property
     def update_instance(
@@ -638,15 +639,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "update_instance" not in self._stubs:
             self._stubs["update_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/UpdateInstance",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/UpdateInstance",
                 request_serializer=service.UpdateInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_instance"]
 
     @property
     def delete_instance(
@@ -664,15 +665,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "delete_instance" not in self._stubs:
             self._stubs["delete_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/DeleteInstance",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/DeleteInstance",
                 request_serializer=service.DeleteInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_instance"]
 
     @property
     def failover_instance(
@@ -694,21 +695,48 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "failover_instance" not in self._stubs:
             self._stubs["failover_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/FailoverInstance",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/FailoverInstance",
                 request_serializer=service.FailoverInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["failover_instance"]
 
     @property
+    def inject_fault(
+        self,
+    ) -> Callable[[service.InjectFaultRequest], Awaitable[operations_pb2.Operation]]:
+        r"""Return a callable for the inject fault method over gRPC.
+
+        Injects fault in an instance.
+        Imperative only.
+
+        Returns:
+            Callable[[~.InjectFaultRequest],
+                    Awaitable[~.Operation]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "inject_fault" not in self._stubs:
+            self._stubs["inject_fault"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/InjectFault",
+                request_serializer=service.InjectFaultRequest.serialize,
+                response_deserializer=operations_pb2.Operation.FromString,
+            )
+        return self._stubs["inject_fault"]
+
+    @property
     def restart_instance(
         self,
     ) -> Callable[
         [service.RestartInstanceRequest], Awaitable[operations_pb2.Operation]
     ]:
         r"""Return a callable for the restart instance method over gRPC.
 
@@ -723,15 +751,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "restart_instance" not in self._stubs:
             self._stubs["restart_instance"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/RestartInstance",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/RestartInstance",
                 request_serializer=service.RestartInstanceRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["restart_instance"]
 
     @property
     def list_backups(
@@ -749,15 +777,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_backups" not in self._stubs:
             self._stubs["list_backups"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListBackups",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListBackups",
                 request_serializer=service.ListBackupsRequest.serialize,
                 response_deserializer=service.ListBackupsResponse.deserialize,
             )
         return self._stubs["list_backups"]
 
     @property
     def get_backup(
@@ -775,15 +803,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "get_backup" not in self._stubs:
             self._stubs["get_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetBackup",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/GetBackup",
                 request_serializer=service.GetBackupRequest.serialize,
                 response_deserializer=resources.Backup.deserialize,
             )
         return self._stubs["get_backup"]
 
     @property
     def create_backup(
@@ -801,15 +829,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "create_backup" not in self._stubs:
             self._stubs["create_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/CreateBackup",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateBackup",
                 request_serializer=service.CreateBackupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["create_backup"]
 
     @property
     def update_backup(
@@ -827,15 +855,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "update_backup" not in self._stubs:
             self._stubs["update_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/UpdateBackup",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/UpdateBackup",
                 request_serializer=service.UpdateBackupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["update_backup"]
 
     @property
     def delete_backup(
@@ -853,15 +881,15 @@
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "delete_backup" not in self._stubs:
             self._stubs["delete_backup"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/DeleteBackup",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/DeleteBackup",
                 request_serializer=service.DeleteBackupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
         return self._stubs["delete_backup"]
 
     @property
     def list_supported_database_flags(
@@ -885,81 +913,148 @@
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
         if "list_supported_database_flags" not in self._stubs:
             self._stubs[
                 "list_supported_database_flags"
             ] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/ListSupportedDatabaseFlags",
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListSupportedDatabaseFlags",
                 request_serializer=service.ListSupportedDatabaseFlagsRequest.serialize,
                 response_deserializer=service.ListSupportedDatabaseFlagsResponse.deserialize,
             )
         return self._stubs["list_supported_database_flags"]
 
     @property
-    def generate_client_certificate(
+    def list_users(
         self,
-    ) -> Callable[
-        [service.GenerateClientCertificateRequest],
-        Awaitable[service.GenerateClientCertificateResponse],
-    ]:
-        r"""Return a callable for the generate client certificate method over gRPC.
+    ) -> Callable[[service.ListUsersRequest], Awaitable[service.ListUsersResponse]]:
+        r"""Return a callable for the list users method over gRPC.
+
+        Lists Users in a given project and location.
+
+        Returns:
+            Callable[[~.ListUsersRequest],
+                    Awaitable[~.ListUsersResponse]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "list_users" not in self._stubs:
+            self._stubs["list_users"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/ListUsers",
+                request_serializer=service.ListUsersRequest.serialize,
+                response_deserializer=service.ListUsersResponse.deserialize,
+            )
+        return self._stubs["list_users"]
+
+    @property
+    def get_user(self) -> Callable[[service.GetUserRequest], Awaitable[resources.User]]:
+        r"""Return a callable for the get user method over gRPC.
 
-        Generate a client certificate signed by a Cluster CA.
-        The sole purpose of this endpoint is to support the Auth
-        Proxy client and the endpoint's behavior is subject to
-        change without notice, so do not rely on its behavior
-        remaining constant. Future changes will not break the
-        Auth Proxy client.
+        Gets details of a single User.
 
         Returns:
-            Callable[[~.GenerateClientCertificateRequest],
-                    Awaitable[~.GenerateClientCertificateResponse]]:
+            Callable[[~.GetUserRequest],
+                    Awaitable[~.User]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "generate_client_certificate" not in self._stubs:
-            self._stubs["generate_client_certificate"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GenerateClientCertificate",
-                request_serializer=service.GenerateClientCertificateRequest.serialize,
-                response_deserializer=service.GenerateClientCertificateResponse.deserialize,
+        if "get_user" not in self._stubs:
+            self._stubs["get_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/GetUser",
+                request_serializer=service.GetUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
             )
-        return self._stubs["generate_client_certificate"]
+        return self._stubs["get_user"]
 
     @property
-    def get_connection_info(
+    def create_user(
         self,
-    ) -> Callable[
-        [service.GetConnectionInfoRequest], Awaitable[resources.ConnectionInfo]
-    ]:
-        r"""Return a callable for the get connection info method over gRPC.
+    ) -> Callable[[service.CreateUserRequest], Awaitable[resources.User]]:
+        r"""Return a callable for the create user method over gRPC.
+
+        Creates a new User in a given project, location, and
+        cluster.
+
+        Returns:
+            Callable[[~.CreateUserRequest],
+                    Awaitable[~.User]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "create_user" not in self._stubs:
+            self._stubs["create_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/CreateUser",
+                request_serializer=service.CreateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["create_user"]
+
+    @property
+    def update_user(
+        self,
+    ) -> Callable[[service.UpdateUserRequest], Awaitable[resources.User]]:
+        r"""Return a callable for the update user method over gRPC.
+
+        Updates the parameters of a single User.
+
+        Returns:
+            Callable[[~.UpdateUserRequest],
+                    Awaitable[~.User]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "update_user" not in self._stubs:
+            self._stubs["update_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/UpdateUser",
+                request_serializer=service.UpdateUserRequest.serialize,
+                response_deserializer=resources.User.deserialize,
+            )
+        return self._stubs["update_user"]
+
+    @property
+    def delete_user(
+        self,
+    ) -> Callable[[service.DeleteUserRequest], Awaitable[empty_pb2.Empty]]:
+        r"""Return a callable for the delete user method over gRPC.
 
-        Get instance metadata used for a connection.
+        Deletes a single User.
 
         Returns:
-            Callable[[~.GetConnectionInfoRequest],
-                    Awaitable[~.ConnectionInfo]]:
+            Callable[[~.DeleteUserRequest],
+                    Awaitable[~.Empty]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "get_connection_info" not in self._stubs:
-            self._stubs["get_connection_info"] = self.grpc_channel.unary_unary(
-                "/google.cloud.alloydb.v1beta.AlloyDBAdmin/GetConnectionInfo",
-                request_serializer=service.GetConnectionInfoRequest.serialize,
-                response_deserializer=resources.ConnectionInfo.deserialize,
+        if "delete_user" not in self._stubs:
+            self._stubs["delete_user"] = self.grpc_channel.unary_unary(
+                "/google.cloud.alloydb.v1.AlloyDBAdmin/DeleteUser",
+                request_serializer=service.DeleteUserRequest.serialize,
+                response_deserializer=empty_pb2.Empty.FromString,
             )
-        return self._stubs["get_connection_info"]
+        return self._stubs["delete_user"]
 
     def close(self):
         return self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/services/alloy_db_admin/transports/rest.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1alpha/services/alloy_db_admin/transports/rest.py`

 * *Files 3% similar despite different names*

```diff
@@ -43,16 +43,17 @@
 try:
     OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
 except AttributeError:  # pragma: NO COVER
     OptionalRetry = Union[retries.Retry, object]  # type: ignore
 
 
 from google.longrunning import operations_pb2  # type: ignore
+from google.protobuf import empty_pb2  # type: ignore
 
-from google.cloud.alloydb_v1beta.types import resources, service
+from google.cloud.alloydb_v1alpha.types import resources, service
 
 from .base import AlloyDBAdminTransport
 from .base import DEFAULT_CLIENT_INFO as BASE_DEFAULT_CLIENT_INFO
 
 DEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(
     gapic_version=BASE_DEFAULT_CLIENT_INFO.gapic_version,
     grpc_version=None,
@@ -119,14 +120,22 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_create_secondary_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_create_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_create_user(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_delete_backup(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_delete_backup(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -143,14 +152,18 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_delete_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_delete_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
             def pre_failover_instance(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_failover_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -191,14 +204,30 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_get_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_get_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_get_user(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
+            def pre_inject_fault(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_inject_fault(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_list_backups(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_list_backups(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -223,14 +252,22 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_list_supported_database_flags(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_list_users(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_list_users(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
             def pre_promote_cluster(self, request, metadata):
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_promote_cluster(self, response):
                 logging.log(f"Received response: {response}")
                 return response
@@ -271,14 +308,22 @@
                 logging.log(f"Received request: {request}")
                 return request, metadata
 
             def post_update_instance(self, response):
                 logging.log(f"Received response: {response}")
                 return response
 
+            def pre_update_user(self, request, metadata):
+                logging.log(f"Received request: {request}")
+                return request, metadata
+
+            def post_update_user(self, response):
+                logging.log(f"Received response: {response}")
+                return response
+
         transport = AlloyDBAdminRestTransport(interceptor=MyCustomAlloyDBAdminInterceptor())
         client = AlloyDBAdminClient(transport=transport)
 
 
     """
 
     def pre_batch_create_instances(
@@ -411,14 +456,33 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_create_user(
+        self, request: service.CreateUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.CreateUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for create_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_create_user(self, response: resources.User) -> resources.User:
+        """Post-rpc interceptor for create_user
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_delete_backup(
         self, request: service.DeleteBackupRequest, metadata: Sequence[Tuple[str, str]]
     ) -> Tuple[service.DeleteBackupRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for delete_backup
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
@@ -476,14 +540,24 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_delete_user(
+        self, request: service.DeleteUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.DeleteUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for delete_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
     def pre_failover_instance(
         self,
         request: service.FailoverInstanceRequest,
         metadata: Sequence[Tuple[str, str]],
     ) -> Tuple[service.FailoverInstanceRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for failover_instance
 
@@ -602,14 +676,54 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_get_user(
+        self, request: service.GetUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.GetUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for get_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_get_user(self, response: resources.User) -> resources.User:
+        """Post-rpc interceptor for get_user
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
+    def pre_inject_fault(
+        self, request: service.InjectFaultRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.InjectFaultRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for inject_fault
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_inject_fault(
+        self, response: operations_pb2.Operation
+    ) -> operations_pb2.Operation:
+        """Post-rpc interceptor for inject_fault
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_list_backups(
         self, request: service.ListBackupsRequest, metadata: Sequence[Tuple[str, str]]
     ) -> Tuple[service.ListBackupsRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for list_backups
 
         Override in a subclass to manipulate the request or metadata
         before they are sent to the AlloyDBAdmin server.
@@ -688,14 +802,35 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_list_users(
+        self, request: service.ListUsersRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.ListUsersRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for list_users
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_list_users(
+        self, response: service.ListUsersResponse
+    ) -> service.ListUsersResponse:
+        """Post-rpc interceptor for list_users
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_promote_cluster(
         self,
         request: service.PromoteClusterRequest,
         metadata: Sequence[Tuple[str, str]],
     ) -> Tuple[service.PromoteClusterRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for promote_cluster
 
@@ -822,14 +957,33 @@
 
         Override in a subclass to manipulate the response
         after it is returned by the AlloyDBAdmin server but before
         it is returned to user code.
         """
         return response
 
+    def pre_update_user(
+        self, request: service.UpdateUserRequest, metadata: Sequence[Tuple[str, str]]
+    ) -> Tuple[service.UpdateUserRequest, Sequence[Tuple[str, str]]]:
+        """Pre-rpc interceptor for update_user
+
+        Override in a subclass to manipulate the request or metadata
+        before they are sent to the AlloyDBAdmin server.
+        """
+        return request, metadata
+
+    def post_update_user(self, response: resources.User) -> resources.User:
+        """Post-rpc interceptor for update_user
+
+        Override in a subclass to manipulate the response
+        after it is returned by the AlloyDBAdmin server but before
+        it is returned to user code.
+        """
+        return response
+
     def pre_get_location(
         self,
         request: locations_pb2.GetLocationRequest,
         metadata: Sequence[Tuple[str, str]],
     ) -> Tuple[locations_pb2.GetLocationRequest, Sequence[Tuple[str, str]]]:
         """Pre-rpc interceptor for get_location
 
@@ -1067,44 +1221,45 @@
         """
         # Only create a new client if we do not already have one.
         if self._operations_client is None:
             http_options: Dict[str, List[Dict[str, str]]] = {
                 "google.longrunning.Operations.CancelOperation": [
                     {
                         "method": "post",
-                        "uri": "/v1beta/{name=projects/*/locations/*/operations/*}:cancel",
+                        "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}:cancel",
+                        "body": "*",
                     },
                 ],
                 "google.longrunning.Operations.DeleteOperation": [
                     {
                         "method": "delete",
-                        "uri": "/v1beta/{name=projects/*/locations/*/operations/*}",
+                        "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}",
                     },
                 ],
                 "google.longrunning.Operations.GetOperation": [
                     {
                         "method": "get",
-                        "uri": "/v1beta/{name=projects/*/locations/*/operations/*}",
+                        "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}",
                     },
                 ],
                 "google.longrunning.Operations.ListOperations": [
                     {
                         "method": "get",
-                        "uri": "/v1beta/{name=projects/*/locations/*}/operations",
+                        "uri": "/v1alpha/{name=projects/*/locations/*}/operations",
                     },
                 ],
             }
 
             rest_transport = operations_v1.OperationsRestTransport(
                 host=self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 scopes=self._scopes,
                 http_options=http_options,
-                path_prefix="v1beta",
+                path_prefix="v1alpha",
             )
 
             self._operations_client = operations_v1.AbstractOperationsClient(
                 transport=rest_transport
             )
 
         # Return the client from cache.
@@ -1151,15 +1306,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/instances:batchCreate",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/instances:batchCreate",
                     "body": "requests",
                 },
             ]
             request, metadata = self._interceptor.pre_batch_create_instances(
                 request, metadata
             )
             pb_request = service.BatchCreateInstancesRequest.pb(request)
@@ -1251,15 +1406,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{parent=projects/*/locations/*}/backups",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*}/backups",
                     "body": "backup",
                 },
             ]
             request, metadata = self._interceptor.pre_create_backup(request, metadata)
             pb_request = service.CreateBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -1349,15 +1504,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{parent=projects/*/locations/*}/clusters",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*}/clusters",
                     "body": "cluster",
                 },
             ]
             request, metadata = self._interceptor.pre_create_cluster(request, metadata)
             pb_request = service.CreateClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -1447,15 +1602,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/instances",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/instances",
                     "body": "instance",
                 },
             ]
             request, metadata = self._interceptor.pre_create_instance(request, metadata)
             pb_request = service.CreateInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -1545,15 +1700,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{parent=projects/*/locations/*}/clusters:createsecondary",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*}/clusters:createsecondary",
                     "body": "cluster",
                 },
             ]
             request, metadata = self._interceptor.pre_create_secondary_cluster(
                 request, metadata
             )
             pb_request = service.CreateSecondaryClusterRequest.pb(request)
@@ -1646,15 +1801,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/instances:createsecondary",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/instances:createsecondary",
                     "body": "instance",
                 },
             ]
             request, metadata = self._interceptor.pre_create_secondary_instance(
                 request, metadata
             )
             pb_request = service.CreateSecondaryInstanceRequest.pb(request)
@@ -1700,14 +1855,111 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_create_secondary_instance(resp)
             return resp
 
+    class _CreateUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("CreateUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {
+            "userId": "",
+        }
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.CreateUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> resources.User:
+            r"""Call the create user method over HTTP.
+
+            Args:
+                request (~.service.CreateUserRequest):
+                    The request object. Message for creating a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.resources.User:
+                    Message describing User object.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/users",
+                    "body": "user",
+                },
+            ]
+            request, metadata = self._interceptor.pre_create_user(request, metadata)
+            pb_request = service.CreateUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = resources.User()
+            pb_resp = resources.User.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_create_user(resp)
+            return resp
+
     class _DeleteBackup(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("DeleteBackup")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -1744,15 +1996,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1beta/{name=projects/*/locations/*/backups/*}",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/backups/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_delete_backup(request, metadata)
             pb_request = service.DeleteBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1831,15 +2083,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*}",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_delete_cluster(request, metadata)
             pb_request = service.DeleteClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1918,15 +2170,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_delete_instance(request, metadata)
             pb_request = service.DeleteInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -1961,14 +2213,88 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_delete_instance(resp)
             return resp
 
+    class _DeleteUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("DeleteUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.DeleteUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ):
+            r"""Call the delete user method over HTTP.
+
+            Args:
+                request (~.service.DeleteUserRequest):
+                    The request object. Message for deleting a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "delete",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/users/*}",
+                },
+            ]
+            request, metadata = self._interceptor.pre_delete_user(request, metadata)
+            pb_request = service.DeleteUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
     class _FailoverInstance(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("FailoverInstance")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -2006,15 +2332,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}:failover",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}:failover",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_failover_instance(
                 request, metadata
             )
             pb_request = service.FailoverInstanceRequest.pb(request)
@@ -2106,15 +2432,15 @@
                     GenerateClientCertificate operation.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}:generateClientCertificate",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}:generateClientCertificate",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_generate_client_certificate(
                 request, metadata
             )
             pb_request = service.GenerateClientCertificateRequest.pb(request)
@@ -2203,15 +2529,15 @@
                 ~.resources.Backup:
                     Message describing Backup object
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{name=projects/*/locations/*/backups/*}",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/backups/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_get_backup(request, metadata)
             pb_request = service.GetBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2295,15 +2621,15 @@
                 needed.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*}",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_get_cluster(request, metadata)
             pb_request = service.GetClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2384,15 +2710,15 @@
                 https://google.aip.dev/156
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*/instances/*}/connectionInfo",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*/instances/*}/connectionInfo",
                 },
             ]
             request, metadata = self._interceptor.pre_get_connection_info(
                 request, metadata
             )
             pb_request = service.GetConnectionInfoRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
@@ -2476,15 +2802,15 @@
                 AlloyDB.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}",
                 },
             ]
             request, metadata = self._interceptor.pre_get_instance(request, metadata)
             pb_request = service.GetInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2521,14 +2847,197 @@
             resp = resources.Instance()
             pb_resp = resources.Instance.pb(resp)
 
             json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_get_instance(resp)
             return resp
 
+    class _GetUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("GetUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.GetUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> resources.User:
+            r"""Call the get user method over HTTP.
+
+            Args:
+                request (~.service.GetUserRequest):
+                    The request object. Message for getting a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.resources.User:
+                    Message describing User object.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "get",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/users/*}",
+                },
+            ]
+            request, metadata = self._interceptor.pre_get_user(request, metadata)
+            pb_request = service.GetUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = resources.User()
+            pb_resp = resources.User.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_get_user(resp)
+            return resp
+
+    class _InjectFault(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("InjectFault")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.InjectFaultRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> operations_pb2.Operation:
+            r"""Call the inject fault method over HTTP.
+
+            Args:
+                request (~.service.InjectFaultRequest):
+                    The request object. Message for triggering fault
+                injection on an instance
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.operations_pb2.Operation:
+                    This resource represents a
+                long-running operation that is the
+                result of a network API call.
+
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "post",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}:injectFault",
+                    "body": "*",
+                },
+            ]
+            request, metadata = self._interceptor.pre_inject_fault(request, metadata)
+            pb_request = service.InjectFaultRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = operations_pb2.Operation()
+            json_format.Parse(response.content, resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_inject_fault(resp)
+            return resp
+
     class _ListBackups(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("ListBackups")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -2565,15 +3074,15 @@
                 Backups
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{parent=projects/*/locations/*}/backups",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*}/backups",
                 },
             ]
             request, metadata = self._interceptor.pre_list_backups(request, metadata)
             pb_request = service.ListBackupsRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2654,15 +3163,15 @@
                 Clusters
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{parent=projects/*/locations/*}/clusters",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*}/clusters",
                 },
             ]
             request, metadata = self._interceptor.pre_list_clusters(request, metadata)
             pb_request = service.ListClustersRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2743,15 +3252,15 @@
                 Instances
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{parent=projects/*/locations/*/clusters/*}/instances",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/instances",
                 },
             ]
             request, metadata = self._interceptor.pre_list_instances(request, metadata)
             pb_request = service.ListInstancesRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
             uri = transcoded_request["uri"]
@@ -2833,15 +3342,15 @@
                     SupportedDatabaseFlags.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{parent=projects/*/locations/*}/supportedDatabaseFlags",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*}/supportedDatabaseFlags",
                 },
             ]
             request, metadata = self._interceptor.pre_list_supported_database_flags(
                 request, metadata
             )
             pb_request = service.ListSupportedDatabaseFlagsRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
@@ -2880,14 +3389,100 @@
             resp = service.ListSupportedDatabaseFlagsResponse()
             pb_resp = service.ListSupportedDatabaseFlagsResponse.pb(resp)
 
             json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_list_supported_database_flags(resp)
             return resp
 
+    class _ListUsers(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("ListUsers")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.ListUsersRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> service.ListUsersResponse:
+            r"""Call the list users method over HTTP.
+
+            Args:
+                request (~.service.ListUsersRequest):
+                    The request object. Message for requesting list of Users
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.service.ListUsersResponse:
+                    Message for response to listing Users
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "get",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*/clusters/*}/users",
+                },
+            ]
+            request, metadata = self._interceptor.pre_list_users(request, metadata)
+            pb_request = service.ListUsersRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = service.ListUsersResponse()
+            pb_resp = service.ListUsersResponse.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_list_users(resp)
+            return resp
+
     class _PromoteCluster(AlloyDBAdminRestStub):
         def __hash__(self):
             return hash("PromoteCluster")
 
         __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
 
         @classmethod
@@ -2924,15 +3519,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*}:promote",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*}:promote",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_promote_cluster(request, metadata)
             pb_request = service.PromoteClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3020,15 +3615,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}:restart",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}:restart",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_restart_instance(
                 request, metadata
             )
             pb_request = service.RestartInstanceRequest.pb(request)
@@ -3120,15 +3715,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{parent=projects/*/locations/*}/clusters:restore",
+                    "uri": "/v1alpha/{parent=projects/*/locations/*}/clusters:restore",
                     "body": "*",
                 },
             ]
             request, metadata = self._interceptor.pre_restore_cluster(request, metadata)
             pb_request = service.RestoreClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3216,15 +3811,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "patch",
-                    "uri": "/v1beta/{backup.name=projects/*/locations/*/backups/*}",
+                    "uri": "/v1alpha/{backup.name=projects/*/locations/*/backups/*}",
                     "body": "backup",
                 },
             ]
             request, metadata = self._interceptor.pre_update_backup(request, metadata)
             pb_request = service.UpdateBackupRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3312,15 +3907,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "patch",
-                    "uri": "/v1beta/{cluster.name=projects/*/locations/*/clusters/*}",
+                    "uri": "/v1alpha/{cluster.name=projects/*/locations/*/clusters/*}",
                     "body": "cluster",
                 },
             ]
             request, metadata = self._interceptor.pre_update_cluster(request, metadata)
             pb_request = service.UpdateClusterRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3408,15 +4003,15 @@
                 result of a network API call.
 
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "patch",
-                    "uri": "/v1beta/{instance.name=projects/*/locations/*/clusters/*/instances/*}",
+                    "uri": "/v1alpha/{instance.name=projects/*/locations/*/clusters/*/instances/*}",
                     "body": "instance",
                 },
             ]
             request, metadata = self._interceptor.pre_update_instance(request, metadata)
             pb_request = service.UpdateInstanceRequest.pb(request)
             transcoded_request = path_template.transcode(http_options, pb_request)
 
@@ -3460,14 +4055,109 @@
 
             # Return the response
             resp = operations_pb2.Operation()
             json_format.Parse(response.content, resp, ignore_unknown_fields=True)
             resp = self._interceptor.post_update_instance(resp)
             return resp
 
+    class _UpdateUser(AlloyDBAdminRestStub):
+        def __hash__(self):
+            return hash("UpdateUser")
+
+        __REQUIRED_FIELDS_DEFAULT_VALUES: Dict[str, Any] = {}
+
+        @classmethod
+        def _get_unset_required_fields(cls, message_dict):
+            return {
+                k: v
+                for k, v in cls.__REQUIRED_FIELDS_DEFAULT_VALUES.items()
+                if k not in message_dict
+            }
+
+        def __call__(
+            self,
+            request: service.UpdateUserRequest,
+            *,
+            retry: OptionalRetry = gapic_v1.method.DEFAULT,
+            timeout: Optional[float] = None,
+            metadata: Sequence[Tuple[str, str]] = (),
+        ) -> resources.User:
+            r"""Call the update user method over HTTP.
+
+            Args:
+                request (~.service.UpdateUserRequest):
+                    The request object. Message for updating a User
+                retry (google.api_core.retry.Retry): Designation of what errors, if any,
+                    should be retried.
+                timeout (float): The timeout for this request.
+                metadata (Sequence[Tuple[str, str]]): Strings which should be
+                    sent along with the request as metadata.
+
+            Returns:
+                ~.resources.User:
+                    Message describing User object.
+            """
+
+            http_options: List[Dict[str, str]] = [
+                {
+                    "method": "patch",
+                    "uri": "/v1alpha/{user.name=projects/*/locations/*/clusters/*/users/*}",
+                    "body": "user",
+                },
+            ]
+            request, metadata = self._interceptor.pre_update_user(request, metadata)
+            pb_request = service.UpdateUserRequest.pb(request)
+            transcoded_request = path_template.transcode(http_options, pb_request)
+
+            # Jsonify the request body
+
+            body = json_format.MessageToJson(
+                transcoded_request["body"],
+                including_default_value_fields=False,
+                use_integers_for_enums=True,
+            )
+            uri = transcoded_request["uri"]
+            method = transcoded_request["method"]
+
+            # Jsonify the query params
+            query_params = json.loads(
+                json_format.MessageToJson(
+                    transcoded_request["query_params"],
+                    including_default_value_fields=False,
+                    use_integers_for_enums=True,
+                )
+            )
+            query_params.update(self._get_unset_required_fields(query_params))
+
+            query_params["$alt"] = "json;enum-encoding=int"
+
+            # Send the request
+            headers = dict(metadata)
+            headers["Content-Type"] = "application/json"
+            response = getattr(self._session, method)(
+                "{host}{uri}".format(host=self._host, uri=uri),
+                timeout=timeout,
+                headers=headers,
+                params=rest_helpers.flatten_query_params(query_params, strict=True),
+                data=body,
+            )
+
+            # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
+            # subclass.
+            if response.status_code >= 400:
+                raise core_exceptions.from_http_response(response)
+
+            # Return the response
+            resp = resources.User()
+            pb_resp = resources.User.pb(resp)
+
+            json_format.Parse(response.content, pb_resp, ignore_unknown_fields=True)
+            resp = self._interceptor.post_update_user(resp)
+            return resp
+
     @property
     def batch_create_instances(
         self,
     ) -> Callable[[service.BatchCreateInstancesRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._BatchCreateInstances(self._session, self._host, self._interceptor)  # type: ignore
@@ -3509,14 +4199,20 @@
         self,
     ) -> Callable[[service.CreateSecondaryInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._CreateSecondaryInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def create_user(self) -> Callable[[service.CreateUserRequest], resources.User]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._CreateUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def delete_backup(
         self,
     ) -> Callable[[service.DeleteBackupRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._DeleteBackup(self._session, self._host, self._interceptor)  # type: ignore
 
@@ -3533,14 +4229,20 @@
         self,
     ) -> Callable[[service.DeleteInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._DeleteInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def delete_user(self) -> Callable[[service.DeleteUserRequest], empty_pb2.Empty]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._DeleteUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def failover_instance(
         self,
     ) -> Callable[[service.FailoverInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._FailoverInstance(self._session, self._host, self._interceptor)  # type: ignore
 
@@ -3580,14 +4282,28 @@
         self,
     ) -> Callable[[service.GetInstanceRequest], resources.Instance]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._GetInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def get_user(self) -> Callable[[service.GetUserRequest], resources.User]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._GetUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
+    def inject_fault(
+        self,
+    ) -> Callable[[service.InjectFaultRequest], operations_pb2.Operation]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._InjectFault(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def list_backups(
         self,
     ) -> Callable[[service.ListBackupsRequest], service.ListBackupsResponse]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._ListBackups(self._session, self._host, self._interceptor)  # type: ignore
 
@@ -3615,14 +4331,22 @@
         service.ListSupportedDatabaseFlagsResponse,
     ]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._ListSupportedDatabaseFlags(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def list_users(
+        self,
+    ) -> Callable[[service.ListUsersRequest], service.ListUsersResponse]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._ListUsers(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def promote_cluster(
         self,
     ) -> Callable[[service.PromoteClusterRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._PromoteCluster(self._session, self._host, self._interceptor)  # type: ignore
 
@@ -3663,14 +4387,20 @@
         self,
     ) -> Callable[[service.UpdateInstanceRequest], operations_pb2.Operation]:
         # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
         # In C++ this would require a dynamic_cast
         return self._UpdateInstance(self._session, self._host, self._interceptor)  # type: ignore
 
     @property
+    def update_user(self) -> Callable[[service.UpdateUserRequest], resources.User]:
+        # The return type is fine, but mypy isn't sophisticated enough to determine what's going on here.
+        # In C++ this would require a dynamic_cast
+        return self._UpdateUser(self._session, self._host, self._interceptor)  # type: ignore
+
+    @property
     def get_location(self):
         return self._GetLocation(self._session, self._host, self._interceptor)  # type: ignore
 
     class _GetLocation(AlloyDBAdminRestStub):
         def __call__(
             self,
             request: locations_pb2.GetLocationRequest,
@@ -3694,15 +4424,15 @@
             Returns:
                 locations_pb2.Location: Response from GetLocation method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{name=projects/*/locations/*}",
+                    "uri": "/v1alpha/{name=projects/*/locations/*}",
                 },
             ]
 
             request, metadata = self._interceptor.pre_get_location(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
@@ -3761,15 +4491,15 @@
             Returns:
                 locations_pb2.ListLocationsResponse: Response from ListLocations method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{name=projects/*}/locations",
+                    "uri": "/v1alpha/{name=projects/*}/locations",
                 },
             ]
 
             request, metadata = self._interceptor.pre_list_locations(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
@@ -3825,24 +4555,26 @@
                 metadata (Sequence[Tuple[str, str]]): Strings which should be
                     sent along with the request as metadata.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "post",
-                    "uri": "/v1beta/{name=projects/*/locations/*/operations/*}:cancel",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}:cancel",
+                    "body": "*",
                 },
             ]
 
             request, metadata = self._interceptor.pre_cancel_operation(
                 request, metadata
             )
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
+            body = json.loads(json.dumps(transcoded_request["body"]))
             uri = transcoded_request["uri"]
             method = transcoded_request["method"]
 
             # Jsonify the query params
             query_params = json.loads(json.dumps(transcoded_request["query_params"]))
 
             # Send the request
@@ -3850,14 +4582,15 @@
             headers["Content-Type"] = "application/json"
 
             response = getattr(self._session, method)(
                 "{host}{uri}".format(host=self._host, uri=uri),
                 timeout=timeout,
                 headers=headers,
                 params=rest_helpers.flatten_query_params(query_params),
+                data=body,
             )
 
             # In case of error, raise the appropriate core_exceptions.GoogleAPICallError exception
             # subclass.
             if response.status_code >= 400:
                 raise core_exceptions.from_http_response(response)
 
@@ -3888,15 +4621,15 @@
                 metadata (Sequence[Tuple[str, str]]): Strings which should be
                     sent along with the request as metadata.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "delete",
-                    "uri": "/v1beta/{name=projects/*/locations/*/operations/*}",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}",
                 },
             ]
 
             request, metadata = self._interceptor.pre_delete_operation(
                 request, metadata
             )
             request_kwargs = json_format.MessageToDict(request)
@@ -3954,15 +4687,15 @@
             Returns:
                 operations_pb2.Operation: Response from GetOperation method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{name=projects/*/locations/*/operations/*}",
+                    "uri": "/v1alpha/{name=projects/*/locations/*/operations/*}",
                 },
             ]
 
             request, metadata = self._interceptor.pre_get_operation(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
 
@@ -4021,15 +4754,15 @@
             Returns:
                 operations_pb2.ListOperationsResponse: Response from ListOperations method.
             """
 
             http_options: List[Dict[str, str]] = [
                 {
                     "method": "get",
-                    "uri": "/v1beta/{name=projects/*/locations/*}/operations",
+                    "uri": "/v1alpha/{name=projects/*/locations/*}/operations",
                 },
             ]
 
             request, metadata = self._interceptor.pre_list_operations(request, metadata)
             request_kwargs = json_format.MessageToDict(request)
             transcoded_request = path_template.transcode(http_options, **request_kwargs)
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/types/__init__.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/types/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -14,64 +14,73 @@
 # limitations under the License.
 #
 from .resources import (
     AutomatedBackupPolicy,
     Backup,
     BackupSource,
     Cluster,
+    ClusterView,
     ConnectionInfo,
     ContinuousBackupConfig,
     ContinuousBackupInfo,
     ContinuousBackupSource,
     DatabaseVersion,
     EncryptionConfig,
     EncryptionInfo,
     Instance,
     InstanceView,
     MigrationSource,
     SslConfig,
     SupportedDatabaseFlag,
+    User,
     UserPassword,
 )
 from .service import (
     BatchCreateInstancesMetadata,
     BatchCreateInstancesRequest,
     BatchCreateInstancesResponse,
     BatchCreateInstanceStatus,
     CreateBackupRequest,
     CreateClusterRequest,
     CreateInstanceRequest,
     CreateInstanceRequests,
     CreateSecondaryClusterRequest,
     CreateSecondaryInstanceRequest,
+    CreateUserRequest,
     DeleteBackupRequest,
     DeleteClusterRequest,
     DeleteInstanceRequest,
+    DeleteUserRequest,
     FailoverInstanceRequest,
     GenerateClientCertificateRequest,
     GenerateClientCertificateResponse,
     GetBackupRequest,
     GetClusterRequest,
     GetConnectionInfoRequest,
     GetInstanceRequest,
+    GetUserRequest,
+    InjectFaultRequest,
     ListBackupsRequest,
     ListBackupsResponse,
     ListClustersRequest,
     ListClustersResponse,
     ListInstancesRequest,
     ListInstancesResponse,
     ListSupportedDatabaseFlagsRequest,
     ListSupportedDatabaseFlagsResponse,
+    ListUsersRequest,
+    ListUsersResponse,
     OperationMetadata,
     PromoteClusterRequest,
     RestartInstanceRequest,
     RestoreClusterRequest,
     UpdateBackupRequest,
     UpdateClusterRequest,
     UpdateInstanceRequest,
+    UpdateUserRequest,
 )
 
 __all__ = (
     "AutomatedBackupPolicy",
     "Backup",
     "BackupSource",
     "Cluster",
@@ -81,46 +90,55 @@
     "ContinuousBackupSource",
     "EncryptionConfig",
     "EncryptionInfo",
     "Instance",
     "MigrationSource",
     "SslConfig",
     "SupportedDatabaseFlag",
+    "User",
     "UserPassword",
+    "ClusterView",
     "DatabaseVersion",
     "InstanceView",
     "BatchCreateInstancesMetadata",
     "BatchCreateInstancesRequest",
     "BatchCreateInstancesResponse",
     "BatchCreateInstanceStatus",
     "CreateBackupRequest",
     "CreateClusterRequest",
     "CreateInstanceRequest",
     "CreateInstanceRequests",
     "CreateSecondaryClusterRequest",
     "CreateSecondaryInstanceRequest",
+    "CreateUserRequest",
     "DeleteBackupRequest",
     "DeleteClusterRequest",
     "DeleteInstanceRequest",
+    "DeleteUserRequest",
     "FailoverInstanceRequest",
     "GenerateClientCertificateRequest",
     "GenerateClientCertificateResponse",
     "GetBackupRequest",
     "GetClusterRequest",
     "GetConnectionInfoRequest",
     "GetInstanceRequest",
+    "GetUserRequest",
+    "InjectFaultRequest",
     "ListBackupsRequest",
     "ListBackupsResponse",
     "ListClustersRequest",
     "ListClustersResponse",
     "ListInstancesRequest",
     "ListInstancesResponse",
     "ListSupportedDatabaseFlagsRequest",
     "ListSupportedDatabaseFlagsResponse",
+    "ListUsersRequest",
+    "ListUsersResponse",
     "OperationMetadata",
     "PromoteClusterRequest",
     "RestartInstanceRequest",
     "RestoreClusterRequest",
     "UpdateBackupRequest",
     "UpdateClusterRequest",
     "UpdateInstanceRequest",
+    "UpdateUserRequest",
 )
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/types/resources.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/types/resources.py`

 * *Files 2% similar despite different names*

```diff
@@ -23,16 +23,17 @@
 from google.type import dayofweek_pb2  # type: ignore
 from google.type import timeofday_pb2  # type: ignore
 import proto  # type: ignore
 
 __protobuf__ = proto.module(
     package="google.cloud.alloydb.v1beta",
     manifest={
-        "DatabaseVersion",
         "InstanceView",
+        "ClusterView",
+        "DatabaseVersion",
         "UserPassword",
         "MigrationSource",
         "EncryptionConfig",
         "EncryptionInfo",
         "SslConfig",
         "AutomatedBackupPolicy",
         "ContinuousBackupConfig",
@@ -40,35 +41,19 @@
         "BackupSource",
         "ContinuousBackupSource",
         "Cluster",
         "Instance",
         "ConnectionInfo",
         "Backup",
         "SupportedDatabaseFlag",
+        "User",
     },
 )
 
 
-class DatabaseVersion(proto.Enum):
-    r"""The supported database engine versions.
-
-    Values:
-        DATABASE_VERSION_UNSPECIFIED (0):
-            This is an unknown database version.
-        POSTGRES_13 (1):
-            DEPRECATED - The database version is Postgres
-            13.
-        POSTGRES_14 (2):
-            The database version is Postgres 14.
-    """
-    DATABASE_VERSION_UNSPECIFIED = 0
-    POSTGRES_13 = 1
-    POSTGRES_14 = 2
-
-
 class InstanceView(proto.Enum):
     r"""View on Instance. Pass this enum to rpcs that returns an
     Instance message to control which subsets of fields to get.
 
     Values:
         INSTANCE_VIEW_UNSPECIFIED (0):
             INSTANCE_VIEW_UNSPECIFIED Not specified, equivalent to
@@ -85,14 +70,54 @@
             the pool.
     """
     INSTANCE_VIEW_UNSPECIFIED = 0
     INSTANCE_VIEW_BASIC = 1
     INSTANCE_VIEW_FULL = 2
 
 
+class ClusterView(proto.Enum):
+    r"""View on Cluster. Pass this enum to rpcs that returns a
+    cluster message to control which subsets of fields to get.
+
+    Values:
+        CLUSTER_VIEW_UNSPECIFIED (0):
+            CLUSTER_VIEW_UNSPECIFIED Not specified, equivalent to BASIC.
+        CLUSTER_VIEW_BASIC (1):
+            BASIC server responses include all the
+            relevant cluster details, excluding
+            Cluster.ContinuousBackupInfo.EarliestRestorableTime
+            and other view-specific fields. The default
+            value.
+        CLUSTER_VIEW_CONTINUOUS_BACKUP (2):
+            CONTINUOUS_BACKUP response returns all the fields from BASIC
+            plus the earliest restorable time if continuous backups are
+            enabled. May increase latency.
+    """
+    CLUSTER_VIEW_UNSPECIFIED = 0
+    CLUSTER_VIEW_BASIC = 1
+    CLUSTER_VIEW_CONTINUOUS_BACKUP = 2
+
+
+class DatabaseVersion(proto.Enum):
+    r"""The supported database engine versions.
+
+    Values:
+        DATABASE_VERSION_UNSPECIFIED (0):
+            This is an unknown database version.
+        POSTGRES_13 (1):
+            DEPRECATED - The database version is Postgres
+            13.
+        POSTGRES_14 (2):
+            The database version is Postgres 14.
+    """
+    DATABASE_VERSION_UNSPECIFIED = 0
+    POSTGRES_13 = 1
+    POSTGRES_14 = 2
+
+
 class UserPassword(proto.Message):
     r"""The username/password for a database user. Used for
     specifying initial users at cluster creation time.
 
     Attributes:
         user (str):
             The database username.
@@ -214,15 +239,15 @@
     kms_key_versions: MutableSequence[str] = proto.RepeatedField(
         proto.STRING,
         number=2,
     )
 
 
 class SslConfig(proto.Message):
-    r"""SSL configuration for an AlloyDB Cluster.
+    r"""SSL configuration.
 
     Attributes:
         ssl_mode (google.cloud.alloydb_v1beta.types.SslConfig.SslMode):
             Optional. SSL mode. Specifies client-server
             SSL/TLS connection behavior.
         ca_source (google.cloud.alloydb_v1beta.types.SslConfig.CaSource):
             Optional. Certificate Authority (CA) source. Only
@@ -231,33 +256,41 @@
     """
 
     class SslMode(proto.Enum):
         r"""SSL mode options.
 
         Values:
             SSL_MODE_UNSPECIFIED (0):
-                SSL mode not specified. Defaults to SSL_MODE_ALLOW.
+                SSL mode not specified. Defaults to ENCRYPTED_ONLY.
             SSL_MODE_ALLOW (1):
                 SSL connections are optional. CA verification
                 not enforced.
             SSL_MODE_REQUIRE (2):
                 SSL connections are required. CA verification
                 not enforced. Clients may use locally
                 self-signed certificates (default psql client
                 behavior).
             SSL_MODE_VERIFY_CA (3):
                 SSL connections are required. CA verification
                 enforced. Clients must have certificates signed
                 by a Cluster CA, e.g. via
                 GenerateClientCertificate.
+            ALLOW_UNENCRYPTED_AND_ENCRYPTED (4):
+                SSL connections are optional. CA verification
+                not enforced.
+            ENCRYPTED_ONLY (5):
+                SSL connections are required. CA verification
+                not enforced.
         """
         SSL_MODE_UNSPECIFIED = 0
         SSL_MODE_ALLOW = 1
         SSL_MODE_REQUIRE = 2
         SSL_MODE_VERIFY_CA = 3
+        ALLOW_UNENCRYPTED_AND_ENCRYPTED = 4
+        ENCRYPTED_ONLY = 5
 
     class CaSource(proto.Enum):
         r"""Certificate Authority (CA) source for SSL/TLS certificates.
 
         Values:
             CA_SOURCE_UNSPECIFIED (0):
                 Certificate Authority (CA) source not specified. Defaults to
@@ -500,14 +533,17 @@
             Output only. When ContinuousBackup was most
             recently enabled. Set to null if
             ContinuousBackup is not enabled.
         schedule (MutableSequence[google.type.dayofweek_pb2.DayOfWeek]):
             Output only. Days of the week on which a
             continuous backup is taken. Output only field.
             Ignored if passed into the request.
+        earliest_restorable_time (google.protobuf.timestamp_pb2.Timestamp):
+            Output only. The earliest restorable time
+            that can be restored to. Output only field.
     """
 
     encryption_info: "EncryptionInfo" = proto.Field(
         proto.MESSAGE,
         number=1,
         message="EncryptionInfo",
     )
@@ -517,14 +553,19 @@
         message=timestamp_pb2.Timestamp,
     )
     schedule: MutableSequence[dayofweek_pb2.DayOfWeek] = proto.RepeatedField(
         proto.ENUM,
         number=3,
         enum=dayofweek_pb2.DayOfWeek,
     )
+    earliest_restorable_time: timestamp_pb2.Timestamp = proto.Field(
+        proto.MESSAGE,
+        number=4,
+        message=timestamp_pb2.Timestamp,
+    )
 
 
 class BackupSource(proto.Message):
     r"""Message describing a BackupSource.
 
     Attributes:
         backup_uid (str):
@@ -632,14 +673,16 @@
             which RPC was used to create the cluster (i.e.
             ``CreateCluster`` vs. ``CreateSecondaryCluster``
         database_version (google.cloud.alloydb_v1beta.types.DatabaseVersion):
             Output only. The database engine major
             version. This is an output-only field and it's
             populated at the Cluster creation time. This
             field cannot be changed after cluster creation.
+        network_config (google.cloud.alloydb_v1beta.types.Cluster.NetworkConfig):
+
         network (str):
             Required. The resource link for the VPC network in which
             cluster resources are created and from which they are
             accessible via Private IP. The network must belong to the
             same project as the cluster. It is specified in the form:
             "projects/{project_number}/global/networks/{network_id}".
             This is required to create a cluster. It can be updated, but
@@ -669,15 +712,15 @@
             will be used. If backups are supported for the
             cluster, the default policy takes one backup a
             day, has a backup window of 1 hour, and retains
             backups for 14 days. For more information on the
             defaults, consult the documentation for the
             message type.
         ssl_config (google.cloud.alloydb_v1beta.types.SslConfig):
-            SSL configuration for this AlloyDB Cluster.
+            SSL configuration for this AlloyDB cluster.
         encryption_config (google.cloud.alloydb_v1beta.types.EncryptionConfig):
             Optional. The encryption config can be
             specified to encrypt the data disks and other
             persistent data resources of a cluster with a
             customer-managed encryption key (CMEK). When
             this field is not specified, the cluster will
             then use default encryption scheme to protect
@@ -762,14 +805,46 @@
                 Secondary cluster that is replicating from
                 another region. This only supports read.
         """
         CLUSTER_TYPE_UNSPECIFIED = 0
         PRIMARY = 1
         SECONDARY = 2
 
+    class NetworkConfig(proto.Message):
+        r"""Metadata related to network configuration.
+
+        Attributes:
+            network (str):
+                Required. The resource link for the VPC network in which
+                cluster resources are created and from which they are
+                accessible via Private IP. The network must belong to the
+                same project as the cluster. It is specified in the form:
+                "projects/{project_number}/global/networks/{network_id}".
+                This is required to create a cluster. It can be updated, but
+                it cannot be removed.
+            allocated_ip_range (str):
+                Optional. The name of the allocated IP range for the private
+                IP AlloyDB cluster. For example:
+                "google-managed-services-default". If set, the instance IPs
+                for this cluster will be created in the allocated range. The
+                range name must comply with RFC 1035. Specifically, the name
+                must be 1-63 characters long and match the regular
+                expression `a-z <[-a-z0-9]*[a-z0-9]>`__?. Field name is
+                intended to be consistent with CloudSQL.
+        """
+
+        network: str = proto.Field(
+            proto.STRING,
+            number=1,
+        )
+        allocated_ip_range: str = proto.Field(
+            proto.STRING,
+            number=2,
+        )
+
     class SecondaryConfig(proto.Message):
         r"""Configuration information for the secondary cluster. This
         should be set if and only if the cluster is of type SECONDARY.
 
         Attributes:
             primary_cluster_name (str):
                 The name of the primary cluster name with the format:
@@ -853,14 +928,19 @@
         enum=ClusterType,
     )
     database_version: "DatabaseVersion" = proto.Field(
         proto.ENUM,
         number=9,
         enum="DatabaseVersion",
     )
+    network_config: NetworkConfig = proto.Field(
+        proto.MESSAGE,
+        number=29,
+        message=NetworkConfig,
+    )
     network: str = proto.Field(
         proto.STRING,
         number=10,
     )
     etag: str = proto.Field(
         proto.STRING,
         number=11,
@@ -962,18 +1042,20 @@
         instance_type (google.cloud.alloydb_v1beta.types.Instance.InstanceType):
             Required. The type of the instance. Specified
             at creation time.
         machine_config (google.cloud.alloydb_v1beta.types.Instance.MachineConfig):
             Configurations for the machines that host the
             underlying database engine.
         availability_type (google.cloud.alloydb_v1beta.types.Instance.AvailabilityType):
-            Availability type of an Instance.
-            Defaults to REGIONAL for both primary and read
-            instances. Note that primary and read instances
-            can have different availability types.
+            Availability type of an Instance. If empty, defaults to
+            REGIONAL for primary instances. For read pools,
+            availability_type is always UNSPECIFIED. Instances in the
+            read pools are evenly distributed across available zones
+            within the region (i.e. read pools with more than one node
+            will have a node in at least two zones).
         gce_zone (str):
             The Compute Engine zone that the instance
             should serve from, per
             https://cloud.google.com/compute/docs/regions-zones
             This can ONLY be specified for ZONAL instances.
             If present for a REGIONAL instance, an error
             will be thrown. If this is absent for a ZONAL
@@ -1023,14 +1105,21 @@
         etag (str):
             For Resource freshness validation
             (https://google.aip.dev/154)
         annotations (MutableMapping[str, str]):
             Annotations to allow client tools to store
             small amount of arbitrary data. This is distinct
             from labels. https://google.aip.dev/128
+        update_policy (google.cloud.alloydb_v1beta.types.Instance.UpdatePolicy):
+            Update policy that will be applied during
+            instance update. This field is not persisted
+            when you update the instance. To use a
+            non-default update policy, you must
+            specify explicitly specify the value in each
+            update request.
     """
 
     class State(proto.Enum):
         r"""Instance State
 
         Values:
             STATE_UNSPECIFIED (0):
@@ -1097,17 +1186,17 @@
         PRIMARY = 1
         READ_POOL = 2
         SECONDARY = 3
 
     class AvailabilityType(proto.Enum):
         r"""The Availability type of an instance. Potential values:
         - ZONAL: The instance serves data from only one zone. Outages in
-        that zone affect instance availability.
+        that     zone affect instance availability.
         - REGIONAL: The instance can serve data from more than one zone
-        in a region (it is highly available).
+        in a     region (it is highly available).
 
         Values:
             AVAILABILITY_TYPE_UNSPECIFIED (0):
                 This is an unknown Availability type.
             ZONAL (1):
                 Zonal available instance.
             REGIONAL (2):
@@ -1231,14 +1320,44 @@
         """
 
         node_count: int = proto.Field(
             proto.INT32,
             number=1,
         )
 
+    class UpdatePolicy(proto.Message):
+        r"""Policy to be used while updating the instance.
+
+        Attributes:
+            mode (google.cloud.alloydb_v1beta.types.Instance.UpdatePolicy.Mode):
+                Mode for updating the instance.
+        """
+
+        class Mode(proto.Enum):
+            r"""Specifies the available modes of update.
+
+            Values:
+                MODE_UNSPECIFIED (0):
+                    Mode is unknown.
+                DEFAULT (1):
+                    Least disruptive way to apply the update.
+                FORCE_APPLY (2):
+                    Performs a forced update when applicable.
+                    This will be fast but may incur a downtime.
+            """
+            MODE_UNSPECIFIED = 0
+            DEFAULT = 1
+            FORCE_APPLY = 2
+
+        mode: "Instance.UpdatePolicy.Mode" = proto.Field(
+            proto.ENUM,
+            number=1,
+            enum="Instance.UpdatePolicy.Mode",
+        )
+
     name: str = proto.Field(
         proto.STRING,
         number=1,
     )
     display_name: str = proto.Field(
         proto.STRING,
         number=2,
@@ -1329,14 +1448,19 @@
         number=17,
     )
     annotations: MutableMapping[str, str] = proto.MapField(
         proto.STRING,
         proto.STRING,
         number=18,
     )
+    update_policy: UpdatePolicy = proto.Field(
+        proto.MESSAGE,
+        number=22,
+        message=UpdatePolicy,
+    )
 
 
 class ConnectionInfo(proto.Message):
     r"""ConnectionInfo singleton resource.
     https://google.aip.dev/156
 
     Attributes:
@@ -1416,15 +1540,16 @@
         description (str):
             User-provided description of the backup.
         cluster_uid (str):
             Output only. The system-generated UID of the
             cluster which was used to create this resource.
         cluster_name (str):
             Required. The full resource name of the backup source
-            cluster (e.g., projects//locations//clusters/<cluster_id>).
+            cluster (e.g.,
+            projects/{project}/locations/{region}/clusters/{cluster_id}).
         reconciling (bool):
             Output only. Reconciling
             (https://google.aip.dev/128#reconciliation), if
             true, indicates that the service is actively
             updating the resource. This can happen due to
             user-triggered updates or system actions like
             failover or maintenance.
@@ -1735,8 +1860,62 @@
     )
     requires_db_restart: bool = proto.Field(
         proto.BOOL,
         number=6,
     )
 
 
+class User(proto.Message):
+    r"""Message describing User object.
+
+    Attributes:
+        name (str):
+            Output only. Name of the resource in the form
+            of
+            projects/{project}/locations/{location}/cluster/{cluster}/users/{user}.
+        password (str):
+            Input only. Password for the user.
+        database_roles (MutableSequence[str]):
+            Optional. List of database roles this user
+            has. The database role strings are subject to
+            the PostgreSQL naming conventions.
+        user_type (google.cloud.alloydb_v1beta.types.User.UserType):
+            Optional. Type of this user.
+    """
+
+    class UserType(proto.Enum):
+        r"""Enum that details the user type.
+
+        Values:
+            USER_TYPE_UNSPECIFIED (0):
+                Unspecified user type.
+            ALLOYDB_BUILT_IN (1):
+                The default user type that authenticates via
+                password-based authentication.
+            ALLOYDB_IAM_USER (2):
+                Database user that can authenticate via
+                IAM-Based authentication.
+        """
+        USER_TYPE_UNSPECIFIED = 0
+        ALLOYDB_BUILT_IN = 1
+        ALLOYDB_IAM_USER = 2
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    password: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    database_roles: MutableSequence[str] = proto.RepeatedField(
+        proto.STRING,
+        number=4,
+    )
+    user_type: UserType = proto.Field(
+        proto.ENUM,
+        number=5,
+        enum=UserType,
+    )
+
+
 __all__ = tuple(sorted(__protobuf__.manifest))
```

### Comparing `google-cloud-alloydb-0.1.1/google/cloud/alloydb_v1beta/types/service.py` & `google-cloud-alloydb-0.2.0/google/cloud/alloydb_v1beta/types/service.py`

 * *Files 10% similar despite different names*

```diff
@@ -46,27 +46,34 @@
         "BatchCreateInstancesRequest",
         "BatchCreateInstancesResponse",
         "BatchCreateInstancesMetadata",
         "BatchCreateInstanceStatus",
         "UpdateInstanceRequest",
         "DeleteInstanceRequest",
         "FailoverInstanceRequest",
+        "InjectFaultRequest",
         "RestartInstanceRequest",
         "ListBackupsRequest",
         "ListBackupsResponse",
         "GetBackupRequest",
         "CreateBackupRequest",
         "UpdateBackupRequest",
         "DeleteBackupRequest",
         "ListSupportedDatabaseFlagsRequest",
         "ListSupportedDatabaseFlagsResponse",
         "GenerateClientCertificateRequest",
         "GenerateClientCertificateResponse",
         "GetConnectionInfoRequest",
         "OperationMetadata",
+        "ListUsersRequest",
+        "ListUsersResponse",
+        "GetUserRequest",
+        "CreateUserRequest",
+        "UpdateUserRequest",
+        "DeleteUserRequest",
     },
 )
 
 
 class ListClustersRequest(proto.Message):
     r"""Message for requesting list of Clusters
 
@@ -150,30 +157,38 @@
     r"""Message for getting a Cluster
 
     Attributes:
         name (str):
             Required. The name of the resource. For the
             required format, see the comment on the
             Cluster.name field.
+        view (google.cloud.alloydb_v1beta.types.ClusterView):
+            Optional. The view of the cluster to return.
+            Returns all default fields if not set.
     """
 
     name: str = proto.Field(
         proto.STRING,
         number=1,
     )
+    view: resources.ClusterView = proto.Field(
+        proto.ENUM,
+        number=2,
+        enum=resources.ClusterView,
+    )
 
 
 class CreateSecondaryClusterRequest(proto.Message):
     r"""
 
     Attributes:
         parent (str):
-            Required. The name of the parent resource
-            (the primary cluster). For the required format,
-            see the comment on the Cluster.name field.
+            Required. The location of the new cluster.
+            For the required format, see the comment on the
+            Cluster.name field.
         cluster_id (str):
             Required. ID of the requesting object (the
             secondary cluster).
         cluster (google.cloud.alloydb_v1beta.types.Cluster):
             Required. Configuration of the requesting
             object (the secondary cluster).
         request_id (str):
@@ -225,15 +240,15 @@
 
 
 class CreateClusterRequest(proto.Message):
     r"""Message for creating a Cluster
 
     Attributes:
         parent (str):
-            Required. The name of the parent resource.
+            Required. The location of the new cluster.
             For the required format, see the comment on the
             Cluster.name field.
         cluster_id (str):
             Required. ID of the requesting object.
         cluster (google.cloud.alloydb_v1beta.types.Cluster):
             Required. The resource being created
         request_id (str):
@@ -856,16 +871,16 @@
         proto.MESSAGE,
         number=1,
         message=resources.Instance,
     )
 
 
 class BatchCreateInstancesMetadata(proto.Message):
-    r"""Message for metadata that is specific to BatchCreateInstances
-    API.
+    r"""Message for metadata that is specific to BatchCreateInstances API.
+    NEXT_ID: 3
 
     Attributes:
         instance_targets (MutableSequence[str]):
             The instances being created in the API call.
             Each string in this list is the server defined
             resource path for target instances in the
             request and for the format of each string, see
@@ -902,18 +917,20 @@
     failed to create and the 4th was never picked up for creation
     because of failure of the previous one. Then, resulting states would
     look something like:
 
     1. Instance1 = ROLLED_BACK
     2. Instance2 = ROLLED_BACK
     3. Instance3 = FAILED
-    4. Instance4 = FAILED However, while the operation is running, the
-       instance might be in other states including PENDING_CREATE,
-       ACTIVE, DELETING and CREATING. The states / do not get further
-       updated once the operation is done.
+    4. Instance4 = FAILED
+
+    However, while the operation is running, the instance might be in
+    other states including PENDING_CREATE, ACTIVE, DELETING and
+    CREATING. The states / do not get further updated once the operation
+    is done.
 
     Attributes:
         state (google.cloud.alloydb_v1beta.types.BatchCreateInstanceStatus.State):
             The current state of an instance involved in the batch
             create operation. Once the operation is complete, the final
             state of the instances in the LRO can be one of:
 
@@ -1156,14 +1173,82 @@
     )
     validate_only: bool = proto.Field(
         proto.BOOL,
         number=3,
     )
 
 
+class InjectFaultRequest(proto.Message):
+    r"""Message for triggering fault injection on an instance
+
+    Attributes:
+        fault_type (google.cloud.alloydb_v1beta.types.InjectFaultRequest.FaultType):
+            Required. The type of fault to be injected in
+            an instance.
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            Instance.name field.
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes after the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, performs request validation
+            (e.g. permission checks and any other type of
+            validation), but do not actually execute the
+            fault injection.
+    """
+
+    class FaultType(proto.Enum):
+        r"""FaultType contains all valid types of faults that can be
+        injected to an instance.
+
+        Values:
+            FAULT_TYPE_UNSPECIFIED (0):
+                The fault type is unknown.
+            STOP_VM (1):
+                Stop the VM
+        """
+        FAULT_TYPE_UNSPECIFIED = 0
+        STOP_VM = 1
+
+    fault_type: FaultType = proto.Field(
+        proto.ENUM,
+        number=1,
+        enum=FaultType,
+    )
+    name: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=4,
+    )
+
+
 class RestartInstanceRequest(proto.Message):
     r"""
 
     Attributes:
         name (str):
             Required. The name of the resource. For the
             required format, see the comment on the
@@ -1569,14 +1654,16 @@
             Optional. An optional hint to the endpoint to
             generate the client certificate with the
             requested duration. The duration can be from 1
             hour to 24 hours. The endpoint may or may not
             honor the hint. If the hint is left unspecified
             or is not honored, then the endpoint will pick
             an appropriate default duration.
+        public_key (str):
+            Optional. The public key from the client.
     """
 
     parent: str = proto.Field(
         proto.STRING,
         number=1,
     )
     request_id: str = proto.Field(
@@ -1588,38 +1675,49 @@
         number=3,
     )
     cert_duration: duration_pb2.Duration = proto.Field(
         proto.MESSAGE,
         number=4,
         message=duration_pb2.Duration,
     )
+    public_key: str = proto.Field(
+        proto.STRING,
+        number=5,
+    )
 
 
 class GenerateClientCertificateResponse(proto.Message):
     r"""Message returned by a GenerateClientCertificate operation.
 
     Attributes:
         pem_certificate (str):
             Output only. The pem-encoded, signed X.509
             certificate.
         pem_certificate_chain (MutableSequence[str]):
             Output only. The pem-encoded chain that may
             be used to verify the X.509 certificate.
             Expected to be in issuer-to-root order according
             to RFC 5246.
+        ca_cert (str):
+            Optional. The pem-encoded cluster ca X.509
+            certificate.
     """
 
     pem_certificate: str = proto.Field(
         proto.STRING,
         number=1,
     )
     pem_certificate_chain: MutableSequence[str] = proto.RepeatedField(
         proto.STRING,
         number=2,
     )
+    ca_cert: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
 
 
 class GetConnectionInfoRequest(proto.Message):
     r"""Request message for GetConnectionInfo.
 
     Attributes:
         parent (str):
@@ -1727,8 +1825,262 @@
     )
     api_version: str = proto.Field(
         proto.STRING,
         number=7,
     )
 
 
+class ListUsersRequest(proto.Message):
+    r"""Message for requesting list of Users
+
+    Attributes:
+        parent (str):
+            Required. Parent value for ListUsersRequest
+        page_size (int):
+            Optional. Requested page size. Server may
+            return fewer items than requested. If
+            unspecified, server will pick an appropriate
+            default.
+        page_token (str):
+            Optional. A token identifying a page of
+            results the server should return.
+        filter (str):
+            Optional. Filtering results
+        order_by (str):
+            Optional. Hint for how to order the results
+    """
+
+    parent: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    page_size: int = proto.Field(
+        proto.INT32,
+        number=2,
+    )
+    page_token: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    filter: str = proto.Field(
+        proto.STRING,
+        number=4,
+    )
+    order_by: str = proto.Field(
+        proto.STRING,
+        number=5,
+    )
+
+
+class ListUsersResponse(proto.Message):
+    r"""Message for response to listing Users
+
+    Attributes:
+        users (MutableSequence[google.cloud.alloydb_v1beta.types.User]):
+            The list of User
+        next_page_token (str):
+            A token identifying a page of results the
+            server should return.
+        unreachable (MutableSequence[str]):
+            Locations that could not be reached.
+    """
+
+    @property
+    def raw_page(self):
+        return self
+
+    users: MutableSequence[resources.User] = proto.RepeatedField(
+        proto.MESSAGE,
+        number=1,
+        message=resources.User,
+    )
+    next_page_token: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    unreachable: MutableSequence[str] = proto.RepeatedField(
+        proto.STRING,
+        number=3,
+    )
+
+
+class GetUserRequest(proto.Message):
+    r"""Message for getting a User
+
+    Attributes:
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            User.name field.
+    """
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+
+
+class CreateUserRequest(proto.Message):
+    r"""Message for creating a User
+
+    Attributes:
+        parent (str):
+            Required. Value for parent.
+        user_id (str):
+            Required. ID of the requesting object.
+        user (google.cloud.alloydb_v1beta.types.User):
+            Required. The resource being created
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes since the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, the backend validates the
+            request, but doesn't actually execute it.
+    """
+
+    parent: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    user_id: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    user: resources.User = proto.Field(
+        proto.MESSAGE,
+        number=3,
+        message=resources.User,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=4,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=5,
+    )
+
+
+class UpdateUserRequest(proto.Message):
+    r"""Message for updating a User
+
+    Attributes:
+        update_mask (google.protobuf.field_mask_pb2.FieldMask):
+            Optional. Field mask is used to specify the fields to be
+            overwritten in the User resource by the update. The fields
+            specified in the update_mask are relative to the resource,
+            not the full request. A field will be overwritten if it is
+            in the mask. If the user does not provide a mask then all
+            fields will be overwritten.
+        user (google.cloud.alloydb_v1beta.types.User):
+            Required. The resource being updated
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes since the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, the backend validates the
+            request, but doesn't actually execute it.
+        allow_missing (bool):
+            Optional. Allow missing fields in the update
+            mask.
+    """
+
+    update_mask: field_mask_pb2.FieldMask = proto.Field(
+        proto.MESSAGE,
+        number=1,
+        message=field_mask_pb2.FieldMask,
+    )
+    user: resources.User = proto.Field(
+        proto.MESSAGE,
+        number=2,
+        message=resources.User,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=3,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=4,
+    )
+    allow_missing: bool = proto.Field(
+        proto.BOOL,
+        number=5,
+    )
+
+
+class DeleteUserRequest(proto.Message):
+    r"""Message for deleting a User
+
+    Attributes:
+        name (str):
+            Required. The name of the resource. For the
+            required format, see the comment on the
+            User.name field.
+        request_id (str):
+            Optional. An optional request ID to identify
+            requests. Specify a unique request ID so that if
+            you must retry your request, the server will
+            know to ignore the request if it has already
+            been completed. The server will guarantee that
+            for at least 60 minutes after the first request.
+            For example, consider a situation where you make
+            an initial request and the request times out. If
+            you make the request again with the same request
+            ID, the server can check if original operation
+            with the same request ID was received, and if
+            so, will ignore the second request. This
+            prevents clients from accidentally creating
+            duplicate commitments.
+            The request ID must be a valid UUID with the
+            exception that zero UUID is not supported
+            (00000000-0000-0000-0000-000000000000).
+        validate_only (bool):
+            Optional. If set, the backend validates the
+            request, but doesn't actually execute it.
+    """
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    request_id: str = proto.Field(
+        proto.STRING,
+        number=2,
+    )
+    validate_only: bool = proto.Field(
+        proto.BOOL,
+        number=3,
+    )
+
+
 __all__ = tuple(sorted(__protobuf__.manifest))
```

### Comparing `google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/PKG-INFO` & `google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: google-cloud-alloydb
-Version: 0.1.1
+Version: 0.2.0
 Summary: Google Cloud Alloydb API client library
 Home-page: https://github.com/googleapis/google-cloud-python
 Author: Google LLC
 Author-email: googleapis-packages@google.com
 License: Apache 2.0
 Platform: Posix; MacOS X; Windows
 Classifier: Development Status :: 4 - Beta
```

### Comparing `google-cloud-alloydb-0.1.1/google_cloud_alloydb.egg-info/SOURCES.txt` & `google-cloud-alloydb-0.2.0/google_cloud_alloydb.egg-info/SOURCES.txt`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/setup.py` & `google-cloud-alloydb-0.2.0/setup.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/tests/__init__.py` & `google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1alpha/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/tests/unit/__init__.py` & `google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1beta/__init__.py`

 * *Files identical despite different names*

### Comparing `google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1/test_alloy_db_admin.py` & `google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1/test_alloy_db_admin.py`

 * *Files 11% similar despite different names*

```diff
@@ -2125,14 +2125,240 @@
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.PromoteClusterRequest,
+        dict,
+    ],
+)
+def test_promote_cluster(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.promote_cluster), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/spam")
+        response = client.promote_cluster(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.PromoteClusterRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+def test_promote_cluster_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.promote_cluster), "__call__") as call:
+        client.promote_cluster()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.PromoteClusterRequest()
+
+
+@pytest.mark.asyncio
+async def test_promote_cluster_async(
+    transport: str = "grpc_asyncio", request_type=service.PromoteClusterRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.promote_cluster), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.promote_cluster(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.PromoteClusterRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+@pytest.mark.asyncio
+async def test_promote_cluster_async_from_dict():
+    await test_promote_cluster_async(request_type=dict)
+
+
+def test_promote_cluster_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.PromoteClusterRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.promote_cluster), "__call__") as call:
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        client.promote_cluster(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_promote_cluster_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.PromoteClusterRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.promote_cluster), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/op")
+        )
+        await client.promote_cluster(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_promote_cluster_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.promote_cluster), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.promote_cluster(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_promote_cluster_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.promote_cluster(
+            service.PromoteClusterRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_promote_cluster_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.promote_cluster), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.promote_cluster(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_promote_cluster_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.promote_cluster(
+            service.PromoteClusterRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.RestoreClusterRequest,
         dict,
     ],
 )
 def test_restore_cluster(request_type, transport: str = "grpc"):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -2269,14 +2495,286 @@
         "parent=parent_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.CreateSecondaryClusterRequest,
+        dict,
+    ],
+)
+def test_create_secondary_cluster(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_cluster), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/spam")
+        response = client.create_secondary_cluster(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateSecondaryClusterRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+def test_create_secondary_cluster_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_cluster), "__call__"
+    ) as call:
+        client.create_secondary_cluster()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateSecondaryClusterRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_cluster_async(
+    transport: str = "grpc_asyncio", request_type=service.CreateSecondaryClusterRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_cluster), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.create_secondary_cluster(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateSecondaryClusterRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_cluster_async_from_dict():
+    await test_create_secondary_cluster_async(request_type=dict)
+
+
+def test_create_secondary_cluster_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateSecondaryClusterRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_cluster), "__call__"
+    ) as call:
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        client.create_secondary_cluster(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_cluster_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateSecondaryClusterRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_cluster), "__call__"
+    ) as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/op")
+        )
+        await client.create_secondary_cluster(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+def test_create_secondary_cluster_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_cluster), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.create_secondary_cluster(
+            parent="parent_value",
+            cluster=resources.Cluster(
+                backup_source=resources.BackupSource(backup_uid="backup_uid_value")
+            ),
+            cluster_id="cluster_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].cluster
+        mock_val = resources.Cluster(
+            backup_source=resources.BackupSource(backup_uid="backup_uid_value")
+        )
+        assert arg == mock_val
+        arg = args[0].cluster_id
+        mock_val = "cluster_id_value"
+        assert arg == mock_val
+
+
+def test_create_secondary_cluster_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_secondary_cluster(
+            service.CreateSecondaryClusterRequest(),
+            parent="parent_value",
+            cluster=resources.Cluster(
+                backup_source=resources.BackupSource(backup_uid="backup_uid_value")
+            ),
+            cluster_id="cluster_id_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_cluster_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_cluster), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.create_secondary_cluster(
+            parent="parent_value",
+            cluster=resources.Cluster(
+                backup_source=resources.BackupSource(backup_uid="backup_uid_value")
+            ),
+            cluster_id="cluster_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].cluster
+        mock_val = resources.Cluster(
+            backup_source=resources.BackupSource(backup_uid="backup_uid_value")
+        )
+        assert arg == mock_val
+        arg = args[0].cluster_id
+        mock_val = "cluster_id_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_cluster_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.create_secondary_cluster(
+            service.CreateSecondaryClusterRequest(),
+            parent="parent_value",
+            cluster=resources.Cluster(
+                backup_source=resources.BackupSource(backup_uid="backup_uid_value")
+            ),
+            cluster_id="cluster_id_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.ListInstancesRequest,
         dict,
     ],
 )
 def test_list_instances(request_type, transport: str = "grpc"):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -3203,14 +3701,274 @@
             instance_id="instance_id_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.CreateSecondaryInstanceRequest,
+        dict,
+    ],
+)
+def test_create_secondary_instance(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_instance), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/spam")
+        response = client.create_secondary_instance(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateSecondaryInstanceRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+def test_create_secondary_instance_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_instance), "__call__"
+    ) as call:
+        client.create_secondary_instance()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateSecondaryInstanceRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_instance_async(
+    transport: str = "grpc_asyncio", request_type=service.CreateSecondaryInstanceRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_instance), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.create_secondary_instance(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateSecondaryInstanceRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_instance_async_from_dict():
+    await test_create_secondary_instance_async(request_type=dict)
+
+
+def test_create_secondary_instance_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateSecondaryInstanceRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_instance), "__call__"
+    ) as call:
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        client.create_secondary_instance(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_instance_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateSecondaryInstanceRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_instance), "__call__"
+    ) as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/op")
+        )
+        await client.create_secondary_instance(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+def test_create_secondary_instance_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_instance), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.create_secondary_instance(
+            parent="parent_value",
+            instance=resources.Instance(name="name_value"),
+            instance_id="instance_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].instance
+        mock_val = resources.Instance(name="name_value")
+        assert arg == mock_val
+        arg = args[0].instance_id
+        mock_val = "instance_id_value"
+        assert arg == mock_val
+
+
+def test_create_secondary_instance_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_secondary_instance(
+            service.CreateSecondaryInstanceRequest(),
+            parent="parent_value",
+            instance=resources.Instance(name="name_value"),
+            instance_id="instance_id_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_instance_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_secondary_instance), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.create_secondary_instance(
+            parent="parent_value",
+            instance=resources.Instance(name="name_value"),
+            instance_id="instance_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].instance
+        mock_val = resources.Instance(name="name_value")
+        assert arg == mock_val
+        arg = args[0].instance_id
+        mock_val = "instance_id_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_create_secondary_instance_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.create_secondary_instance(
+            service.CreateSecondaryInstanceRequest(),
+            parent="parent_value",
+            instance=resources.Instance(name="name_value"),
+            instance_id="instance_id_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.BatchCreateInstancesRequest,
         dict,
     ],
 )
 def test_batch_create_instances(request_type, transport: str = "grpc"):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -4059,14 +4817,250 @@
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.InjectFaultRequest,
+        dict,
+    ],
+)
+def test_inject_fault(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/spam")
+        response = client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.InjectFaultRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+def test_inject_fault_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        client.inject_fault()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.InjectFaultRequest()
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_async(
+    transport: str = "grpc_asyncio", request_type=service.InjectFaultRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.InjectFaultRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_async_from_dict():
+    await test_inject_fault_async(request_type=dict)
+
+
+def test_inject_fault_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.InjectFaultRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.InjectFaultRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/op")
+        )
+        await client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_inject_fault_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.inject_fault(
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].fault_type
+        mock_val = service.InjectFaultRequest.FaultType.STOP_VM
+        assert arg == mock_val
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_inject_fault_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.inject_fault(
+            service.InjectFaultRequest(),
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.inject_fault(
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].fault_type
+        mock_val = service.InjectFaultRequest.FaultType.STOP_VM
+        assert arg == mock_val
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.inject_fault(
+            service.InjectFaultRequest(),
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.RestartInstanceRequest,
         dict,
     ],
 )
 def test_restart_instance(request_type, transport: str = "grpc"):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -6128,14 +7122,1408 @@
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.ListUsersRequest,
+        dict,
+    ],
+)
+def test_list_users(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = service.ListUsersResponse(
+            next_page_token="next_page_token_value",
+            unreachable=["unreachable_value"],
+        )
+        response = client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.ListUsersRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, pagers.ListUsersPager)
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
+
+
+def test_list_users_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        client.list_users()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.ListUsersRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_users_async(
+    transport: str = "grpc_asyncio", request_type=service.ListUsersRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            service.ListUsersResponse(
+                next_page_token="next_page_token_value",
+                unreachable=["unreachable_value"],
+            )
+        )
+        response = await client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.ListUsersRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, pagers.ListUsersAsyncPager)
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
+
+
+@pytest.mark.asyncio
+async def test_list_users_async_from_dict():
+    await test_list_users_async(request_type=dict)
+
+
+def test_list_users_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.ListUsersRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        call.return_value = service.ListUsersResponse()
+        client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_list_users_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.ListUsersRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            service.ListUsersResponse()
+        )
+        await client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+def test_list_users_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = service.ListUsersResponse()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.list_users(
+            parent="parent_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+
+
+def test_list_users_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.list_users(
+            service.ListUsersRequest(),
+            parent="parent_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_list_users_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = service.ListUsersResponse()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            service.ListUsersResponse()
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.list_users(
+            parent="parent_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_list_users_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.list_users(
+            service.ListUsersRequest(),
+            parent="parent_value",
+        )
+
+
+def test_list_users_pager(transport_name: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials,
+        transport=transport_name,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+
+        metadata = ()
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
+        )
+        pager = client.list_users(request={})
+
+        assert pager._metadata == metadata
+
+        results = list(pager)
+        assert len(results) == 6
+        assert all(isinstance(i, resources.User) for i in results)
+
+
+def test_list_users_pages(transport_name: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials,
+        transport=transport_name,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+        pages = list(client.list_users(request={}).pages)
+        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
+            assert page_.raw_page.next_page_token == token
+
+
+@pytest.mark.asyncio
+async def test_list_users_async_pager():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_users), "__call__", new_callable=mock.AsyncMock
+    ) as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+        async_pager = await client.list_users(
+            request={},
+        )
+        assert async_pager.next_page_token == "abc"
+        responses = []
+        async for response in async_pager:  # pragma: no branch
+            responses.append(response)
+
+        assert len(responses) == 6
+        assert all(isinstance(i, resources.User) for i in responses)
+
+
+@pytest.mark.asyncio
+async def test_list_users_async_pages():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_users), "__call__", new_callable=mock.AsyncMock
+    ) as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+        pages = []
+        async for page_ in (
+            await client.list_users(request={})
+        ).pages:  # pragma: no branch
+            pages.append(page_)
+        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
+            assert page_.raw_page.next_page_token == token
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.GetUserRequest,
+        dict,
+    ],
+)
+def test_get_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+        response = client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.GetUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_get_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        client.get_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.GetUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_user_async(
+    transport: str = "grpc_asyncio", request_type=service.GetUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            resources.User(
+                name="name_value",
+                password="password_value",
+                database_roles=["database_roles_value"],
+                user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+            )
+        )
+        response = await client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.GetUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+@pytest.mark.asyncio
+async def test_get_user_async_from_dict():
+    await test_get_user_async(request_type=dict)
+
+
+def test_get_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.GetUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        call.return_value = resources.User()
+        client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_get_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.GetUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        await client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_get_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.get_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_get_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.get_user(
+            service.GetUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_get_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.get_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_get_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.get_user(
+            service.GetUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.CreateUserRequest,
+        dict,
+    ],
+)
+def test_create_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+        response = client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_create_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        client.create_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_user_async(
+    transport: str = "grpc_asyncio", request_type=service.CreateUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            resources.User(
+                name="name_value",
+                password="password_value",
+                database_roles=["database_roles_value"],
+                user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+            )
+        )
+        response = await client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+@pytest.mark.asyncio
+async def test_create_user_async_from_dict():
+    await test_create_user_async(request_type=dict)
+
+
+def test_create_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateUserRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        call.return_value = resources.User()
+        client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_create_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateUserRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        await client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+def test_create_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.create_user(
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].user_id
+        mock_val = "user_id_value"
+        assert arg == mock_val
+
+
+def test_create_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_user(
+            service.CreateUserRequest(),
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_create_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.create_user(
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].user_id
+        mock_val = "user_id_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_create_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.create_user(
+            service.CreateUserRequest(),
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.UpdateUserRequest,
+        dict,
+    ],
+)
+def test_update_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+        response = client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.UpdateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_update_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        client.update_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.UpdateUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_user_async(
+    transport: str = "grpc_asyncio", request_type=service.UpdateUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            resources.User(
+                name="name_value",
+                password="password_value",
+                database_roles=["database_roles_value"],
+                user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+            )
+        )
+        response = await client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.UpdateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+@pytest.mark.asyncio
+async def test_update_user_async_from_dict():
+    await test_update_user_async(request_type=dict)
+
+
+def test_update_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.UpdateUserRequest()
+
+    request.user.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        call.return_value = resources.User()
+        client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "user.name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_update_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.UpdateUserRequest()
+
+    request.user.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        await client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "user.name=name_value",
+    ) in kw["metadata"]
+
+
+def test_update_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.update_user(
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].update_mask
+        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
+        assert arg == mock_val
+
+
+def test_update_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.update_user(
+            service.UpdateUserRequest(),
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+
+@pytest.mark.asyncio
+async def test_update_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.update_user(
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].update_mask
+        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_update_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.update_user(
+            service.UpdateUserRequest(),
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.DeleteUserRequest,
+        dict,
+    ],
+)
+def test_delete_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = None
+        response = client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.DeleteUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert response is None
+
+
+def test_delete_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        client.delete_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.DeleteUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_user_async(
+    transport: str = "grpc_asyncio", request_type=service.DeleteUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        response = await client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.DeleteUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert response is None
+
+
+@pytest.mark.asyncio
+async def test_delete_user_async_from_dict():
+    await test_delete_user_async(request_type=dict)
+
+
+def test_delete_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.DeleteUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        call.return_value = None
+        client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_delete_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.DeleteUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        await client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_delete_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = None
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.delete_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_delete_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.delete_user(
+            service.DeleteUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_delete_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = None
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.delete_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_delete_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.delete_user(
+            service.DeleteUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.ListClustersRequest,
         dict,
     ],
 )
 def test_list_clusters_rest(request_type):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -6549,14 +8937,16 @@
     # verify required fields with default values are now present
 
     jsonified_request["name"] = "name_value"
 
     unset_fields = transport_class(
         credentials=ga_credentials.AnonymousCredentials()
     ).get_cluster._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(("view",))
     jsonified_request.update(unset_fields)
 
     # verify required fields with non-default values are left alone
     assert "name" in jsonified_request
     assert jsonified_request["name"] == "name_value"
 
     client = AlloyDBAdminClient(
@@ -6601,15 +8991,15 @@
 
 def test_get_cluster_rest_unset_required_fields():
     transport = transports.AlloyDBAdminRestTransport(
         credentials=ga_credentials.AnonymousCredentials
     )
 
     unset_fields = transport.get_cluster._get_unset_required_fields({})
-    assert set(unset_fields) == (set(()) & set(("name",)))
+    assert set(unset_fields) == (set(("view",)) & set(("name",)))
 
 
 @pytest.mark.parametrize("null_interceptor", [True, False])
 def test_get_cluster_rest_interceptors(null_interceptor):
     transport = transports.AlloyDBAdminRestTransport(
         credentials=ga_credentials.AnonymousCredentials(),
         interceptor=None
@@ -6805,14 +9195,25 @@
         },
         "ssl_config": {"ssl_mode": 1, "ca_source": 1},
         "encryption_config": {},
         "encryption_info": {
             "encryption_type": 1,
             "kms_key_versions": ["kms_key_versions_value1", "kms_key_versions_value2"],
         },
+        "continuous_backup_config": {
+            "enabled": True,
+            "recovery_window_days": 2166,
+            "encryption_config": {},
+        },
+        "continuous_backup_info": {
+            "encryption_info": {},
+            "enabled_time": {},
+            "schedule": [1],
+            "earliest_restorable_time": {},
+        },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
         },
@@ -7067,14 +9468,25 @@
         },
         "ssl_config": {"ssl_mode": 1, "ca_source": 1},
         "encryption_config": {},
         "encryption_info": {
             "encryption_type": 1,
             "kms_key_versions": ["kms_key_versions_value1", "kms_key_versions_value2"],
         },
+        "continuous_backup_config": {
+            "enabled": True,
+            "recovery_window_days": 2166,
+            "encryption_config": {},
+        },
+        "continuous_backup_info": {
+            "encryption_info": {},
+            "enabled_time": {},
+            "schedule": [1],
+            "earliest_restorable_time": {},
+        },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
         },
@@ -7222,14 +9634,25 @@
         },
         "ssl_config": {"ssl_mode": 1, "ca_source": 1},
         "encryption_config": {},
         "encryption_info": {
             "encryption_type": 1,
             "kms_key_versions": ["kms_key_versions_value1", "kms_key_versions_value2"],
         },
+        "continuous_backup_config": {
+            "enabled": True,
+            "recovery_window_days": 2166,
+            "encryption_config": {},
+        },
+        "continuous_backup_info": {
+            "encryption_info": {},
+            "enabled_time": {},
+            "schedule": [1],
+            "earliest_restorable_time": {},
+        },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
         },
@@ -7464,14 +9887,25 @@
         },
         "ssl_config": {"ssl_mode": 1, "ca_source": 1},
         "encryption_config": {},
         "encryption_info": {
             "encryption_type": 1,
             "kms_key_versions": ["kms_key_versions_value1", "kms_key_versions_value2"],
         },
+        "continuous_backup_config": {
+            "enabled": True,
+            "recovery_window_days": 2166,
+            "encryption_config": {},
+        },
+        "continuous_backup_info": {
+            "encryption_info": {},
+            "enabled_time": {},
+            "schedule": [1],
+            "earliest_restorable_time": {},
+        },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
         },
@@ -7835,14 +10269,276 @@
         credentials=ga_credentials.AnonymousCredentials(), transport="rest"
     )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.PromoteClusterRequest,
+        dict,
+    ],
+)
+def test_promote_cluster_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"name": "projects/sample1/locations/sample2/clusters/sample3"}
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.promote_cluster(request)
+
+    # Establish that the response is the type that we expect.
+    assert response.operation.name == "operations/spam"
+
+
+def test_promote_cluster_rest_required_fields(
+    request_type=service.PromoteClusterRequest,
+):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).promote_cluster._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).promote_cluster._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = operations_pb2.Operation(name="operations/spam")
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "post",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+            json_return_value = json_format.MessageToJson(return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.promote_cluster(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_promote_cluster_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.promote_cluster._get_unset_required_fields({})
+    assert set(unset_fields) == (set(()) & set(("name",)))
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_promote_cluster_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        operation.Operation, "_set_result_from_operation"
+    ), mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_promote_cluster"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_promote_cluster"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.PromoteClusterRequest.pb(service.PromoteClusterRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = json_format.MessageToJson(
+            operations_pb2.Operation()
+        )
+
+        request = service.PromoteClusterRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = operations_pb2.Operation()
+
+        client.promote_cluster(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_promote_cluster_rest_bad_request(
+    transport: str = "rest", request_type=service.PromoteClusterRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"name": "projects/sample1/locations/sample2/clusters/sample3"}
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.promote_cluster(request)
+
+
+def test_promote_cluster_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {"name": "projects/sample1/locations/sample2/clusters/sample3"}
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.promote_cluster(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1/{name=projects/*/locations/*/clusters/*}:promote"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_promote_cluster_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.promote_cluster(
+            service.PromoteClusterRequest(),
+            name="name_value",
+        )
+
+
+def test_promote_cluster_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.RestoreClusterRequest,
         dict,
     ],
 )
 def test_restore_cluster_rest(request_type):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -8055,14 +10751,456 @@
         credentials=ga_credentials.AnonymousCredentials(), transport="rest"
     )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.CreateSecondaryClusterRequest,
+        dict,
+    ],
+)
+def test_create_secondary_cluster_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2"}
+    request_init["cluster"] = {
+        "backup_source": {
+            "backup_uid": "backup_uid_value",
+            "backup_name": "backup_name_value",
+        },
+        "migration_source": {
+            "host_port": "host_port_value",
+            "reference_id": "reference_id_value",
+            "source_type": 1,
+        },
+        "name": "name_value",
+        "display_name": "display_name_value",
+        "uid": "uid_value",
+        "create_time": {"seconds": 751, "nanos": 543},
+        "update_time": {},
+        "delete_time": {},
+        "labels": {},
+        "state": 1,
+        "cluster_type": 1,
+        "database_version": 1,
+        "network": "network_value",
+        "etag": "etag_value",
+        "annotations": {},
+        "reconciling": True,
+        "initial_user": {"user": "user_value", "password": "password_value"},
+        "automated_backup_policy": {
+            "weekly_schedule": {
+                "start_times": [
+                    {"hours": 561, "minutes": 773, "seconds": 751, "nanos": 543}
+                ],
+                "days_of_week": [1],
+            },
+            "time_based_retention": {
+                "retention_period": {"seconds": 751, "nanos": 543}
+            },
+            "quantity_based_retention": {"count": 553},
+            "enabled": True,
+            "backup_window": {},
+            "encryption_config": {"kms_key_name": "kms_key_name_value"},
+            "location": "location_value",
+            "labels": {},
+        },
+        "ssl_config": {"ssl_mode": 1, "ca_source": 1},
+        "encryption_config": {},
+        "encryption_info": {
+            "encryption_type": 1,
+            "kms_key_versions": ["kms_key_versions_value1", "kms_key_versions_value2"],
+        },
+        "continuous_backup_config": {
+            "enabled": True,
+            "recovery_window_days": 2166,
+            "encryption_config": {},
+        },
+        "continuous_backup_info": {
+            "encryption_info": {},
+            "enabled_time": {},
+            "schedule": [1],
+            "earliest_restorable_time": {},
+        },
+        "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
+        "primary_config": {
+            "secondary_cluster_names": [
+                "secondary_cluster_names_value1",
+                "secondary_cluster_names_value2",
+            ]
+        },
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.create_secondary_cluster(request)
+
+    # Establish that the response is the type that we expect.
+    assert response.operation.name == "operations/spam"
+
+
+def test_create_secondary_cluster_rest_required_fields(
+    request_type=service.CreateSecondaryClusterRequest,
+):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["parent"] = ""
+    request_init["cluster_id"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+    assert "clusterId" not in jsonified_request
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_secondary_cluster._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+    assert "clusterId" in jsonified_request
+    assert jsonified_request["clusterId"] == request_init["cluster_id"]
+
+    jsonified_request["parent"] = "parent_value"
+    jsonified_request["clusterId"] = "cluster_id_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_secondary_cluster._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "cluster_id",
+            "request_id",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "parent" in jsonified_request
+    assert jsonified_request["parent"] == "parent_value"
+    assert "clusterId" in jsonified_request
+    assert jsonified_request["clusterId"] == "cluster_id_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = operations_pb2.Operation(name="operations/spam")
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "post",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+            json_return_value = json_format.MessageToJson(return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.create_secondary_cluster(request)
+
+            expected_params = [
+                (
+                    "clusterId",
+                    "",
+                ),
+                ("$alt", "json;enum-encoding=int"),
+            ]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_create_secondary_cluster_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.create_secondary_cluster._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "clusterId",
+                "requestId",
+                "validateOnly",
+            )
+        )
+        & set(
+            (
+                "parent",
+                "clusterId",
+                "cluster",
+            )
+        )
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_create_secondary_cluster_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        operation.Operation, "_set_result_from_operation"
+    ), mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_create_secondary_cluster"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_create_secondary_cluster"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.CreateSecondaryClusterRequest.pb(
+            service.CreateSecondaryClusterRequest()
+        )
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = json_format.MessageToJson(
+            operations_pb2.Operation()
+        )
+
+        request = service.CreateSecondaryClusterRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = operations_pb2.Operation()
+
+        client.create_secondary_cluster(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_create_secondary_cluster_rest_bad_request(
+    transport: str = "rest", request_type=service.CreateSecondaryClusterRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2"}
+    request_init["cluster"] = {
+        "backup_source": {
+            "backup_uid": "backup_uid_value",
+            "backup_name": "backup_name_value",
+        },
+        "migration_source": {
+            "host_port": "host_port_value",
+            "reference_id": "reference_id_value",
+            "source_type": 1,
+        },
+        "name": "name_value",
+        "display_name": "display_name_value",
+        "uid": "uid_value",
+        "create_time": {"seconds": 751, "nanos": 543},
+        "update_time": {},
+        "delete_time": {},
+        "labels": {},
+        "state": 1,
+        "cluster_type": 1,
+        "database_version": 1,
+        "network": "network_value",
+        "etag": "etag_value",
+        "annotations": {},
+        "reconciling": True,
+        "initial_user": {"user": "user_value", "password": "password_value"},
+        "automated_backup_policy": {
+            "weekly_schedule": {
+                "start_times": [
+                    {"hours": 561, "minutes": 773, "seconds": 751, "nanos": 543}
+                ],
+                "days_of_week": [1],
+            },
+            "time_based_retention": {
+                "retention_period": {"seconds": 751, "nanos": 543}
+            },
+            "quantity_based_retention": {"count": 553},
+            "enabled": True,
+            "backup_window": {},
+            "encryption_config": {"kms_key_name": "kms_key_name_value"},
+            "location": "location_value",
+            "labels": {},
+        },
+        "ssl_config": {"ssl_mode": 1, "ca_source": 1},
+        "encryption_config": {},
+        "encryption_info": {
+            "encryption_type": 1,
+            "kms_key_versions": ["kms_key_versions_value1", "kms_key_versions_value2"],
+        },
+        "continuous_backup_config": {
+            "enabled": True,
+            "recovery_window_days": 2166,
+            "encryption_config": {},
+        },
+        "continuous_backup_info": {
+            "encryption_info": {},
+            "enabled_time": {},
+            "schedule": [1],
+            "earliest_restorable_time": {},
+        },
+        "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
+        "primary_config": {
+            "secondary_cluster_names": [
+                "secondary_cluster_names_value1",
+                "secondary_cluster_names_value2",
+            ]
+        },
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.create_secondary_cluster(request)
+
+
+def test_create_secondary_cluster_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {"parent": "projects/sample1/locations/sample2"}
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            parent="parent_value",
+            cluster=resources.Cluster(
+                backup_source=resources.BackupSource(backup_uid="backup_uid_value")
+            ),
+            cluster_id="cluster_id_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.create_secondary_cluster(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1/{parent=projects/*/locations/*}/clusters:createsecondary"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_create_secondary_cluster_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_secondary_cluster(
+            service.CreateSecondaryClusterRequest(),
+            parent="parent_value",
+            cluster=resources.Cluster(
+                backup_source=resources.BackupSource(backup_uid="backup_uid_value")
+            ),
+            cluster_id="cluster_id_value",
+        )
+
+
+def test_create_secondary_cluster_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.ListInstancesRequest,
         dict,
     ],
 )
 def test_list_instances_rest(request_type):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -9057,14 +12195,386 @@
         credentials=ga_credentials.AnonymousCredentials(), transport="rest"
     )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.CreateSecondaryInstanceRequest,
+        dict,
+    ],
+)
+def test_create_secondary_instance_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request_init["instance"] = {
+        "name": "name_value",
+        "display_name": "display_name_value",
+        "uid": "uid_value",
+        "create_time": {"seconds": 751, "nanos": 543},
+        "update_time": {},
+        "delete_time": {},
+        "labels": {},
+        "state": 1,
+        "instance_type": 1,
+        "machine_config": {"cpu_count": 976},
+        "availability_type": 1,
+        "gce_zone": "gce_zone_value",
+        "database_flags": {},
+        "writable_node": {
+            "zone_id": "zone_id_value",
+            "id": "id_value",
+            "ip": "ip_value",
+            "state": "state_value",
+        },
+        "nodes": {},
+        "query_insights_config": {
+            "record_application_tags": True,
+            "record_client_address": True,
+            "query_string_length": 2061,
+            "query_plans_per_minute": 2378,
+        },
+        "read_pool_config": {"node_count": 1070},
+        "ip_address": "ip_address_value",
+        "reconciling": True,
+        "etag": "etag_value",
+        "annotations": {},
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.create_secondary_instance(request)
+
+    # Establish that the response is the type that we expect.
+    assert response.operation.name == "operations/spam"
+
+
+def test_create_secondary_instance_rest_required_fields(
+    request_type=service.CreateSecondaryInstanceRequest,
+):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["parent"] = ""
+    request_init["instance_id"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+    assert "instanceId" not in jsonified_request
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_secondary_instance._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+    assert "instanceId" in jsonified_request
+    assert jsonified_request["instanceId"] == request_init["instance_id"]
+
+    jsonified_request["parent"] = "parent_value"
+    jsonified_request["instanceId"] = "instance_id_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_secondary_instance._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "instance_id",
+            "request_id",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "parent" in jsonified_request
+    assert jsonified_request["parent"] == "parent_value"
+    assert "instanceId" in jsonified_request
+    assert jsonified_request["instanceId"] == "instance_id_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = operations_pb2.Operation(name="operations/spam")
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "post",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+            json_return_value = json_format.MessageToJson(return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.create_secondary_instance(request)
+
+            expected_params = [
+                (
+                    "instanceId",
+                    "",
+                ),
+                ("$alt", "json;enum-encoding=int"),
+            ]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_create_secondary_instance_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.create_secondary_instance._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "instanceId",
+                "requestId",
+                "validateOnly",
+            )
+        )
+        & set(
+            (
+                "parent",
+                "instanceId",
+                "instance",
+            )
+        )
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_create_secondary_instance_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        operation.Operation, "_set_result_from_operation"
+    ), mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_create_secondary_instance"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_create_secondary_instance"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.CreateSecondaryInstanceRequest.pb(
+            service.CreateSecondaryInstanceRequest()
+        )
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = json_format.MessageToJson(
+            operations_pb2.Operation()
+        )
+
+        request = service.CreateSecondaryInstanceRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = operations_pb2.Operation()
+
+        client.create_secondary_instance(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_create_secondary_instance_rest_bad_request(
+    transport: str = "rest", request_type=service.CreateSecondaryInstanceRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request_init["instance"] = {
+        "name": "name_value",
+        "display_name": "display_name_value",
+        "uid": "uid_value",
+        "create_time": {"seconds": 751, "nanos": 543},
+        "update_time": {},
+        "delete_time": {},
+        "labels": {},
+        "state": 1,
+        "instance_type": 1,
+        "machine_config": {"cpu_count": 976},
+        "availability_type": 1,
+        "gce_zone": "gce_zone_value",
+        "database_flags": {},
+        "writable_node": {
+            "zone_id": "zone_id_value",
+            "id": "id_value",
+            "ip": "ip_value",
+            "state": "state_value",
+        },
+        "nodes": {},
+        "query_insights_config": {
+            "record_application_tags": True,
+            "record_client_address": True,
+            "query_string_length": 2061,
+            "query_plans_per_minute": 2378,
+        },
+        "read_pool_config": {"node_count": 1070},
+        "ip_address": "ip_address_value",
+        "reconciling": True,
+        "etag": "etag_value",
+        "annotations": {},
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.create_secondary_instance(request)
+
+
+def test_create_secondary_instance_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            parent="parent_value",
+            instance=resources.Instance(name="name_value"),
+            instance_id="instance_id_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.create_secondary_instance(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1/{parent=projects/*/locations/*/clusters/*}/instances:createsecondary"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_create_secondary_instance_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_secondary_instance(
+            service.CreateSecondaryInstanceRequest(),
+            parent="parent_value",
+            instance=resources.Instance(name="name_value"),
+            instance_id="instance_id_value",
+        )
+
+
+def test_create_secondary_instance_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.BatchCreateInstancesRequest,
         dict,
     ],
 )
 def test_batch_create_instances_rest(request_type):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -10272,14 +13782,290 @@
         credentials=ga_credentials.AnonymousCredentials(), transport="rest"
     )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.InjectFaultRequest,
+        dict,
+    ],
+)
+def test_inject_fault_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/instances/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.inject_fault(request)
+
+    # Establish that the response is the type that we expect.
+    assert response.operation.name == "operations/spam"
+
+
+def test_inject_fault_rest_required_fields(request_type=service.InjectFaultRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).inject_fault._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).inject_fault._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = operations_pb2.Operation(name="operations/spam")
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "post",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+            json_return_value = json_format.MessageToJson(return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.inject_fault(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_inject_fault_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.inject_fault._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(())
+        & set(
+            (
+                "faultType",
+                "name",
+            )
+        )
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_inject_fault_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        operation.Operation, "_set_result_from_operation"
+    ), mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_inject_fault"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_inject_fault"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.InjectFaultRequest.pb(service.InjectFaultRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = json_format.MessageToJson(
+            operations_pb2.Operation()
+        )
+
+        request = service.InjectFaultRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = operations_pb2.Operation()
+
+        client.inject_fault(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_inject_fault_rest_bad_request(
+    transport: str = "rest", request_type=service.InjectFaultRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/instances/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.inject_fault(request)
+
+
+def test_inject_fault_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/instances/sample4"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.inject_fault(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1/{name=projects/*/locations/*/clusters/*/instances/*}:injectFault"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_inject_fault_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.inject_fault(
+            service.InjectFaultRequest(),
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+
+def test_inject_fault_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.RestartInstanceRequest,
         dict,
     ],
 )
 def test_restart_instance_rest(request_type):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -12453,14 +16239,1534 @@
         assert all(isinstance(i, resources.SupportedDatabaseFlag) for i in results)
 
         pages = list(client.list_supported_database_flags(request=sample_request).pages)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.ListUsersRequest,
+        dict,
+    ],
+)
+def test_list_users_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = service.ListUsersResponse(
+            next_page_token="next_page_token_value",
+            unreachable=["unreachable_value"],
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = service.ListUsersResponse.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.list_users(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, pagers.ListUsersPager)
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
+
+
+def test_list_users_rest_required_fields(request_type=service.ListUsersRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["parent"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).list_users._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["parent"] = "parent_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).list_users._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "filter",
+            "order_by",
+            "page_size",
+            "page_token",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "parent" in jsonified_request
+    assert jsonified_request["parent"] == "parent_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = service.ListUsersResponse()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "get",
+                "query_params": pb_request,
+            }
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = service.ListUsersResponse.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.list_users(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_list_users_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.list_users._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "filter",
+                "orderBy",
+                "pageSize",
+                "pageToken",
+            )
+        )
+        & set(("parent",))
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_list_users_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_list_users"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_list_users"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.ListUsersRequest.pb(service.ListUsersRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = service.ListUsersResponse.to_json(
+            service.ListUsersResponse()
+        )
+
+        request = service.ListUsersRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = service.ListUsersResponse()
+
+        client.list_users(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_list_users_rest_bad_request(
+    transport: str = "rest", request_type=service.ListUsersRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.list_users(request)
+
+
+def test_list_users_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = service.ListUsersResponse()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            parent="parent_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = service.ListUsersResponse.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.list_users(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1/{parent=projects/*/locations/*/clusters/*}/users"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_list_users_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.list_users(
+            service.ListUsersRequest(),
+            parent="parent_value",
+        )
+
+
+def test_list_users_rest_pager(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # TODO(kbandes): remove this mock unless there's a good reason for it.
+        # with mock.patch.object(path_template, 'transcode') as transcode:
+        # Set the response as a series of pages
+        response = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+        )
+        # Two responses for two calls
+        response = response + response
+
+        # Wrap the values into proper Response objs
+        response = tuple(service.ListUsersResponse.to_json(x) for x in response)
+        return_values = tuple(Response() for i in response)
+        for return_val, response_val in zip(return_values, response):
+            return_val._content = response_val.encode("UTF-8")
+            return_val.status_code = 200
+        req.side_effect = return_values
+
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        pager = client.list_users(request=sample_request)
+
+        results = list(pager)
+        assert len(results) == 6
+        assert all(isinstance(i, resources.User) for i in results)
+
+        pages = list(client.list_users(request=sample_request).pages)
+        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
+            assert page_.raw_page.next_page_token == token
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.GetUserRequest,
+        dict,
+    ],
+)
+def test_get_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.get_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_get_user_rest_required_fields(request_type=service.GetUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).get_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).get_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = resources.User()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "get",
+                "query_params": pb_request,
+            }
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = resources.User.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.get_user(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_get_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.get_user._get_unset_required_fields({})
+    assert set(unset_fields) == (set(()) & set(("name",)))
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_get_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_get_user"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_get_user"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.GetUserRequest.pb(service.GetUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = resources.User.to_json(resources.User())
+
+        request = service.GetUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = resources.User()
+
+        client.get_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_get_user_rest_bad_request(
+    transport: str = "rest", request_type=service.GetUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.get_user(request)
+
+
+def test_get_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.get_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1/{name=projects/*/locations/*/clusters/*/users/*}"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_get_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.get_user(
+            service.GetUserRequest(),
+            name="name_value",
+        )
+
+
+def test_get_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.CreateUserRequest,
+        dict,
+    ],
+)
+def test_create_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request_init["user"] = {
+        "name": "name_value",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.create_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_create_user_rest_required_fields(request_type=service.CreateUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["parent"] = ""
+    request_init["user_id"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+    assert "userId" not in jsonified_request
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+    assert "userId" in jsonified_request
+    assert jsonified_request["userId"] == request_init["user_id"]
+
+    jsonified_request["parent"] = "parent_value"
+    jsonified_request["userId"] = "user_id_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_user._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "request_id",
+            "user_id",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "parent" in jsonified_request
+    assert jsonified_request["parent"] == "parent_value"
+    assert "userId" in jsonified_request
+    assert jsonified_request["userId"] == "user_id_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = resources.User()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "post",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = resources.User.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.create_user(request)
+
+            expected_params = [
+                (
+                    "userId",
+                    "",
+                ),
+                ("$alt", "json;enum-encoding=int"),
+            ]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_create_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.create_user._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "requestId",
+                "userId",
+                "validateOnly",
+            )
+        )
+        & set(
+            (
+                "parent",
+                "userId",
+                "user",
+            )
+        )
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_create_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_create_user"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_create_user"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.CreateUserRequest.pb(service.CreateUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = resources.User.to_json(resources.User())
+
+        request = service.CreateUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = resources.User()
+
+        client.create_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_create_user_rest_bad_request(
+    transport: str = "rest", request_type=service.CreateUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request_init["user"] = {
+        "name": "name_value",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.create_user(request)
+
+
+def test_create_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.create_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1/{parent=projects/*/locations/*/clusters/*}/users"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_create_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_user(
+            service.CreateUserRequest(),
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+
+def test_create_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.UpdateUserRequest,
+        dict,
+    ],
+)
+def test_update_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "user": {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+    }
+    request_init["user"] = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.update_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_update_user_rest_required_fields(request_type=service.UpdateUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).update_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).update_user._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "allow_missing",
+            "request_id",
+            "update_mask",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = resources.User()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "patch",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = resources.User.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.update_user(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_update_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.update_user._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "allowMissing",
+                "requestId",
+                "updateMask",
+                "validateOnly",
+            )
+        )
+        & set(("user",))
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_update_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_update_user"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_update_user"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.UpdateUserRequest.pb(service.UpdateUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = resources.User.to_json(resources.User())
+
+        request = service.UpdateUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = resources.User()
+
+        client.update_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_update_user_rest_bad_request(
+    transport: str = "rest", request_type=service.UpdateUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "user": {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+    }
+    request_init["user"] = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.update_user(request)
+
+
+def test_update_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "user": {
+                "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+            }
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.update_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1/{user.name=projects/*/locations/*/clusters/*/users/*}"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_update_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.update_user(
+            service.UpdateUserRequest(),
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+
+def test_update_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.DeleteUserRequest,
+        dict,
+    ],
+)
+def test_delete_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = None
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = ""
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.delete_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert response is None
+
+
+def test_delete_user_rest_required_fields(request_type=service.DeleteUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).delete_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).delete_user._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "request_id",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = None
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "delete",
+                "query_params": pb_request,
+            }
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+            json_return_value = ""
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.delete_user(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_delete_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.delete_user._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "requestId",
+                "validateOnly",
+            )
+        )
+        & set(("name",))
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_delete_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_delete_user"
+    ) as pre:
+        pre.assert_not_called()
+        pb_message = service.DeleteUserRequest.pb(service.DeleteUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+
+        request = service.DeleteUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+
+        client.delete_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+
+
+def test_delete_user_rest_bad_request(
+    transport: str = "rest", request_type=service.DeleteUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.delete_user(request)
+
+
+def test_delete_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = None
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = ""
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.delete_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1/{name=projects/*/locations/*/clusters/*/users/*}"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_delete_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.delete_user(
+            service.DeleteUserRequest(),
+            name="name_value",
+        )
+
+
+def test_delete_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
 def test_credentials_transport_error():
     # It is an error to provide credentials and a transport instance.
     transport = transports.AlloyDBAdminGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     with pytest.raises(ValueError):
         client = AlloyDBAdminClient(
@@ -12597,29 +17903,38 @@
     # raise NotImplementedError.
     methods = (
         "list_clusters",
         "get_cluster",
         "create_cluster",
         "update_cluster",
         "delete_cluster",
+        "promote_cluster",
         "restore_cluster",
+        "create_secondary_cluster",
         "list_instances",
         "get_instance",
         "create_instance",
+        "create_secondary_instance",
         "batch_create_instances",
         "update_instance",
         "delete_instance",
         "failover_instance",
+        "inject_fault",
         "restart_instance",
         "list_backups",
         "get_backup",
         "create_backup",
         "update_backup",
         "delete_backup",
         "list_supported_database_flags",
+        "list_users",
+        "get_user",
+        "create_user",
+        "update_user",
+        "delete_user",
         "get_location",
         "list_locations",
         "get_operation",
         "cancel_operation",
         "delete_operation",
         "list_operations",
     )
@@ -12910,38 +18225,50 @@
     assert session1 != session2
     session1 = client1.transport.update_cluster._session
     session2 = client2.transport.update_cluster._session
     assert session1 != session2
     session1 = client1.transport.delete_cluster._session
     session2 = client2.transport.delete_cluster._session
     assert session1 != session2
+    session1 = client1.transport.promote_cluster._session
+    session2 = client2.transport.promote_cluster._session
+    assert session1 != session2
     session1 = client1.transport.restore_cluster._session
     session2 = client2.transport.restore_cluster._session
     assert session1 != session2
+    session1 = client1.transport.create_secondary_cluster._session
+    session2 = client2.transport.create_secondary_cluster._session
+    assert session1 != session2
     session1 = client1.transport.list_instances._session
     session2 = client2.transport.list_instances._session
     assert session1 != session2
     session1 = client1.transport.get_instance._session
     session2 = client2.transport.get_instance._session
     assert session1 != session2
     session1 = client1.transport.create_instance._session
     session2 = client2.transport.create_instance._session
     assert session1 != session2
+    session1 = client1.transport.create_secondary_instance._session
+    session2 = client2.transport.create_secondary_instance._session
+    assert session1 != session2
     session1 = client1.transport.batch_create_instances._session
     session2 = client2.transport.batch_create_instances._session
     assert session1 != session2
     session1 = client1.transport.update_instance._session
     session2 = client2.transport.update_instance._session
     assert session1 != session2
     session1 = client1.transport.delete_instance._session
     session2 = client2.transport.delete_instance._session
     assert session1 != session2
     session1 = client1.transport.failover_instance._session
     session2 = client2.transport.failover_instance._session
     assert session1 != session2
+    session1 = client1.transport.inject_fault._session
+    session2 = client2.transport.inject_fault._session
+    assert session1 != session2
     session1 = client1.transport.restart_instance._session
     session2 = client2.transport.restart_instance._session
     assert session1 != session2
     session1 = client1.transport.list_backups._session
     session2 = client2.transport.list_backups._session
     assert session1 != session2
     session1 = client1.transport.get_backup._session
@@ -12955,14 +18282,29 @@
     assert session1 != session2
     session1 = client1.transport.delete_backup._session
     session2 = client2.transport.delete_backup._session
     assert session1 != session2
     session1 = client1.transport.list_supported_database_flags._session
     session2 = client2.transport.list_supported_database_flags._session
     assert session1 != session2
+    session1 = client1.transport.list_users._session
+    session2 = client2.transport.list_users._session
+    assert session1 != session2
+    session1 = client1.transport.get_user._session
+    session2 = client2.transport.get_user._session
+    assert session1 != session2
+    session1 = client1.transport.create_user._session
+    session2 = client2.transport.create_user._session
+    assert session1 != session2
+    session1 = client1.transport.update_user._session
+    session2 = client2.transport.update_user._session
+    assert session1 != session2
+    session1 = client1.transport.delete_user._session
+    session2 = client2.transport.delete_user._session
+    assert session1 != session2
 
 
 def test_alloy_db_admin_grpc_transport_channel():
     channel = grpc.secure_channel("http://localhost/", grpc.local_channel_credentials())
 
     # Check that channel is used if provided.
     transport = transports.AlloyDBAdminGrpcTransport(
@@ -13273,109 +18615,138 @@
     path = AlloyDBAdminClient.supported_database_flag_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_supported_database_flag_path(path)
     assert expected == actual
 
 
+def test_user_path():
+    project = "oyster"
+    location = "nudibranch"
+    cluster = "cuttlefish"
+    user = "mussel"
+    expected = "projects/{project}/locations/{location}/clusters/{cluster}/users/{user}".format(
+        project=project,
+        location=location,
+        cluster=cluster,
+        user=user,
+    )
+    actual = AlloyDBAdminClient.user_path(project, location, cluster, user)
+    assert expected == actual
+
+
+def test_parse_user_path():
+    expected = {
+        "project": "winkle",
+        "location": "nautilus",
+        "cluster": "scallop",
+        "user": "abalone",
+    }
+    path = AlloyDBAdminClient.user_path(**expected)
+
+    # Check that the path construction is reversible.
+    actual = AlloyDBAdminClient.parse_user_path(path)
+    assert expected == actual
+
+
 def test_common_billing_account_path():
-    billing_account = "oyster"
+    billing_account = "squid"
     expected = "billingAccounts/{billing_account}".format(
         billing_account=billing_account,
     )
     actual = AlloyDBAdminClient.common_billing_account_path(billing_account)
     assert expected == actual
 
 
 def test_parse_common_billing_account_path():
     expected = {
-        "billing_account": "nudibranch",
+        "billing_account": "clam",
     }
     path = AlloyDBAdminClient.common_billing_account_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_billing_account_path(path)
     assert expected == actual
 
 
 def test_common_folder_path():
-    folder = "cuttlefish"
+    folder = "whelk"
     expected = "folders/{folder}".format(
         folder=folder,
     )
     actual = AlloyDBAdminClient.common_folder_path(folder)
     assert expected == actual
 
 
 def test_parse_common_folder_path():
     expected = {
-        "folder": "mussel",
+        "folder": "octopus",
     }
     path = AlloyDBAdminClient.common_folder_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_folder_path(path)
     assert expected == actual
 
 
 def test_common_organization_path():
-    organization = "winkle"
+    organization = "oyster"
     expected = "organizations/{organization}".format(
         organization=organization,
     )
     actual = AlloyDBAdminClient.common_organization_path(organization)
     assert expected == actual
 
 
 def test_parse_common_organization_path():
     expected = {
-        "organization": "nautilus",
+        "organization": "nudibranch",
     }
     path = AlloyDBAdminClient.common_organization_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_organization_path(path)
     assert expected == actual
 
 
 def test_common_project_path():
-    project = "scallop"
+    project = "cuttlefish"
     expected = "projects/{project}".format(
         project=project,
     )
     actual = AlloyDBAdminClient.common_project_path(project)
     assert expected == actual
 
 
 def test_parse_common_project_path():
     expected = {
-        "project": "abalone",
+        "project": "mussel",
     }
     path = AlloyDBAdminClient.common_project_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_project_path(path)
     assert expected == actual
 
 
 def test_common_location_path():
-    project = "squid"
-    location = "clam"
+    project = "winkle"
+    location = "nautilus"
     expected = "projects/{project}/locations/{location}".format(
         project=project,
         location=location,
     )
     actual = AlloyDBAdminClient.common_location_path(project, location)
     assert expected == actual
 
 
 def test_parse_common_location_path():
     expected = {
-        "project": "whelk",
-        "location": "octopus",
+        "project": "scallop",
+        "location": "abalone",
     }
     path = AlloyDBAdminClient.common_location_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_location_path(path)
     assert expected == actual
```

### Comparing `google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1alpha/test_alloy_db_admin.py` & `google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1alpha/test_alloy_db_admin.py`

 * *Files 7% similar despite different names*

```diff
@@ -4817,14 +4817,250 @@
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.InjectFaultRequest,
+        dict,
+    ],
+)
+def test_inject_fault(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/spam")
+        response = client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.InjectFaultRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+def test_inject_fault_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        client.inject_fault()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.InjectFaultRequest()
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_async(
+    transport: str = "grpc_asyncio", request_type=service.InjectFaultRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.InjectFaultRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_async_from_dict():
+    await test_inject_fault_async(request_type=dict)
+
+
+def test_inject_fault_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.InjectFaultRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.InjectFaultRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/op")
+        )
+        await client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_inject_fault_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.inject_fault(
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].fault_type
+        mock_val = service.InjectFaultRequest.FaultType.STOP_VM
+        assert arg == mock_val
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_inject_fault_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.inject_fault(
+            service.InjectFaultRequest(),
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.inject_fault(
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].fault_type
+        mock_val = service.InjectFaultRequest.FaultType.STOP_VM
+        assert arg == mock_val
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.inject_fault(
+            service.InjectFaultRequest(),
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.RestartInstanceRequest,
         dict,
     ],
 )
 def test_restart_instance(request_type, transport: str = "grpc"):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -6908,26 +7144,28 @@
     with mock.patch.object(
         type(client.transport.generate_client_certificate), "__call__"
     ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = service.GenerateClientCertificateResponse(
             pem_certificate="pem_certificate_value",
             pem_certificate_chain=["pem_certificate_chain_value"],
+            ca_cert="ca_cert_value",
         )
         response = client.generate_client_certificate(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == service.GenerateClientCertificateRequest()
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, service.GenerateClientCertificateResponse)
     assert response.pem_certificate == "pem_certificate_value"
     assert response.pem_certificate_chain == ["pem_certificate_chain_value"]
+    assert response.ca_cert == "ca_cert_value"
 
 
 def test_generate_client_certificate_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -6963,27 +7201,29 @@
         type(client.transport.generate_client_certificate), "__call__"
     ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             service.GenerateClientCertificateResponse(
                 pem_certificate="pem_certificate_value",
                 pem_certificate_chain=["pem_certificate_chain_value"],
+                ca_cert="ca_cert_value",
             )
         )
         response = await client.generate_client_certificate(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == service.GenerateClientCertificateRequest()
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, service.GenerateClientCertificateResponse)
     assert response.pem_certificate == "pem_certificate_value"
     assert response.pem_certificate_chain == ["pem_certificate_chain_value"]
+    assert response.ca_cert == "ca_cert_value"
 
 
 @pytest.mark.asyncio
 async def test_generate_client_certificate_async_from_dict():
     await test_generate_client_certificate_async(request_type=dict)
 
 
@@ -7395,14 +7635,1408 @@
             parent="parent_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.ListUsersRequest,
+        dict,
+    ],
+)
+def test_list_users(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = service.ListUsersResponse(
+            next_page_token="next_page_token_value",
+            unreachable=["unreachable_value"],
+        )
+        response = client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.ListUsersRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, pagers.ListUsersPager)
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
+
+
+def test_list_users_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        client.list_users()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.ListUsersRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_users_async(
+    transport: str = "grpc_asyncio", request_type=service.ListUsersRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            service.ListUsersResponse(
+                next_page_token="next_page_token_value",
+                unreachable=["unreachable_value"],
+            )
+        )
+        response = await client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.ListUsersRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, pagers.ListUsersAsyncPager)
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
+
+
+@pytest.mark.asyncio
+async def test_list_users_async_from_dict():
+    await test_list_users_async(request_type=dict)
+
+
+def test_list_users_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.ListUsersRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        call.return_value = service.ListUsersResponse()
+        client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_list_users_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.ListUsersRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            service.ListUsersResponse()
+        )
+        await client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+def test_list_users_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = service.ListUsersResponse()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.list_users(
+            parent="parent_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+
+
+def test_list_users_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.list_users(
+            service.ListUsersRequest(),
+            parent="parent_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_list_users_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = service.ListUsersResponse()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            service.ListUsersResponse()
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.list_users(
+            parent="parent_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_list_users_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.list_users(
+            service.ListUsersRequest(),
+            parent="parent_value",
+        )
+
+
+def test_list_users_pager(transport_name: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials,
+        transport=transport_name,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+
+        metadata = ()
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
+        )
+        pager = client.list_users(request={})
+
+        assert pager._metadata == metadata
+
+        results = list(pager)
+        assert len(results) == 6
+        assert all(isinstance(i, resources.User) for i in results)
+
+
+def test_list_users_pages(transport_name: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials,
+        transport=transport_name,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+        pages = list(client.list_users(request={}).pages)
+        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
+            assert page_.raw_page.next_page_token == token
+
+
+@pytest.mark.asyncio
+async def test_list_users_async_pager():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_users), "__call__", new_callable=mock.AsyncMock
+    ) as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+        async_pager = await client.list_users(
+            request={},
+        )
+        assert async_pager.next_page_token == "abc"
+        responses = []
+        async for response in async_pager:  # pragma: no branch
+            responses.append(response)
+
+        assert len(responses) == 6
+        assert all(isinstance(i, resources.User) for i in responses)
+
+
+@pytest.mark.asyncio
+async def test_list_users_async_pages():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_users), "__call__", new_callable=mock.AsyncMock
+    ) as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+        pages = []
+        async for page_ in (
+            await client.list_users(request={})
+        ).pages:  # pragma: no branch
+            pages.append(page_)
+        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
+            assert page_.raw_page.next_page_token == token
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.GetUserRequest,
+        dict,
+    ],
+)
+def test_get_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+        response = client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.GetUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_get_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        client.get_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.GetUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_user_async(
+    transport: str = "grpc_asyncio", request_type=service.GetUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            resources.User(
+                name="name_value",
+                password="password_value",
+                database_roles=["database_roles_value"],
+                user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+            )
+        )
+        response = await client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.GetUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+@pytest.mark.asyncio
+async def test_get_user_async_from_dict():
+    await test_get_user_async(request_type=dict)
+
+
+def test_get_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.GetUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        call.return_value = resources.User()
+        client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_get_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.GetUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        await client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_get_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.get_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_get_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.get_user(
+            service.GetUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_get_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.get_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_get_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.get_user(
+            service.GetUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.CreateUserRequest,
+        dict,
+    ],
+)
+def test_create_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+        response = client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_create_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        client.create_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_user_async(
+    transport: str = "grpc_asyncio", request_type=service.CreateUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            resources.User(
+                name="name_value",
+                password="password_value",
+                database_roles=["database_roles_value"],
+                user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+            )
+        )
+        response = await client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+@pytest.mark.asyncio
+async def test_create_user_async_from_dict():
+    await test_create_user_async(request_type=dict)
+
+
+def test_create_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateUserRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        call.return_value = resources.User()
+        client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_create_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateUserRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        await client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+def test_create_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.create_user(
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].user_id
+        mock_val = "user_id_value"
+        assert arg == mock_val
+
+
+def test_create_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_user(
+            service.CreateUserRequest(),
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_create_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.create_user(
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].user_id
+        mock_val = "user_id_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_create_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.create_user(
+            service.CreateUserRequest(),
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.UpdateUserRequest,
+        dict,
+    ],
+)
+def test_update_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+        response = client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.UpdateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_update_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        client.update_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.UpdateUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_user_async(
+    transport: str = "grpc_asyncio", request_type=service.UpdateUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            resources.User(
+                name="name_value",
+                password="password_value",
+                database_roles=["database_roles_value"],
+                user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+            )
+        )
+        response = await client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.UpdateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+@pytest.mark.asyncio
+async def test_update_user_async_from_dict():
+    await test_update_user_async(request_type=dict)
+
+
+def test_update_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.UpdateUserRequest()
+
+    request.user.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        call.return_value = resources.User()
+        client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "user.name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_update_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.UpdateUserRequest()
+
+    request.user.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        await client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "user.name=name_value",
+    ) in kw["metadata"]
+
+
+def test_update_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.update_user(
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].update_mask
+        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
+        assert arg == mock_val
+
+
+def test_update_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.update_user(
+            service.UpdateUserRequest(),
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+
+@pytest.mark.asyncio
+async def test_update_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.update_user(
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].update_mask
+        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_update_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.update_user(
+            service.UpdateUserRequest(),
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.DeleteUserRequest,
+        dict,
+    ],
+)
+def test_delete_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = None
+        response = client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.DeleteUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert response is None
+
+
+def test_delete_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        client.delete_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.DeleteUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_user_async(
+    transport: str = "grpc_asyncio", request_type=service.DeleteUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        response = await client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.DeleteUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert response is None
+
+
+@pytest.mark.asyncio
+async def test_delete_user_async_from_dict():
+    await test_delete_user_async(request_type=dict)
+
+
+def test_delete_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.DeleteUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        call.return_value = None
+        client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_delete_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.DeleteUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        await client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_delete_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = None
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.delete_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_delete_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.delete_user(
+            service.DeleteUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_delete_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = None
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.delete_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_delete_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.delete_user(
+            service.DeleteUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.ListClustersRequest,
         dict,
     ],
 )
 def test_list_clusters_rest(request_type):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -7817,14 +9451,16 @@
     # verify required fields with default values are now present
 
     jsonified_request["name"] = "name_value"
 
     unset_fields = transport_class(
         credentials=ga_credentials.AnonymousCredentials()
     ).get_cluster._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(("view",))
     jsonified_request.update(unset_fields)
 
     # verify required fields with non-default values are left alone
     assert "name" in jsonified_request
     assert jsonified_request["name"] == "name_value"
 
     client = AlloyDBAdminClient(
@@ -7869,15 +9505,15 @@
 
 def test_get_cluster_rest_unset_required_fields():
     transport = transports.AlloyDBAdminRestTransport(
         credentials=ga_credentials.AnonymousCredentials
     )
 
     unset_fields = transport.get_cluster._get_unset_required_fields({})
-    assert set(unset_fields) == (set(()) & set(("name",)))
+    assert set(unset_fields) == (set(("view",)) & set(("name",)))
 
 
 @pytest.mark.parametrize("null_interceptor", [True, False])
 def test_get_cluster_rest_interceptors(null_interceptor):
     transport = transports.AlloyDBAdminRestTransport(
         credentials=ga_credentials.AnonymousCredentials(),
         interceptor=None
@@ -8046,14 +9682,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -8083,14 +9723,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -8318,14 +9959,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -8355,14 +10000,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -8484,14 +10130,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -8521,14 +10171,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -8736,14 +10387,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -8773,14 +10428,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -9660,14 +11316,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -9697,14 +11357,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -9936,14 +11597,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -9973,14 +11638,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -10744,14 +12410,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a response.
     with mock.patch.object(type(client.transport._session), "request") as req:
         # Designate an appropriate value for the returned response.
         return_value = operations_pb2.Operation(name="operations/spam")
@@ -10985,14 +12652,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a BadRequest error.
     with mock.patch.object(Session, "request") as req, pytest.raises(
         core_exceptions.BadRequest
     ):
@@ -11114,14 +12782,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a response.
     with mock.patch.object(type(client.transport._session), "request") as req:
         # Designate an appropriate value for the returned response.
         return_value = operations_pb2.Operation(name="operations/spam")
@@ -11357,14 +13026,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a BadRequest error.
     with mock.patch.object(Session, "request") as req, pytest.raises(
         core_exceptions.BadRequest
     ):
@@ -11491,14 +13161,15 @@
                         "query_plans_per_minute": 2378,
                     },
                     "read_pool_config": {"node_count": 1070},
                     "ip_address": "ip_address_value",
                     "reconciling": True,
                     "etag": "etag_value",
                     "annotations": {},
+                    "update_policy": {"mode": 1},
                 },
                 "request_id": "request_id_value",
                 "validate_only": True,
             }
         ]
     }
     request = request_type(**request_init)
@@ -11718,14 +13389,15 @@
                         "query_plans_per_minute": 2378,
                     },
                     "read_pool_config": {"node_count": 1070},
                     "ip_address": "ip_address_value",
                     "reconciling": True,
                     "etag": "etag_value",
                     "annotations": {},
+                    "update_policy": {"mode": 1},
                 },
                 "request_id": "request_id_value",
                 "validate_only": True,
             }
         ]
     }
     request = request_type(**request_init)
@@ -11795,14 +13467,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a response.
     with mock.patch.object(type(client.transport._session), "request") as req:
         # Designate an appropriate value for the returned response.
         return_value = operations_pb2.Operation(name="operations/spam")
@@ -12018,14 +13691,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a BadRequest error.
     with mock.patch.object(Session, "request") as req, pytest.raises(
         core_exceptions.BadRequest
     ):
@@ -12657,14 +14331,290 @@
         credentials=ga_credentials.AnonymousCredentials(), transport="rest"
     )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.InjectFaultRequest,
+        dict,
+    ],
+)
+def test_inject_fault_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/instances/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.inject_fault(request)
+
+    # Establish that the response is the type that we expect.
+    assert response.operation.name == "operations/spam"
+
+
+def test_inject_fault_rest_required_fields(request_type=service.InjectFaultRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).inject_fault._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).inject_fault._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = operations_pb2.Operation(name="operations/spam")
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "post",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+            json_return_value = json_format.MessageToJson(return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.inject_fault(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_inject_fault_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.inject_fault._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(())
+        & set(
+            (
+                "faultType",
+                "name",
+            )
+        )
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_inject_fault_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        operation.Operation, "_set_result_from_operation"
+    ), mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_inject_fault"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_inject_fault"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.InjectFaultRequest.pb(service.InjectFaultRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = json_format.MessageToJson(
+            operations_pb2.Operation()
+        )
+
+        request = service.InjectFaultRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = operations_pb2.Operation()
+
+        client.inject_fault(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_inject_fault_rest_bad_request(
+    transport: str = "rest", request_type=service.InjectFaultRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/instances/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.inject_fault(request)
+
+
+def test_inject_fault_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/instances/sample4"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.inject_fault(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1alpha/{name=projects/*/locations/*/clusters/*/instances/*}:injectFault"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_inject_fault_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.inject_fault(
+            service.InjectFaultRequest(),
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+
+def test_inject_fault_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.RestartInstanceRequest,
         dict,
     ],
 )
 def test_restart_instance_rest(request_type):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -14865,14 +16815,15 @@
 
     # Mock the http request call within the method and fake a response.
     with mock.patch.object(type(client.transport._session), "request") as req:
         # Designate an appropriate value for the returned response.
         return_value = service.GenerateClientCertificateResponse(
             pem_certificate="pem_certificate_value",
             pem_certificate_chain=["pem_certificate_chain_value"],
+            ca_cert="ca_cert_value",
         )
 
         # Wrap the value into a proper Response obj
         response_value = Response()
         response_value.status_code = 200
         pb_return_value = service.GenerateClientCertificateResponse.pb(return_value)
         json_return_value = json_format.MessageToJson(pb_return_value)
@@ -14881,14 +16832,15 @@
         req.return_value = response_value
         response = client.generate_client_certificate(request)
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, service.GenerateClientCertificateResponse)
     assert response.pem_certificate == "pem_certificate_value"
     assert response.pem_certificate_chain == ["pem_certificate_chain_value"]
+    assert response.ca_cert == "ca_cert_value"
 
 
 def test_generate_client_certificate_rest_required_fields(
     request_type=service.GenerateClientCertificateRequest,
 ):
     transport_class = transports.AlloyDBAdminRestTransport
 
@@ -15397,14 +17349,1534 @@
 
 def test_get_connection_info_rest_error():
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(), transport="rest"
     )
 
 
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.ListUsersRequest,
+        dict,
+    ],
+)
+def test_list_users_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = service.ListUsersResponse(
+            next_page_token="next_page_token_value",
+            unreachable=["unreachable_value"],
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = service.ListUsersResponse.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.list_users(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, pagers.ListUsersPager)
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
+
+
+def test_list_users_rest_required_fields(request_type=service.ListUsersRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["parent"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).list_users._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["parent"] = "parent_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).list_users._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "filter",
+            "order_by",
+            "page_size",
+            "page_token",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "parent" in jsonified_request
+    assert jsonified_request["parent"] == "parent_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = service.ListUsersResponse()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "get",
+                "query_params": pb_request,
+            }
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = service.ListUsersResponse.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.list_users(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_list_users_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.list_users._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "filter",
+                "orderBy",
+                "pageSize",
+                "pageToken",
+            )
+        )
+        & set(("parent",))
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_list_users_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_list_users"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_list_users"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.ListUsersRequest.pb(service.ListUsersRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = service.ListUsersResponse.to_json(
+            service.ListUsersResponse()
+        )
+
+        request = service.ListUsersRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = service.ListUsersResponse()
+
+        client.list_users(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_list_users_rest_bad_request(
+    transport: str = "rest", request_type=service.ListUsersRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.list_users(request)
+
+
+def test_list_users_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = service.ListUsersResponse()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            parent="parent_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = service.ListUsersResponse.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.list_users(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1alpha/{parent=projects/*/locations/*/clusters/*}/users"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_list_users_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.list_users(
+            service.ListUsersRequest(),
+            parent="parent_value",
+        )
+
+
+def test_list_users_rest_pager(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # TODO(kbandes): remove this mock unless there's a good reason for it.
+        # with mock.patch.object(path_template, 'transcode') as transcode:
+        # Set the response as a series of pages
+        response = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+        )
+        # Two responses for two calls
+        response = response + response
+
+        # Wrap the values into proper Response objs
+        response = tuple(service.ListUsersResponse.to_json(x) for x in response)
+        return_values = tuple(Response() for i in response)
+        for return_val, response_val in zip(return_values, response):
+            return_val._content = response_val.encode("UTF-8")
+            return_val.status_code = 200
+        req.side_effect = return_values
+
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        pager = client.list_users(request=sample_request)
+
+        results = list(pager)
+        assert len(results) == 6
+        assert all(isinstance(i, resources.User) for i in results)
+
+        pages = list(client.list_users(request=sample_request).pages)
+        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
+            assert page_.raw_page.next_page_token == token
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.GetUserRequest,
+        dict,
+    ],
+)
+def test_get_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.get_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_get_user_rest_required_fields(request_type=service.GetUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).get_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).get_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = resources.User()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "get",
+                "query_params": pb_request,
+            }
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = resources.User.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.get_user(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_get_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.get_user._get_unset_required_fields({})
+    assert set(unset_fields) == (set(()) & set(("name",)))
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_get_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_get_user"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_get_user"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.GetUserRequest.pb(service.GetUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = resources.User.to_json(resources.User())
+
+        request = service.GetUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = resources.User()
+
+        client.get_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_get_user_rest_bad_request(
+    transport: str = "rest", request_type=service.GetUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.get_user(request)
+
+
+def test_get_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.get_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1alpha/{name=projects/*/locations/*/clusters/*/users/*}"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_get_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.get_user(
+            service.GetUserRequest(),
+            name="name_value",
+        )
+
+
+def test_get_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.CreateUserRequest,
+        dict,
+    ],
+)
+def test_create_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request_init["user"] = {
+        "name": "name_value",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.create_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_create_user_rest_required_fields(request_type=service.CreateUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["parent"] = ""
+    request_init["user_id"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+    assert "userId" not in jsonified_request
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+    assert "userId" in jsonified_request
+    assert jsonified_request["userId"] == request_init["user_id"]
+
+    jsonified_request["parent"] = "parent_value"
+    jsonified_request["userId"] = "user_id_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_user._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "request_id",
+            "user_id",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "parent" in jsonified_request
+    assert jsonified_request["parent"] == "parent_value"
+    assert "userId" in jsonified_request
+    assert jsonified_request["userId"] == "user_id_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = resources.User()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "post",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = resources.User.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.create_user(request)
+
+            expected_params = [
+                (
+                    "userId",
+                    "",
+                ),
+                ("$alt", "json;enum-encoding=int"),
+            ]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_create_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.create_user._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "requestId",
+                "userId",
+                "validateOnly",
+            )
+        )
+        & set(
+            (
+                "parent",
+                "userId",
+                "user",
+            )
+        )
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_create_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_create_user"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_create_user"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.CreateUserRequest.pb(service.CreateUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = resources.User.to_json(resources.User())
+
+        request = service.CreateUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = resources.User()
+
+        client.create_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_create_user_rest_bad_request(
+    transport: str = "rest", request_type=service.CreateUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request_init["user"] = {
+        "name": "name_value",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.create_user(request)
+
+
+def test_create_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.create_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1alpha/{parent=projects/*/locations/*/clusters/*}/users"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_create_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_user(
+            service.CreateUserRequest(),
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+
+def test_create_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.UpdateUserRequest,
+        dict,
+    ],
+)
+def test_update_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "user": {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+    }
+    request_init["user"] = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.update_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_update_user_rest_required_fields(request_type=service.UpdateUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).update_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).update_user._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "allow_missing",
+            "request_id",
+            "update_mask",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = resources.User()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "patch",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = resources.User.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.update_user(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_update_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.update_user._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "allowMissing",
+                "requestId",
+                "updateMask",
+                "validateOnly",
+            )
+        )
+        & set(("user",))
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_update_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_update_user"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_update_user"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.UpdateUserRequest.pb(service.UpdateUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = resources.User.to_json(resources.User())
+
+        request = service.UpdateUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = resources.User()
+
+        client.update_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_update_user_rest_bad_request(
+    transport: str = "rest", request_type=service.UpdateUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "user": {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+    }
+    request_init["user"] = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.update_user(request)
+
+
+def test_update_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "user": {
+                "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+            }
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.update_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1alpha/{user.name=projects/*/locations/*/clusters/*/users/*}"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_update_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.update_user(
+            service.UpdateUserRequest(),
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+
+def test_update_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.DeleteUserRequest,
+        dict,
+    ],
+)
+def test_delete_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = None
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = ""
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.delete_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert response is None
+
+
+def test_delete_user_rest_required_fields(request_type=service.DeleteUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).delete_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).delete_user._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "request_id",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = None
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "delete",
+                "query_params": pb_request,
+            }
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+            json_return_value = ""
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.delete_user(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_delete_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.delete_user._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "requestId",
+                "validateOnly",
+            )
+        )
+        & set(("name",))
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_delete_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_delete_user"
+    ) as pre:
+        pre.assert_not_called()
+        pb_message = service.DeleteUserRequest.pb(service.DeleteUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+
+        request = service.DeleteUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+
+        client.delete_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+
+
+def test_delete_user_rest_bad_request(
+    transport: str = "rest", request_type=service.DeleteUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.delete_user(request)
+
+
+def test_delete_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = None
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = ""
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.delete_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1alpha/{name=projects/*/locations/*/clusters/*/users/*}"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_delete_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.delete_user(
+            service.DeleteUserRequest(),
+            name="name_value",
+        )
+
+
+def test_delete_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
 def test_credentials_transport_error():
     # It is an error to provide credentials and a transport instance.
     transport = transports.AlloyDBAdminGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     with pytest.raises(ValueError):
         client = AlloyDBAdminClient(
@@ -15552,23 +19024,29 @@
         "get_instance",
         "create_instance",
         "create_secondary_instance",
         "batch_create_instances",
         "update_instance",
         "delete_instance",
         "failover_instance",
+        "inject_fault",
         "restart_instance",
         "list_backups",
         "get_backup",
         "create_backup",
         "update_backup",
         "delete_backup",
         "list_supported_database_flags",
         "generate_client_certificate",
         "get_connection_info",
+        "list_users",
+        "get_user",
+        "create_user",
+        "update_user",
+        "delete_user",
         "get_location",
         "list_locations",
         "get_operation",
         "cancel_operation",
         "delete_operation",
         "list_operations",
     )
@@ -15892,14 +19370,17 @@
     assert session1 != session2
     session1 = client1.transport.delete_instance._session
     session2 = client2.transport.delete_instance._session
     assert session1 != session2
     session1 = client1.transport.failover_instance._session
     session2 = client2.transport.failover_instance._session
     assert session1 != session2
+    session1 = client1.transport.inject_fault._session
+    session2 = client2.transport.inject_fault._session
+    assert session1 != session2
     session1 = client1.transport.restart_instance._session
     session2 = client2.transport.restart_instance._session
     assert session1 != session2
     session1 = client1.transport.list_backups._session
     session2 = client2.transport.list_backups._session
     assert session1 != session2
     session1 = client1.transport.get_backup._session
@@ -15919,14 +19400,29 @@
     assert session1 != session2
     session1 = client1.transport.generate_client_certificate._session
     session2 = client2.transport.generate_client_certificate._session
     assert session1 != session2
     session1 = client1.transport.get_connection_info._session
     session2 = client2.transport.get_connection_info._session
     assert session1 != session2
+    session1 = client1.transport.list_users._session
+    session2 = client2.transport.list_users._session
+    assert session1 != session2
+    session1 = client1.transport.get_user._session
+    session2 = client2.transport.get_user._session
+    assert session1 != session2
+    session1 = client1.transport.create_user._session
+    session2 = client2.transport.create_user._session
+    assert session1 != session2
+    session1 = client1.transport.update_user._session
+    session2 = client2.transport.update_user._session
+    assert session1 != session2
+    session1 = client1.transport.delete_user._session
+    session2 = client2.transport.delete_user._session
+    assert session1 != session2
 
 
 def test_alloy_db_admin_grpc_transport_channel():
     channel = grpc.secure_channel("http://localhost/", grpc.local_channel_credentials())
 
     # Check that channel is used if provided.
     transport = transports.AlloyDBAdminGrpcTransport(
@@ -16268,109 +19764,138 @@
     path = AlloyDBAdminClient.supported_database_flag_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_supported_database_flag_path(path)
     assert expected == actual
 
 
+def test_user_path():
+    project = "squid"
+    location = "clam"
+    cluster = "whelk"
+    user = "octopus"
+    expected = "projects/{project}/locations/{location}/clusters/{cluster}/users/{user}".format(
+        project=project,
+        location=location,
+        cluster=cluster,
+        user=user,
+    )
+    actual = AlloyDBAdminClient.user_path(project, location, cluster, user)
+    assert expected == actual
+
+
+def test_parse_user_path():
+    expected = {
+        "project": "oyster",
+        "location": "nudibranch",
+        "cluster": "cuttlefish",
+        "user": "mussel",
+    }
+    path = AlloyDBAdminClient.user_path(**expected)
+
+    # Check that the path construction is reversible.
+    actual = AlloyDBAdminClient.parse_user_path(path)
+    assert expected == actual
+
+
 def test_common_billing_account_path():
-    billing_account = "squid"
+    billing_account = "winkle"
     expected = "billingAccounts/{billing_account}".format(
         billing_account=billing_account,
     )
     actual = AlloyDBAdminClient.common_billing_account_path(billing_account)
     assert expected == actual
 
 
 def test_parse_common_billing_account_path():
     expected = {
-        "billing_account": "clam",
+        "billing_account": "nautilus",
     }
     path = AlloyDBAdminClient.common_billing_account_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_billing_account_path(path)
     assert expected == actual
 
 
 def test_common_folder_path():
-    folder = "whelk"
+    folder = "scallop"
     expected = "folders/{folder}".format(
         folder=folder,
     )
     actual = AlloyDBAdminClient.common_folder_path(folder)
     assert expected == actual
 
 
 def test_parse_common_folder_path():
     expected = {
-        "folder": "octopus",
+        "folder": "abalone",
     }
     path = AlloyDBAdminClient.common_folder_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_folder_path(path)
     assert expected == actual
 
 
 def test_common_organization_path():
-    organization = "oyster"
+    organization = "squid"
     expected = "organizations/{organization}".format(
         organization=organization,
     )
     actual = AlloyDBAdminClient.common_organization_path(organization)
     assert expected == actual
 
 
 def test_parse_common_organization_path():
     expected = {
-        "organization": "nudibranch",
+        "organization": "clam",
     }
     path = AlloyDBAdminClient.common_organization_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_organization_path(path)
     assert expected == actual
 
 
 def test_common_project_path():
-    project = "cuttlefish"
+    project = "whelk"
     expected = "projects/{project}".format(
         project=project,
     )
     actual = AlloyDBAdminClient.common_project_path(project)
     assert expected == actual
 
 
 def test_parse_common_project_path():
     expected = {
-        "project": "mussel",
+        "project": "octopus",
     }
     path = AlloyDBAdminClient.common_project_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_project_path(path)
     assert expected == actual
 
 
 def test_common_location_path():
-    project = "winkle"
-    location = "nautilus"
+    project = "oyster"
+    location = "nudibranch"
     expected = "projects/{project}/locations/{location}".format(
         project=project,
         location=location,
     )
     actual = AlloyDBAdminClient.common_location_path(project, location)
     assert expected == actual
 
 
 def test_parse_common_location_path():
     expected = {
-        "project": "scallop",
-        "location": "abalone",
+        "project": "cuttlefish",
+        "location": "mussel",
     }
     path = AlloyDBAdminClient.common_location_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_location_path(path)
     assert expected == actual
```

### Comparing `google-cloud-alloydb-0.1.1/tests/unit/gapic/alloydb_v1beta/test_alloy_db_admin.py` & `google-cloud-alloydb-0.2.0/tests/unit/gapic/alloydb_v1beta/test_alloy_db_admin.py`

 * *Files 7% similar despite different names*

```diff
@@ -4817,14 +4817,250 @@
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.InjectFaultRequest,
+        dict,
+    ],
+)
+def test_inject_fault(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/spam")
+        response = client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.InjectFaultRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+def test_inject_fault_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        client.inject_fault()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.InjectFaultRequest()
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_async(
+    transport: str = "grpc_asyncio", request_type=service.InjectFaultRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.InjectFaultRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, future.Future)
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_async_from_dict():
+    await test_inject_fault_async(request_type=dict)
+
+
+def test_inject_fault_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.InjectFaultRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.InjectFaultRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/op")
+        )
+        await client.inject_fault(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_inject_fault_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.inject_fault(
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].fault_type
+        mock_val = service.InjectFaultRequest.FaultType.STOP_VM
+        assert arg == mock_val
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_inject_fault_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.inject_fault(
+            service.InjectFaultRequest(),
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.inject_fault), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = operations_pb2.Operation(name="operations/op")
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.inject_fault(
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].fault_type
+        mock_val = service.InjectFaultRequest.FaultType.STOP_VM
+        assert arg == mock_val
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_inject_fault_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.inject_fault(
+            service.InjectFaultRequest(),
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.RestartInstanceRequest,
         dict,
     ],
 )
 def test_restart_instance(request_type, transport: str = "grpc"):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -6908,26 +7144,28 @@
     with mock.patch.object(
         type(client.transport.generate_client_certificate), "__call__"
     ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = service.GenerateClientCertificateResponse(
             pem_certificate="pem_certificate_value",
             pem_certificate_chain=["pem_certificate_chain_value"],
+            ca_cert="ca_cert_value",
         )
         response = client.generate_client_certificate(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == service.GenerateClientCertificateRequest()
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, service.GenerateClientCertificateResponse)
     assert response.pem_certificate == "pem_certificate_value"
     assert response.pem_certificate_chain == ["pem_certificate_chain_value"]
+    assert response.ca_cert == "ca_cert_value"
 
 
 def test_generate_client_certificate_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -6963,27 +7201,29 @@
         type(client.transport.generate_client_certificate), "__call__"
     ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             service.GenerateClientCertificateResponse(
                 pem_certificate="pem_certificate_value",
                 pem_certificate_chain=["pem_certificate_chain_value"],
+                ca_cert="ca_cert_value",
             )
         )
         response = await client.generate_client_certificate(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == service.GenerateClientCertificateRequest()
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, service.GenerateClientCertificateResponse)
     assert response.pem_certificate == "pem_certificate_value"
     assert response.pem_certificate_chain == ["pem_certificate_chain_value"]
+    assert response.ca_cert == "ca_cert_value"
 
 
 @pytest.mark.asyncio
 async def test_generate_client_certificate_async_from_dict():
     await test_generate_client_certificate_async(request_type=dict)
 
 
@@ -7395,14 +7635,1408 @@
             parent="parent_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.ListUsersRequest,
+        dict,
+    ],
+)
+def test_list_users(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = service.ListUsersResponse(
+            next_page_token="next_page_token_value",
+            unreachable=["unreachable_value"],
+        )
+        response = client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.ListUsersRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, pagers.ListUsersPager)
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
+
+
+def test_list_users_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        client.list_users()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.ListUsersRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_users_async(
+    transport: str = "grpc_asyncio", request_type=service.ListUsersRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            service.ListUsersResponse(
+                next_page_token="next_page_token_value",
+                unreachable=["unreachable_value"],
+            )
+        )
+        response = await client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.ListUsersRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, pagers.ListUsersAsyncPager)
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
+
+
+@pytest.mark.asyncio
+async def test_list_users_async_from_dict():
+    await test_list_users_async(request_type=dict)
+
+
+def test_list_users_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.ListUsersRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        call.return_value = service.ListUsersResponse()
+        client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_list_users_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.ListUsersRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            service.ListUsersResponse()
+        )
+        await client.list_users(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+def test_list_users_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = service.ListUsersResponse()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.list_users(
+            parent="parent_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+
+
+def test_list_users_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.list_users(
+            service.ListUsersRequest(),
+            parent="parent_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_list_users_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = service.ListUsersResponse()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            service.ListUsersResponse()
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.list_users(
+            parent="parent_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_list_users_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.list_users(
+            service.ListUsersRequest(),
+            parent="parent_value",
+        )
+
+
+def test_list_users_pager(transport_name: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials,
+        transport=transport_name,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+
+        metadata = ()
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
+        )
+        pager = client.list_users(request={})
+
+        assert pager._metadata == metadata
+
+        results = list(pager)
+        assert len(results) == 6
+        assert all(isinstance(i, resources.User) for i in results)
+
+
+def test_list_users_pages(transport_name: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials,
+        transport=transport_name,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_users), "__call__") as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+        pages = list(client.list_users(request={}).pages)
+        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
+            assert page_.raw_page.next_page_token == token
+
+
+@pytest.mark.asyncio
+async def test_list_users_async_pager():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_users), "__call__", new_callable=mock.AsyncMock
+    ) as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+        async_pager = await client.list_users(
+            request={},
+        )
+        assert async_pager.next_page_token == "abc"
+        responses = []
+        async for response in async_pager:  # pragma: no branch
+            responses.append(response)
+
+        assert len(responses) == 6
+        assert all(isinstance(i, resources.User) for i in responses)
+
+
+@pytest.mark.asyncio
+async def test_list_users_async_pages():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials,
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_users), "__call__", new_callable=mock.AsyncMock
+    ) as call:
+        # Set the response to a series of pages.
+        call.side_effect = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+            RuntimeError,
+        )
+        pages = []
+        async for page_ in (
+            await client.list_users(request={})
+        ).pages:  # pragma: no branch
+            pages.append(page_)
+        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
+            assert page_.raw_page.next_page_token == token
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.GetUserRequest,
+        dict,
+    ],
+)
+def test_get_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+        response = client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.GetUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_get_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        client.get_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.GetUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_user_async(
+    transport: str = "grpc_asyncio", request_type=service.GetUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            resources.User(
+                name="name_value",
+                password="password_value",
+                database_roles=["database_roles_value"],
+                user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+            )
+        )
+        response = await client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.GetUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+@pytest.mark.asyncio
+async def test_get_user_async_from_dict():
+    await test_get_user_async(request_type=dict)
+
+
+def test_get_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.GetUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        call.return_value = resources.User()
+        client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_get_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.GetUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        await client.get_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_get_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.get_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_get_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.get_user(
+            service.GetUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_get_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.get_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_get_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.get_user(
+            service.GetUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.CreateUserRequest,
+        dict,
+    ],
+)
+def test_create_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+        response = client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_create_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        client.create_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_user_async(
+    transport: str = "grpc_asyncio", request_type=service.CreateUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            resources.User(
+                name="name_value",
+                password="password_value",
+                database_roles=["database_roles_value"],
+                user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+            )
+        )
+        response = await client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.CreateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+@pytest.mark.asyncio
+async def test_create_user_async_from_dict():
+    await test_create_user_async(request_type=dict)
+
+
+def test_create_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateUserRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        call.return_value = resources.User()
+        client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_create_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.CreateUserRequest()
+
+    request.parent = "parent_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        await client.create_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "parent=parent_value",
+    ) in kw["metadata"]
+
+
+def test_create_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.create_user(
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].user_id
+        mock_val = "user_id_value"
+        assert arg == mock_val
+
+
+def test_create_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_user(
+            service.CreateUserRequest(),
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_create_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.create_user(
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].parent
+        mock_val = "parent_value"
+        assert arg == mock_val
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].user_id
+        mock_val = "user_id_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_create_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.create_user(
+            service.CreateUserRequest(),
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.UpdateUserRequest,
+        dict,
+    ],
+)
+def test_update_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+        response = client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.UpdateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_update_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        client.update_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.UpdateUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_user_async(
+    transport: str = "grpc_asyncio", request_type=service.UpdateUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            resources.User(
+                name="name_value",
+                password="password_value",
+                database_roles=["database_roles_value"],
+                user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+            )
+        )
+        response = await client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.UpdateUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+@pytest.mark.asyncio
+async def test_update_user_async_from_dict():
+    await test_update_user_async(request_type=dict)
+
+
+def test_update_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.UpdateUserRequest()
+
+    request.user.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        call.return_value = resources.User()
+        client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "user.name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_update_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.UpdateUserRequest()
+
+    request.user.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        await client.update_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "user.name=name_value",
+    ) in kw["metadata"]
+
+
+def test_update_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.update_user(
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].update_mask
+        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
+        assert arg == mock_val
+
+
+def test_update_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.update_user(
+            service.UpdateUserRequest(),
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+
+@pytest.mark.asyncio
+async def test_update_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = resources.User()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.User())
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.update_user(
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].user
+        mock_val = resources.User(name="name_value")
+        assert arg == mock_val
+        arg = args[0].update_mask
+        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_update_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.update_user(
+            service.UpdateUserRequest(),
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.DeleteUserRequest,
+        dict,
+    ],
+)
+def test_delete_user(request_type, transport: str = "grpc"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = None
+        response = client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.DeleteUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert response is None
+
+
+def test_delete_user_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        client.delete_user()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.DeleteUserRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_user_async(
+    transport: str = "grpc_asyncio", request_type=service.DeleteUserRequest
+):
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        response = await client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == service.DeleteUserRequest()
+
+    # Establish that the response is the type that we expect.
+    assert response is None
+
+
+@pytest.mark.asyncio
+async def test_delete_user_async_from_dict():
+    await test_delete_user_async(request_type=dict)
+
+
+def test_delete_user_field_headers():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.DeleteUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        call.return_value = None
+        client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_delete_user_field_headers_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = service.DeleteUserRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        await client.delete_user(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_delete_user_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = None
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.delete_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_delete_user_flattened_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.delete_user(
+            service.DeleteUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_delete_user_flattened_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_user), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = None
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.delete_user(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_delete_user_flattened_error_async():
+    client = AlloyDBAdminAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.delete_user(
+            service.DeleteUserRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.ListClustersRequest,
         dict,
     ],
 )
 def test_list_clusters_rest(request_type):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -7817,14 +9451,16 @@
     # verify required fields with default values are now present
 
     jsonified_request["name"] = "name_value"
 
     unset_fields = transport_class(
         credentials=ga_credentials.AnonymousCredentials()
     ).get_cluster._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(("view",))
     jsonified_request.update(unset_fields)
 
     # verify required fields with non-default values are left alone
     assert "name" in jsonified_request
     assert jsonified_request["name"] == "name_value"
 
     client = AlloyDBAdminClient(
@@ -7869,15 +9505,15 @@
 
 def test_get_cluster_rest_unset_required_fields():
     transport = transports.AlloyDBAdminRestTransport(
         credentials=ga_credentials.AnonymousCredentials
     )
 
     unset_fields = transport.get_cluster._get_unset_required_fields({})
-    assert set(unset_fields) == (set(()) & set(("name",)))
+    assert set(unset_fields) == (set(("view",)) & set(("name",)))
 
 
 @pytest.mark.parametrize("null_interceptor", [True, False])
 def test_get_cluster_rest_interceptors(null_interceptor):
     transport = transports.AlloyDBAdminRestTransport(
         credentials=ga_credentials.AnonymousCredentials(),
         interceptor=None
@@ -8046,14 +9682,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -8083,14 +9723,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -8318,14 +9959,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -8355,14 +10000,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -8484,14 +10130,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -8521,14 +10171,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -8736,14 +10387,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -8773,14 +10428,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -9660,14 +11316,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -9697,14 +11357,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -9936,14 +11597,18 @@
         "create_time": {"seconds": 751, "nanos": 543},
         "update_time": {},
         "delete_time": {},
         "labels": {},
         "state": 1,
         "cluster_type": 1,
         "database_version": 1,
+        "network_config": {
+            "network": "network_value",
+            "allocated_ip_range": "allocated_ip_range_value",
+        },
         "network": "network_value",
         "etag": "etag_value",
         "annotations": {},
         "reconciling": True,
         "initial_user": {"user": "user_value", "password": "password_value"},
         "automated_backup_policy": {
             "weekly_schedule": {
@@ -9973,14 +11638,15 @@
             "recovery_window_days": 2166,
             "encryption_config": {},
         },
         "continuous_backup_info": {
             "encryption_info": {},
             "enabled_time": {},
             "schedule": [1],
+            "earliest_restorable_time": {},
         },
         "secondary_config": {"primary_cluster_name": "primary_cluster_name_value"},
         "primary_config": {
             "secondary_cluster_names": [
                 "secondary_cluster_names_value1",
                 "secondary_cluster_names_value2",
             ]
@@ -10744,14 +12410,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a response.
     with mock.patch.object(type(client.transport._session), "request") as req:
         # Designate an appropriate value for the returned response.
         return_value = operations_pb2.Operation(name="operations/spam")
@@ -10985,14 +12652,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a BadRequest error.
     with mock.patch.object(Session, "request") as req, pytest.raises(
         core_exceptions.BadRequest
     ):
@@ -11114,14 +12782,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a response.
     with mock.patch.object(type(client.transport._session), "request") as req:
         # Designate an appropriate value for the returned response.
         return_value = operations_pb2.Operation(name="operations/spam")
@@ -11357,14 +13026,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a BadRequest error.
     with mock.patch.object(Session, "request") as req, pytest.raises(
         core_exceptions.BadRequest
     ):
@@ -11491,14 +13161,15 @@
                         "query_plans_per_minute": 2378,
                     },
                     "read_pool_config": {"node_count": 1070},
                     "ip_address": "ip_address_value",
                     "reconciling": True,
                     "etag": "etag_value",
                     "annotations": {},
+                    "update_policy": {"mode": 1},
                 },
                 "request_id": "request_id_value",
                 "validate_only": True,
             }
         ]
     }
     request = request_type(**request_init)
@@ -11718,14 +13389,15 @@
                         "query_plans_per_minute": 2378,
                     },
                     "read_pool_config": {"node_count": 1070},
                     "ip_address": "ip_address_value",
                     "reconciling": True,
                     "etag": "etag_value",
                     "annotations": {},
+                    "update_policy": {"mode": 1},
                 },
                 "request_id": "request_id_value",
                 "validate_only": True,
             }
         ]
     }
     request = request_type(**request_init)
@@ -11795,14 +13467,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a response.
     with mock.patch.object(type(client.transport._session), "request") as req:
         # Designate an appropriate value for the returned response.
         return_value = operations_pb2.Operation(name="operations/spam")
@@ -12018,14 +13691,15 @@
             "query_plans_per_minute": 2378,
         },
         "read_pool_config": {"node_count": 1070},
         "ip_address": "ip_address_value",
         "reconciling": True,
         "etag": "etag_value",
         "annotations": {},
+        "update_policy": {"mode": 1},
     }
     request = request_type(**request_init)
 
     # Mock the http request call within the method and fake a BadRequest error.
     with mock.patch.object(Session, "request") as req, pytest.raises(
         core_exceptions.BadRequest
     ):
@@ -12657,14 +14331,290 @@
         credentials=ga_credentials.AnonymousCredentials(), transport="rest"
     )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
+        service.InjectFaultRequest,
+        dict,
+    ],
+)
+def test_inject_fault_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/instances/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.inject_fault(request)
+
+    # Establish that the response is the type that we expect.
+    assert response.operation.name == "operations/spam"
+
+
+def test_inject_fault_rest_required_fields(request_type=service.InjectFaultRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).inject_fault._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).inject_fault._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = operations_pb2.Operation(name="operations/spam")
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "post",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+            json_return_value = json_format.MessageToJson(return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.inject_fault(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_inject_fault_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.inject_fault._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(())
+        & set(
+            (
+                "faultType",
+                "name",
+            )
+        )
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_inject_fault_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        operation.Operation, "_set_result_from_operation"
+    ), mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_inject_fault"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_inject_fault"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.InjectFaultRequest.pb(service.InjectFaultRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = json_format.MessageToJson(
+            operations_pb2.Operation()
+        )
+
+        request = service.InjectFaultRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = operations_pb2.Operation()
+
+        client.inject_fault(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_inject_fault_rest_bad_request(
+    transport: str = "rest", request_type=service.InjectFaultRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/instances/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.inject_fault(request)
+
+
+def test_inject_fault_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = operations_pb2.Operation(name="operations/spam")
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/instances/sample4"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = json_format.MessageToJson(return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.inject_fault(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1beta/{name=projects/*/locations/*/clusters/*/instances/*}:injectFault"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_inject_fault_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.inject_fault(
+            service.InjectFaultRequest(),
+            fault_type=service.InjectFaultRequest.FaultType.STOP_VM,
+            name="name_value",
+        )
+
+
+def test_inject_fault_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
         service.RestartInstanceRequest,
         dict,
     ],
 )
 def test_restart_instance_rest(request_type):
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -14865,14 +16815,15 @@
 
     # Mock the http request call within the method and fake a response.
     with mock.patch.object(type(client.transport._session), "request") as req:
         # Designate an appropriate value for the returned response.
         return_value = service.GenerateClientCertificateResponse(
             pem_certificate="pem_certificate_value",
             pem_certificate_chain=["pem_certificate_chain_value"],
+            ca_cert="ca_cert_value",
         )
 
         # Wrap the value into a proper Response obj
         response_value = Response()
         response_value.status_code = 200
         pb_return_value = service.GenerateClientCertificateResponse.pb(return_value)
         json_return_value = json_format.MessageToJson(pb_return_value)
@@ -14881,14 +16832,15 @@
         req.return_value = response_value
         response = client.generate_client_certificate(request)
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, service.GenerateClientCertificateResponse)
     assert response.pem_certificate == "pem_certificate_value"
     assert response.pem_certificate_chain == ["pem_certificate_chain_value"]
+    assert response.ca_cert == "ca_cert_value"
 
 
 def test_generate_client_certificate_rest_required_fields(
     request_type=service.GenerateClientCertificateRequest,
 ):
     transport_class = transports.AlloyDBAdminRestTransport
 
@@ -15397,14 +17349,1534 @@
 
 def test_get_connection_info_rest_error():
     client = AlloyDBAdminClient(
         credentials=ga_credentials.AnonymousCredentials(), transport="rest"
     )
 
 
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.ListUsersRequest,
+        dict,
+    ],
+)
+def test_list_users_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = service.ListUsersResponse(
+            next_page_token="next_page_token_value",
+            unreachable=["unreachable_value"],
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = service.ListUsersResponse.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.list_users(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, pagers.ListUsersPager)
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
+
+
+def test_list_users_rest_required_fields(request_type=service.ListUsersRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["parent"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).list_users._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["parent"] = "parent_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).list_users._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "filter",
+            "order_by",
+            "page_size",
+            "page_token",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "parent" in jsonified_request
+    assert jsonified_request["parent"] == "parent_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = service.ListUsersResponse()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "get",
+                "query_params": pb_request,
+            }
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = service.ListUsersResponse.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.list_users(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_list_users_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.list_users._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "filter",
+                "orderBy",
+                "pageSize",
+                "pageToken",
+            )
+        )
+        & set(("parent",))
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_list_users_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_list_users"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_list_users"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.ListUsersRequest.pb(service.ListUsersRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = service.ListUsersResponse.to_json(
+            service.ListUsersResponse()
+        )
+
+        request = service.ListUsersRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = service.ListUsersResponse()
+
+        client.list_users(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_list_users_rest_bad_request(
+    transport: str = "rest", request_type=service.ListUsersRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.list_users(request)
+
+
+def test_list_users_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = service.ListUsersResponse()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            parent="parent_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = service.ListUsersResponse.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.list_users(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1beta/{parent=projects/*/locations/*/clusters/*}/users"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_list_users_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.list_users(
+            service.ListUsersRequest(),
+            parent="parent_value",
+        )
+
+
+def test_list_users_rest_pager(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # TODO(kbandes): remove this mock unless there's a good reason for it.
+        # with mock.patch.object(path_template, 'transcode') as transcode:
+        # Set the response as a series of pages
+        response = (
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                    resources.User(),
+                ],
+                next_page_token="abc",
+            ),
+            service.ListUsersResponse(
+                users=[],
+                next_page_token="def",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                ],
+                next_page_token="ghi",
+            ),
+            service.ListUsersResponse(
+                users=[
+                    resources.User(),
+                    resources.User(),
+                ],
+            ),
+        )
+        # Two responses for two calls
+        response = response + response
+
+        # Wrap the values into proper Response objs
+        response = tuple(service.ListUsersResponse.to_json(x) for x in response)
+        return_values = tuple(Response() for i in response)
+        for return_val, response_val in zip(return_values, response):
+            return_val._content = response_val.encode("UTF-8")
+            return_val.status_code = 200
+        req.side_effect = return_values
+
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        pager = client.list_users(request=sample_request)
+
+        results = list(pager)
+        assert len(results) == 6
+        assert all(isinstance(i, resources.User) for i in results)
+
+        pages = list(client.list_users(request=sample_request).pages)
+        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
+            assert page_.raw_page.next_page_token == token
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.GetUserRequest,
+        dict,
+    ],
+)
+def test_get_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.get_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_get_user_rest_required_fields(request_type=service.GetUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).get_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).get_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = resources.User()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "get",
+                "query_params": pb_request,
+            }
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = resources.User.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.get_user(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_get_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.get_user._get_unset_required_fields({})
+    assert set(unset_fields) == (set(()) & set(("name",)))
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_get_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_get_user"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_get_user"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.GetUserRequest.pb(service.GetUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = resources.User.to_json(resources.User())
+
+        request = service.GetUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = resources.User()
+
+        client.get_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_get_user_rest_bad_request(
+    transport: str = "rest", request_type=service.GetUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.get_user(request)
+
+
+def test_get_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.get_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1beta/{name=projects/*/locations/*/clusters/*/users/*}"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_get_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.get_user(
+            service.GetUserRequest(),
+            name="name_value",
+        )
+
+
+def test_get_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.CreateUserRequest,
+        dict,
+    ],
+)
+def test_create_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request_init["user"] = {
+        "name": "name_value",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.create_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_create_user_rest_required_fields(request_type=service.CreateUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["parent"] = ""
+    request_init["user_id"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+    assert "userId" not in jsonified_request
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+    assert "userId" in jsonified_request
+    assert jsonified_request["userId"] == request_init["user_id"]
+
+    jsonified_request["parent"] = "parent_value"
+    jsonified_request["userId"] = "user_id_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).create_user._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "request_id",
+            "user_id",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "parent" in jsonified_request
+    assert jsonified_request["parent"] == "parent_value"
+    assert "userId" in jsonified_request
+    assert jsonified_request["userId"] == "user_id_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = resources.User()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "post",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = resources.User.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.create_user(request)
+
+            expected_params = [
+                (
+                    "userId",
+                    "",
+                ),
+                ("$alt", "json;enum-encoding=int"),
+            ]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_create_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.create_user._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "requestId",
+                "userId",
+                "validateOnly",
+            )
+        )
+        & set(
+            (
+                "parent",
+                "userId",
+                "user",
+            )
+        )
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_create_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_create_user"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_create_user"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.CreateUserRequest.pb(service.CreateUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = resources.User.to_json(resources.User())
+
+        request = service.CreateUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = resources.User()
+
+        client.create_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_create_user_rest_bad_request(
+    transport: str = "rest", request_type=service.CreateUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {"parent": "projects/sample1/locations/sample2/clusters/sample3"}
+    request_init["user"] = {
+        "name": "name_value",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.create_user(request)
+
+
+def test_create_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "parent": "projects/sample1/locations/sample2/clusters/sample3"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.create_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1beta/{parent=projects/*/locations/*/clusters/*}/users"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_create_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.create_user(
+            service.CreateUserRequest(),
+            parent="parent_value",
+            user=resources.User(name="name_value"),
+            user_id="user_id_value",
+        )
+
+
+def test_create_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.UpdateUserRequest,
+        dict,
+    ],
+)
+def test_update_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "user": {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+    }
+    request_init["user"] = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User(
+            name="name_value",
+            password="password_value",
+            database_roles=["database_roles_value"],
+            user_type=resources.User.UserType.ALLOYDB_BUILT_IN,
+        )
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.update_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, resources.User)
+    assert response.name == "name_value"
+    assert response.password == "password_value"
+    assert response.database_roles == ["database_roles_value"]
+    assert response.user_type == resources.User.UserType.ALLOYDB_BUILT_IN
+
+
+def test_update_user_rest_required_fields(request_type=service.UpdateUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).update_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).update_user._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "allow_missing",
+            "request_id",
+            "update_mask",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = resources.User()
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "patch",
+                "query_params": pb_request,
+            }
+            transcode_result["body"] = pb_request
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+
+            pb_return_value = resources.User.pb(return_value)
+            json_return_value = json_format.MessageToJson(pb_return_value)
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.update_user(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_update_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.update_user._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "allowMissing",
+                "requestId",
+                "updateMask",
+                "validateOnly",
+            )
+        )
+        & set(("user",))
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_update_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "post_update_user"
+    ) as post, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_update_user"
+    ) as pre:
+        pre.assert_not_called()
+        post.assert_not_called()
+        pb_message = service.UpdateUserRequest.pb(service.UpdateUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+        req.return_value._content = resources.User.to_json(resources.User())
+
+        request = service.UpdateUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+        post.return_value = resources.User()
+
+        client.update_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+        post.assert_called_once()
+
+
+def test_update_user_rest_bad_request(
+    transport: str = "rest", request_type=service.UpdateUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "user": {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+    }
+    request_init["user"] = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4",
+        "password": "password_value",
+        "database_roles": ["database_roles_value1", "database_roles_value2"],
+        "user_type": 1,
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.update_user(request)
+
+
+def test_update_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = resources.User()
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "user": {
+                "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+            }
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        pb_return_value = resources.User.pb(return_value)
+        json_return_value = json_format.MessageToJson(pb_return_value)
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.update_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1beta/{user.name=projects/*/locations/*/clusters/*/users/*}"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_update_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.update_user(
+            service.UpdateUserRequest(),
+            user=resources.User(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        )
+
+
+def test_update_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        service.DeleteUserRequest,
+        dict,
+    ],
+)
+def test_delete_user_rest(request_type):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = None
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = ""
+
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+        response = client.delete_user(request)
+
+    # Establish that the response is the type that we expect.
+    assert response is None
+
+
+def test_delete_user_rest_required_fields(request_type=service.DeleteUserRequest):
+    transport_class = transports.AlloyDBAdminRestTransport
+
+    request_init = {}
+    request_init["name"] = ""
+    request = request_type(**request_init)
+    pb_request = request_type.pb(request)
+    jsonified_request = json.loads(
+        json_format.MessageToJson(
+            pb_request,
+            including_default_value_fields=False,
+            use_integers_for_enums=False,
+        )
+    )
+
+    # verify fields with default values are dropped
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).delete_user._get_unset_required_fields(jsonified_request)
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with default values are now present
+
+    jsonified_request["name"] = "name_value"
+
+    unset_fields = transport_class(
+        credentials=ga_credentials.AnonymousCredentials()
+    ).delete_user._get_unset_required_fields(jsonified_request)
+    # Check that path parameters and body parameters are not mixing in.
+    assert not set(unset_fields) - set(
+        (
+            "request_id",
+            "validate_only",
+        )
+    )
+    jsonified_request.update(unset_fields)
+
+    # verify required fields with non-default values are left alone
+    assert "name" in jsonified_request
+    assert jsonified_request["name"] == "name_value"
+
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+    request = request_type(**request_init)
+
+    # Designate an appropriate value for the returned response.
+    return_value = None
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(Session, "request") as req:
+        # We need to mock transcode() because providing default values
+        # for required fields will fail the real version if the http_options
+        # expect actual values for those fields.
+        with mock.patch.object(path_template, "transcode") as transcode:
+            # A uri without fields and an empty body will force all the
+            # request fields to show up in the query_params.
+            pb_request = request_type.pb(request)
+            transcode_result = {
+                "uri": "v1/sample_method",
+                "method": "delete",
+                "query_params": pb_request,
+            }
+            transcode.return_value = transcode_result
+
+            response_value = Response()
+            response_value.status_code = 200
+            json_return_value = ""
+
+            response_value._content = json_return_value.encode("UTF-8")
+            req.return_value = response_value
+
+            response = client.delete_user(request)
+
+            expected_params = [("$alt", "json;enum-encoding=int")]
+            actual_params = req.call_args.kwargs["params"]
+            assert expected_params == actual_params
+
+
+def test_delete_user_rest_unset_required_fields():
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials
+    )
+
+    unset_fields = transport.delete_user._get_unset_required_fields({})
+    assert set(unset_fields) == (
+        set(
+            (
+                "requestId",
+                "validateOnly",
+            )
+        )
+        & set(("name",))
+    )
+
+
+@pytest.mark.parametrize("null_interceptor", [True, False])
+def test_delete_user_rest_interceptors(null_interceptor):
+    transport = transports.AlloyDBAdminRestTransport(
+        credentials=ga_credentials.AnonymousCredentials(),
+        interceptor=None
+        if null_interceptor
+        else transports.AlloyDBAdminRestInterceptor(),
+    )
+    client = AlloyDBAdminClient(transport=transport)
+    with mock.patch.object(
+        type(client.transport._session), "request"
+    ) as req, mock.patch.object(
+        path_template, "transcode"
+    ) as transcode, mock.patch.object(
+        transports.AlloyDBAdminRestInterceptor, "pre_delete_user"
+    ) as pre:
+        pre.assert_not_called()
+        pb_message = service.DeleteUserRequest.pb(service.DeleteUserRequest())
+        transcode.return_value = {
+            "method": "post",
+            "uri": "my_uri",
+            "body": pb_message,
+            "query_params": pb_message,
+        }
+
+        req.return_value = Response()
+        req.return_value.status_code = 200
+        req.return_value.request = PreparedRequest()
+
+        request = service.DeleteUserRequest()
+        metadata = [
+            ("key", "val"),
+            ("cephalopod", "squid"),
+        ]
+        pre.return_value = request, metadata
+
+        client.delete_user(
+            request,
+            metadata=[
+                ("key", "val"),
+                ("cephalopod", "squid"),
+            ],
+        )
+
+        pre.assert_called_once()
+
+
+def test_delete_user_rest_bad_request(
+    transport: str = "rest", request_type=service.DeleteUserRequest
+):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # send a request that will satisfy transcoding
+    request_init = {
+        "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+    }
+    request = request_type(**request_init)
+
+    # Mock the http request call within the method and fake a BadRequest error.
+    with mock.patch.object(Session, "request") as req, pytest.raises(
+        core_exceptions.BadRequest
+    ):
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 400
+        response_value.request = Request()
+        req.return_value = response_value
+        client.delete_user(request)
+
+
+def test_delete_user_rest_flattened():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="rest",
+    )
+
+    # Mock the http request call within the method and fake a response.
+    with mock.patch.object(type(client.transport._session), "request") as req:
+        # Designate an appropriate value for the returned response.
+        return_value = None
+
+        # get arguments that satisfy an http rule for this method
+        sample_request = {
+            "name": "projects/sample1/locations/sample2/clusters/sample3/users/sample4"
+        }
+
+        # get truthy value for each flattened field
+        mock_args = dict(
+            name="name_value",
+        )
+        mock_args.update(sample_request)
+
+        # Wrap the value into a proper Response obj
+        response_value = Response()
+        response_value.status_code = 200
+        json_return_value = ""
+        response_value._content = json_return_value.encode("UTF-8")
+        req.return_value = response_value
+
+        client.delete_user(**mock_args)
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(req.mock_calls) == 1
+        _, args, _ = req.mock_calls[0]
+        assert path_template.validate(
+            "%s/v1beta/{name=projects/*/locations/*/clusters/*/users/*}"
+            % client.transport._host,
+            args[1],
+        )
+
+
+def test_delete_user_rest_flattened_error(transport: str = "rest"):
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.delete_user(
+            service.DeleteUserRequest(),
+            name="name_value",
+        )
+
+
+def test_delete_user_rest_error():
+    client = AlloyDBAdminClient(
+        credentials=ga_credentials.AnonymousCredentials(), transport="rest"
+    )
+
+
 def test_credentials_transport_error():
     # It is an error to provide credentials and a transport instance.
     transport = transports.AlloyDBAdminGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     with pytest.raises(ValueError):
         client = AlloyDBAdminClient(
@@ -15552,23 +19024,29 @@
         "get_instance",
         "create_instance",
         "create_secondary_instance",
         "batch_create_instances",
         "update_instance",
         "delete_instance",
         "failover_instance",
+        "inject_fault",
         "restart_instance",
         "list_backups",
         "get_backup",
         "create_backup",
         "update_backup",
         "delete_backup",
         "list_supported_database_flags",
         "generate_client_certificate",
         "get_connection_info",
+        "list_users",
+        "get_user",
+        "create_user",
+        "update_user",
+        "delete_user",
         "get_location",
         "list_locations",
         "get_operation",
         "cancel_operation",
         "delete_operation",
         "list_operations",
     )
@@ -15892,14 +19370,17 @@
     assert session1 != session2
     session1 = client1.transport.delete_instance._session
     session2 = client2.transport.delete_instance._session
     assert session1 != session2
     session1 = client1.transport.failover_instance._session
     session2 = client2.transport.failover_instance._session
     assert session1 != session2
+    session1 = client1.transport.inject_fault._session
+    session2 = client2.transport.inject_fault._session
+    assert session1 != session2
     session1 = client1.transport.restart_instance._session
     session2 = client2.transport.restart_instance._session
     assert session1 != session2
     session1 = client1.transport.list_backups._session
     session2 = client2.transport.list_backups._session
     assert session1 != session2
     session1 = client1.transport.get_backup._session
@@ -15919,14 +19400,29 @@
     assert session1 != session2
     session1 = client1.transport.generate_client_certificate._session
     session2 = client2.transport.generate_client_certificate._session
     assert session1 != session2
     session1 = client1.transport.get_connection_info._session
     session2 = client2.transport.get_connection_info._session
     assert session1 != session2
+    session1 = client1.transport.list_users._session
+    session2 = client2.transport.list_users._session
+    assert session1 != session2
+    session1 = client1.transport.get_user._session
+    session2 = client2.transport.get_user._session
+    assert session1 != session2
+    session1 = client1.transport.create_user._session
+    session2 = client2.transport.create_user._session
+    assert session1 != session2
+    session1 = client1.transport.update_user._session
+    session2 = client2.transport.update_user._session
+    assert session1 != session2
+    session1 = client1.transport.delete_user._session
+    session2 = client2.transport.delete_user._session
+    assert session1 != session2
 
 
 def test_alloy_db_admin_grpc_transport_channel():
     channel = grpc.secure_channel("http://localhost/", grpc.local_channel_credentials())
 
     # Check that channel is used if provided.
     transport = transports.AlloyDBAdminGrpcTransport(
@@ -16268,109 +19764,138 @@
     path = AlloyDBAdminClient.supported_database_flag_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_supported_database_flag_path(path)
     assert expected == actual
 
 
+def test_user_path():
+    project = "squid"
+    location = "clam"
+    cluster = "whelk"
+    user = "octopus"
+    expected = "projects/{project}/locations/{location}/clusters/{cluster}/users/{user}".format(
+        project=project,
+        location=location,
+        cluster=cluster,
+        user=user,
+    )
+    actual = AlloyDBAdminClient.user_path(project, location, cluster, user)
+    assert expected == actual
+
+
+def test_parse_user_path():
+    expected = {
+        "project": "oyster",
+        "location": "nudibranch",
+        "cluster": "cuttlefish",
+        "user": "mussel",
+    }
+    path = AlloyDBAdminClient.user_path(**expected)
+
+    # Check that the path construction is reversible.
+    actual = AlloyDBAdminClient.parse_user_path(path)
+    assert expected == actual
+
+
 def test_common_billing_account_path():
-    billing_account = "squid"
+    billing_account = "winkle"
     expected = "billingAccounts/{billing_account}".format(
         billing_account=billing_account,
     )
     actual = AlloyDBAdminClient.common_billing_account_path(billing_account)
     assert expected == actual
 
 
 def test_parse_common_billing_account_path():
     expected = {
-        "billing_account": "clam",
+        "billing_account": "nautilus",
     }
     path = AlloyDBAdminClient.common_billing_account_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_billing_account_path(path)
     assert expected == actual
 
 
 def test_common_folder_path():
-    folder = "whelk"
+    folder = "scallop"
     expected = "folders/{folder}".format(
         folder=folder,
     )
     actual = AlloyDBAdminClient.common_folder_path(folder)
     assert expected == actual
 
 
 def test_parse_common_folder_path():
     expected = {
-        "folder": "octopus",
+        "folder": "abalone",
     }
     path = AlloyDBAdminClient.common_folder_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_folder_path(path)
     assert expected == actual
 
 
 def test_common_organization_path():
-    organization = "oyster"
+    organization = "squid"
     expected = "organizations/{organization}".format(
         organization=organization,
     )
     actual = AlloyDBAdminClient.common_organization_path(organization)
     assert expected == actual
 
 
 def test_parse_common_organization_path():
     expected = {
-        "organization": "nudibranch",
+        "organization": "clam",
     }
     path = AlloyDBAdminClient.common_organization_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_organization_path(path)
     assert expected == actual
 
 
 def test_common_project_path():
-    project = "cuttlefish"
+    project = "whelk"
     expected = "projects/{project}".format(
         project=project,
     )
     actual = AlloyDBAdminClient.common_project_path(project)
     assert expected == actual
 
 
 def test_parse_common_project_path():
     expected = {
-        "project": "mussel",
+        "project": "octopus",
     }
     path = AlloyDBAdminClient.common_project_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_project_path(path)
     assert expected == actual
 
 
 def test_common_location_path():
-    project = "winkle"
-    location = "nautilus"
+    project = "oyster"
+    location = "nudibranch"
     expected = "projects/{project}/locations/{location}".format(
         project=project,
         location=location,
     )
     actual = AlloyDBAdminClient.common_location_path(project, location)
     assert expected == actual
 
 
 def test_parse_common_location_path():
     expected = {
-        "project": "scallop",
-        "location": "abalone",
+        "project": "cuttlefish",
+        "location": "mussel",
     }
     path = AlloyDBAdminClient.common_location_path(**expected)
 
     # Check that the path construction is reversible.
     actual = AlloyDBAdminClient.parse_common_location_path(path)
     assert expected == actual
```

